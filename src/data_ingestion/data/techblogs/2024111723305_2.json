[{"id": 91220, "date": "2024-11-04T09:39:18", "date_gmt": "2024-11-04T17:39:18", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91220"}, "modified": "2024-11-14T09:10:48", "modified_gmt": "2024-11-14T17:10:48", "slug": "discover-new-biological-insights-with-accelerated-pangenome-alignment-in-nvidia-parabricks", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/discover-new-biological-insights-with-accelerated-pangenome-alignment-in-nvidia-parabricks/", "title": {"rendered": "Discover New Biological Insights with Accelerated Pangenome Alignment in NVIDIA Parabricks"}, "content": {"rendered": "\n<p><a href=\"https://www.nvidia.com/en-us/clara/parabricks/\">NVIDIA Parabricks</a> is a scalable genomics analysis software suite that solves omics challenges with accelerated computing and deep learning to unlock new scientific breakthroughs. <a href=\"https://docs.nvidia.com/clara/parabricks/latest/index.html?ncid=em-anno-217927-vt12\">NVIDIA Parabricks v4.4</a> introduces new features and functionality including accelerated pangenome graph alignment, as announced at the American Society of Human Genetics (ASHG) national meeting.&nbsp;</p>\n\n\n\n<p>The core new feature of the Parabricks v4.4 release is single-end and paired-end support for <a href=\"https://www.science.org/doi/10.1126/science.abg8871\">Giraffe</a> for accelerated pangenome graph alignment. The release also includes additional functionality for Minimap2 and GATK HaplotypeCaller, as well as tool performance improvements. It also expands collaborations to support genomic sequencing and software platforms.&nbsp;</p>\n\n\n\n<p>Release highlights include the following:</p>\n\n\n\n<h3 id=\"new_features\"  class=\"wp-block-heading\">New features<a href=\"#new_features\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li>GPU-accelerated Giraffe, with single-end and paired-end support&nbsp;</li>\n\n\n\n<li>Pbmm2 wrapper for native PacBio input and output of Minimap2</li>\n\n\n\n<li>Allele option support in GATK HaplotypeCaller&nbsp;</li>\n\n\n\n<li>Support for unaligned BAMs: FQ2BAM (BWA-MEM) and Minimap2</li>\n</ul>\n\n\n\n<h3 id=\"improved_features\"  class=\"wp-block-heading\">Improved features<a href=\"#improved_features\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Faster Minimap2 for PacBio and Oxford Nanopore (ONT) data</li>\n\n\n\n<li>DeepVariant acceleration for ONT data</li>\n\n\n\n<li>Faster CRAM file writer (2x acceleration over CPU-only)</li>\n\n\n\n<li>&lt;30-minute end-to-end 30x whole genome sequencing (WGS) germline on a single-GPU system (NVIDIA Grace Hopper)</li>\n</ul>\n\n\n\n<h3 id=\"new_collaborations_and_benchmarks\"  class=\"wp-block-heading\">New collaborations and benchmarks<a href=\"#new_collaborations_and_benchmarks\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Complete Genomics data supported on Parabricks</li>\n\n\n\n<li>Parabricks now available on Basepair platform</li>\n\n\n\n<li>Updated benchmarks, including DeepSomatic and Giraffe</li>\n</ul>\n\n\n\n<p>The latest release of Parabricks v4.4 enables scientists and researchers to use Giraffe for pangenome alignment. By understanding genetic diversity from pangenomes and using the accelerated version of Giraffe available in Parabricks v4.4, scientists can discover new biological insights even faster.</p>\n\n\n\n<h2 id=\"understanding_genetic_diversity_from_pangenomes\"  class=\"wp-block-heading\">Understanding genetic diversity from pangenomes<a href=\"#understanding_genetic_diversity_from_pangenomes\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>To understand the underlying cause of disease, individuals\u2019 genomes have historically been compared to a linear reference genome. Although a linear reference genome is not the DNA sequence of an individual, but is instead an average genome constructed from DNA of a few individuals, it serves as an accepted representation of a single consensus haplotype.&nbsp;</p>\n\n\n\n<p>Genome Reference Consortium Human Build 38 (GRCh38) is the current human reference genome that is most widely used across genetic studies as the comparison for different genetic studies. It inherently introduces biases and errors in variant calling, especially in repetitive or highly polymorphic regions. Additionally, it may inadequately represent genetic variation from minority populations, thereby limiting understanding of the complete spectrum of genetic diversity.</p>\n\n\n\n<p>In contrast, graph-based pangenomes offer a robust solution to this issue by integrating multiple reference genomes into a unified structure. This approach effectively captures the genetic diversity within a species, enabling more accurate detection and analysis of variations across different genomes. By representing genomic data as graphs, pangenome graphs enable comprehensive and unbiased genetic variation analysis, overcoming the limitations imposed by reliance on a single reference genome.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"815\" height=\"669\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph.png\" alt=\"The reference genome as a linear haploid sequence is limited in how well it can represent genetic diversity of populations, including single nucleotide polymorphisms (SNPs), indels and structural variants that are more common amongst specific subpopulations.\nAligning to a pangenome graph reference enables high accuracy genomic analysis by providing representation for many diverse subpopulations. \n\" class=\"wp-image-91227\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph.png 815w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-300x246.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-625x513.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-140x115.png 140w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-768x630.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-645x529.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-365x300.png 365w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-110x90.png 110w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-362x297.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-linear-reference-genome-pangenome-graph-134x110.png 134w\" sizes=\"(max-width: 815px) 100vw, 815px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. A linear reference genome compared to a pangenome graph</em></em></figcaption></figure>\n\n\n\n<h2 id=\"graph_genomes\"  class=\"wp-block-heading\">Graph genomes<a href=\"#graph_genomes\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>To represent pangenome data, graph genomes provide a unified framework for representing the genetic variation of multiple genomes. The graph structure of the data provides easier understanding of structural changes, including insertions, deletions, and rearrangements.&nbsp;</p>\n\n\n\n<p>Graph genomes are particularly beneficial to improving accuracy in variant calling since they can help increase detection of genetic variants. However, the analysis becomes more&nbsp;challenging, particularly in alignment, since graph-based representations introduce more complexities than the linear sequences of single references. Additionally, as graph genomes grow in size and complexity, computational requirements and processing can become prohibitive.&nbsp;</p>\n\n\n\n<h2 id=\"accelerating_pangenome_alignment_with_giraffe\"  class=\"wp-block-heading\">Accelerating pangenome alignment with Giraffe<a href=\"#accelerating_pangenome_alignment_with_giraffe\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Giraffe is a software tool to support pangenome graph alignment. Built by the University of California, Santa Cruz (UCSC), it is used particularly in the context of large-scale genomic sequencing projects and helps with alignment, assembly, and variant calling. Giraffe enables new genomic sequences to be compared to a pangenome\u2014not just a single reference genome.&nbsp;</p>\n\n\n\n<p>With the latest v4.4 release, Parabricks now supports Giraffe for single-end and paired-end data to provide GPU-acceleration for pangenome alignment. Plus, results are fully equivalent to the <a href=\"https://github.com/vgteam/vg/releases/tag/v1.59.0\">open-source version of Giraffe</a> so that researchers can use Parabricks v4.4 to replicate an open-source tool. As a result, scientists and researchers can increase accuracy and improve variant calling\u2014particularly across genetic variations and diverse populations.</p>\n\n\n\n<p>\u201cThe current human reference genome has been the cornerstone of human genetics research for over twenty years,\u201d explains Dr. Benedict Paten, professor and associate director at the University of California, Santa Cruz Genomics Institute. \u201cHowever, it contains just a single representative sequence for each chromosome and so can\u2019t by definition capture the rich variation present in our population. To understand the common genetic diversity of our population a human pangenome is necessary.\u201d&nbsp;</p>\n\n\n\n<p>\u201cPangenomes encode hundreds or, in the future, even thousands of individual genomes in a reference structure,\u201d Dr. Paten adds. \u201cThey better represent us, ensuring research and future precision therapeutics account for our individual diversity. At UCSC, we have a research team dedicated to building tools to use the pangenome. This includes Giraffe, a tool for mapping a new sample to the pangenome. We are excited to be working with the NVIDIA team to accelerate Giraffe and make it a workhorse tool for future projects. This has potential to have a huge downstream impact.\u201d&nbsp;</p>\n\n\n\n<h2 id=\"new_collaborations\"  class=\"wp-block-heading\">New collaborations<a href=\"#new_collaborations\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>In addition to the latest features of Parabricks v4.4, NVIDIA expands collaborations with genomic sequencing and software platforms\u2013including Complete Genomics and Basepair.&nbsp;</p>\n\n\n\n<h3 id=\"complete_genomics\"  class=\"wp-block-heading\">Complete Genomics<a href=\"#complete_genomics\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p><a href=\"https://www.completegenomics.com/\">Complete Genomics</a> is committed to driving genomics forward with complete sequencing solutions that improve lives. Offering a wide range of applications, including WGS, single-cell analysis, spatial transcriptomics, and microbiology, Complete Genomics leverages its proprietary DNBSEQ (DNA Nanoball Sequencing) technology. This technology produces deep sequencing coverage while ensuring high accuracy and low error rates. Parabricks germline workflows can now use data from Complete Genomicssequencers, including the DNBSEQ-T7 and DNBSEQ-G400.&nbsp;</p>\n\n\n\n<p>The integration of the DNBSEQ with Parabricks technology provides an accelerated and cost-effective solution for secondary genomic analysis. For example, processing a 30x WGS sample using fq2bam and haplotypecaller workflows on the DNBSEQ-T7 sequencer can be optimized for speed or cost depending on the GPU instance.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Speed</strong>: 16-minute runtime on four NVIDIA L40 GPUs</li>\n\n\n\n<li><strong>Cost</strong>: $2.67 cost on four NVIDIA L4 GPUs</li>\n</ul>\n\n\n\n<p>&#8220;Our integration of NVIDIA Parabricks allows us to harness the full potential of our DNBSEQ-T7 sequencing platform,\u201d says Rob Tarbox, VP of Product and Marketing at Complete Genomics. \u201cBy combining our high-quality sequencing data with Parabricks\u2019 speed and accuracy, we\u2019re enabling researchers to uncover variants more efficiently and cost-effectively, ultimately advancing precision medicine and improving patient outcomes.</p>\n\n\n\n<p><a href=\"https://docs.nvidia.com/clara/parabricks/latest/tutorials/cloudguides/benchmarkingguide.html\">Explore the quick start guide</a> to learn more about benchmarking Parabricks germline workflows with Complete Genomics data.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"625\" height=\"570\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-625x570.png\" alt=\"The Complete Genomics DNBSEQ-T7 sequencer. \n\" class=\"wp-image-91229\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-625x570.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-300x273.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-126x115.png 126w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-768x700.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-1536x1400.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-2048x1866.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-645x588.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-329x300.png 329w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-99x90.png 99w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-362x330.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-121x110.png 121w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/complete-genomics-sequencer-1024x933.png 1024w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 2. The Complete Genomics DNBSEQ-T7 sequencer. Image credit: Complete Genomics</em></em></figcaption></figure>\n\n\n\n<h3 id=\"basepair\"  class=\"wp-block-heading\">Basepair<a href=\"#basepair\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p><a href=\"https://www.basepairtech.com/\">Basepair</a> is a next-generation sequencing (NGS) data analysis platform. Their point-and-click user interface helps make genomic data analysis and visualization more accessible to a broader range of scientists.&nbsp;</p>\n\n\n\n<p>Now, users can supercharge their genomic data analysis by using Parabricks on Basepair, powered by HealthOmics from AWS. Parabricks on Basepair gives users an intuitive graphical user interface (GUI) with interactive visualizations entirely provisioned within their own AWS account for compute and storage.&nbsp;</p>\n\n\n\n<p>\u201cWe are excited to support Parabricks on Basepair, bringing accelerated tools alongside a more comprehensive and visual way to analyze their genomic data,\u201d says Simon Valentine, chief commercial officer at Basepair. \u201cParabricks provides access to some of the most effective bioinformatics tools available today. By making them available through Basepair\u2019s intuitive point-and-click interface we can work together to make them accessible to an even broader range of scientists.\u201d&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1319\" height=\"971\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair.png\" alt=\"Screenshot of NVIDIA Parabricks running on the Basepair platform, with fields for pipeline, samples, analysis name, and omics.\" class=\"wp-image-91231\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair.png 1319w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-300x221.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-625x460.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-156x115.png 156w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-768x565.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-645x475.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-408x300.png 408w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-122x90.png 122w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-362x266.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-149x110.png 149w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-parabricks-running-on-basepair-1024x754.png 1024w\" sizes=\"(max-width: 1319px) 100vw, 1319px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 3. NVIDIA Parabricks running on the Basepair platform. Image credit: Basepair</em></em></figcaption></figure></div>\n\n\n<h2 id=\"latest_parabricks_benchmarks\"  class=\"wp-block-heading\">Latest Parabricks benchmarks<a href=\"#latest_parabricks_benchmarks\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>In addition to new features and upgrades for each release, NVIDIA continuously works to improve benchmark performance across instruments, tools, and GPUs.&nbsp;&nbsp;</p>\n\n\n\n<p>Table 1 outlines the latest benchmarks on the most popular NVIDIA GPUs for the fastest speed (NVIDIA H100) and lowest cost per sample (NVIDIA L4)\u2013including Giraffe from Parabricks v4.4 and <a href=\"https://developer.nvidia.com/blog/unlock-deeper-insights-of-somatic-mutations-with-deep-learning/\">DeepSomatic from v4.3.1</a>.</p>\n\n\n\n<figure class=\"wp-block-table aligncenter\"><table class=\"has-fixed-layout\"><tbody><tr><td></td><td class=\"has-text-align-center\" data-align=\"center\" colspan=\"2\"><strong>NVIDIA H100&nbsp; GPU</strong><br><strong>Fastest speed</strong></td><td class=\"has-text-align-center\" data-align=\"center\" colspan=\"2\"><strong>NVIDIA L4 GPU</strong><br><strong>Lowest cost per sample</strong></td></tr><tr><td></td><td class=\"has-text-align-center\" data-align=\"center\"><strong>2 GPUs</strong></td><td class=\"has-text-align-center\" data-align=\"center\"><strong>4 GPUs</strong></td><td class=\"has-text-align-center\" data-align=\"center\"><strong>2 GPUs</strong></td><td class=\"has-text-align-center\" data-align=\"center\"><strong>4 GPUs</strong></td></tr><tr><td><strong>Giraffe</strong></td><td class=\"has-text-align-center\" data-align=\"center\">65.8</td><td class=\"has-text-align-center\" data-align=\"center\">42.1</td><td class=\"has-text-align-center\" data-align=\"center\">84.9</td><td class=\"has-text-align-center\" data-align=\"center\">44.7</td></tr><tr><td><strong>DeepSomatic</strong></td><td class=\"has-text-align-center\" data-align=\"center\">56.28</td><td class=\"has-text-align-center\" data-align=\"center\">35.13</td><td class=\"has-text-align-center\" data-align=\"center\">215.53</td><td class=\"has-text-align-center\" data-align=\"center\">108.55</td></tr><tr><td><strong>FQ2BAM (BWA-MEM)</strong></td><td class=\"has-text-align-center\" data-align=\"center\">13.8</td><td class=\"has-text-align-center\" data-align=\"center\">9.15</td><td class=\"has-text-align-center\" data-align=\"center\">48.15</td><td class=\"has-text-align-center\" data-align=\"center\">27.88</td></tr><tr><td><strong>BWA-Meth</strong></td><td class=\"has-text-align-center\" data-align=\"center\">27.43</td><td class=\"has-text-align-center\" data-align=\"center\">15.12</td><td class=\"has-text-align-center\" data-align=\"center\">77.35</td><td class=\"has-text-align-center\" data-align=\"center\">39.77</td></tr><tr><td><strong>DeepVariant</strong></td><td class=\"has-text-align-center\" data-align=\"center\">9.6</td><td class=\"has-text-align-center\" data-align=\"center\">5.82</td><td class=\"has-text-align-center\" data-align=\"center\">23.48</td><td class=\"has-text-align-center\" data-align=\"center\">13.10</td></tr><tr><td><strong>HaplotypeCaller</strong></td><td class=\"has-text-align-center\" data-align=\"center\">10.57</td><td class=\"has-text-align-center\" data-align=\"center\">4.90</td><td class=\"has-text-align-center\" data-align=\"center\">12.00</td><td class=\"has-text-align-center\" data-align=\"center\">7.73</td></tr><tr><td><strong>Mutect2</strong></td><td class=\"has-text-align-center\" data-align=\"center\">25.80</td><td class=\"has-text-align-center\" data-align=\"center\">13.60</td><td class=\"has-text-align-center\" data-align=\"center\">55.8</td><td class=\"has-text-align-center\" data-align=\"center\">32.50</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 1. The latest benchmarks on the most popular NVIDIA GPUs for the fastest speed and lowest cost per sample</em> <em>with performance time in minutes</em></figcaption></figure>\n\n\n\n<p class=\"has-small-font-size\"><em>30x whole genome sequenced for FQ2BAM (BWA-Mem), BWA-Meth, DeepVariant, and Haplotype Caller with Illumina data. <br>50x tumor-normal whole genome sequenced for DeepSomatic and Mutect2 with Illumina data.</em></p>\n\n\n\n<h2 id=\"get_started\"  class=\"wp-block-heading\">Get started<a href=\"#get_started\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>With the NVIDIA Parabricks v4.4 release, scientists and researchers using graph genomes can now access Giraffe for pangenome alignment. Parabricks v4.4 supports the groundbreaking tool from UCSC by powering an accelerated version of Giraffe to help discover new biological insights\u2014now even faster.&nbsp;</p>\n\n\n\n<p>Download <a href=\"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/containers/clara-parabricks?nvid=nv-int-tblg-737311-vt12\">NVIDIA Parabricks</a> to get started with GPU-accelerated genomics analysis and join the conversation on the <a href=\"https://forums.developer.nvidia.com/c/healthcare/parabricks/290\">NVIDIA Parabricks Developer Forum</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>NVIDIA Parabricks is a scalable genomics analysis software suite that solves omics challenges with accelerated computing and deep learning to unlock new scientific breakthroughs. NVIDIA Parabricks v4.4 introduces new features and functionality including accelerated pangenome graph alignment, as announced at the American Society of Human Genetics (ASHG) national meeting.&nbsp; The core new feature of the &hellip; <a href=\"https://developer.nvidia.com/blog/discover-new-biological-insights-with-accelerated-pangenome-alignment-in-nvidia-parabricks/\">Continued</a></p>\n", "protected": false}, "author": 2135, "featured_media": 91236, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1513809", "discourse_permalink": "https://forums.developer.nvidia.com/t/discover-new-biological-insights-with-accelerated-pangenome-alignment-in-nvidia-parabricks/312178", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 696, 3110], "tags": [1910, 453, 2932, 1163], "coauthors": [3857], "class_list": ["post-91220", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-center-cloud", "category-data-science", "category-generative-ai", "tag-bioinformatics-and-genomics", "tag-featured", "tag-large-language-models", "tag-parabricks"], "acf": {"post_industry": ["Healthcare & Life Sciences"], "post_products": ["H100", "Parabricks"], "post_learning_levels": ["General Interest"], "post_content_types": ["News"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/dna.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nJi", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Data Science", "link": "https://developer.nvidia.com/blog/category/data-science/", "id": 696}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91220"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2135"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91220"}], "version-history": [{"count": 17, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91220/revisions"}], "predecessor-version": [{"id": 91445, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91220/revisions/91445"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91236"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91220"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91220"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91220"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91220"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91234, "date": "2024-11-04T09:30:00", "date_gmt": "2024-11-04T17:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91234"}, "modified": "2024-11-14T09:10:49", "modified_gmt": "2024-11-14T17:10:49", "slug": "frictionless-collaboration-and-rapid-prototyping-in-hybrid-environments-with-nvidia-ai-workbench", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/frictionless-collaboration-and-rapid-prototyping-in-hybrid-environments-with-nvidia-ai-workbench/", "title": {"rendered": "Frictionless Collaboration and Rapid Prototyping in Hybrid Environments with NVIDIA AI Workbench"}, "content": {"rendered": "\n<p><a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/overview/introduction.html\">NVIDIA AI Workbench</a> is a free development environment manager that streamlines data science, AI, and machine learning (ML) projects on systems of choice. The goal is to provide a frictionless way to create, compute, and collaborate on and across PCs, workstations, data centers, and clouds. The basic user experience is straightforward:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Easy setup on single systems: </strong>Click through install in minutes on Windows, Ubuntu, and macOS, with a one-line install on remote systems.</li>\n\n\n\n<li><strong>Managed experience for decentralized deployment</strong>: A free, PaaS/SaaS type UX in truly hybrid contexts with no need for a centralized, service-based platform.&nbsp;</li>\n\n\n\n<li><strong>Seamless collaboration for experts and beginners:</strong> Friendly Git, container, and application management without limiting customization by power users.</li>\n\n\n\n<li><strong>Consistent across users and systems: </strong>Migrate workloads and applications across different systems while maintaining functionality and user experience.&nbsp;</li>\n\n\n\n<li><strong>Simplified GPU handling</strong>: Handles system dependencies like <a href=\"https://docs.nvidia.com/datacenter/tesla/driver-installation-guide/index.html#ubuntu\">NVIDIA drivers</a> and the <a href=\"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html\">NVIDIA Container Toolkit</a>, as well as <a href=\"https://docs.nvidia.com/deeplearning/frameworks/user-guide/index.html\">GPU-enabled container</a> runtime configuration.</li>\n</ul>\n\n\n\n<p>This post explores highlights of the October release of NVIDIA AI Workbench, which is the most significant since the product launch at GTC 2024 and is a big step closer to the full product vision.</p>\n\n\n\n<h2 id=\"release_highlights\"  class=\"wp-block-heading\">Release highlights<a href=\"#release_highlights\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>This section will detail the major new capabilities and user-requested updates in the latest release. </p>\n\n\n\n<p>Major new capabilities include:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Enhance collaboration through expanded Git support, such as branching, merging, diffs, and finer-grained control for commits and gitignore.</li>\n\n\n\n<li>Create complex applications and workflows with multicontainer environments through Docker Compose support.</li>\n\n\n\n<li>Simple, fast, and secure rapid prototyping with application sharing with single-user URLs.</li>\n</ul>\n\n\n\n<p>User requested updates:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Dark mode for the Desktop App</li>\n\n\n\n<li>Improved installation on localized versions of Windows</li>\n</ul>\n\n\n\n<h3 id=\"expanded_git_support\"  class=\"wp-block-heading\">Expanded Git support<a href=\"#expanded_git_support\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Previously, AI Workbench supported only single, monolithic commits on the main branch. Users had to manage branches and merges manually, and this created various types of confusion, especially around resolving merge conflicts. Now, users can manage branches, merges, and conflicts directly in the Desktop App and the CLI. In addition, they can see and triage individual file diffs for commits. The UI is built to work seamlessly with manual Git operations and will update to reflect relevant changes.&nbsp;&nbsp;&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"3825\" height=\"2244\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1.jpg\" alt=\"A screenshot of the AI Workbench Desktop App tab for Git branching showing two different branches. \" class=\"wp-image-91258\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1.jpg 3825w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-300x176.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-625x367.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-179x105.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-768x451.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-1536x901.jpg 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-2048x1201.jpg 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-645x378.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-500x293.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-153x90.jpg 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-362x212.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-188x110.jpg 188w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-desktop-app-git-branching-1-1024x601.jpg 1024w\" sizes=\"(max-width: 3825px) 100vw, 3825px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. AI Workbench Desktop App tab for Git branching</em></em></figcaption></figure></div>\n\n\n<p>These features are found in two new tabs on the Desktop App: Changes and Branches.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Changes</strong>: Gives a line-by-line view of the diffs between the working tree and previous commits. Users can now select and commit file changes individually or in bulk based on visible file diffs tracked changes (addition, modification, or deletion), as well as being able to individually reject or add a file to git-ignore. The view also updates dynamically to reflect manual Git actions, for example manually staging a file and then following up with a change to the file in the working tree.</li>\n\n\n\n<li><strong>Branches</strong>: Provides branch management, including creation, switching, and merging, as well as visibility for remote branches on a Git server. Merging branches with a conflict initiates a conflict resolution flow that users can do within the UI, or move to a terminal or file editor of their choice.&nbsp;</li>\n</ul>\n\n\n\n<p><a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/git/git.html\">Learn more about how these advanced Git features work</a>.</p>\n\n\n\n<h3 id=\"multicontainer_support_with_docker_compose_stacks\"  class=\"wp-block-heading\">Multicontainer support with Docker Compose stacks<a href=\"#multicontainer_support_with_docker_compose_stacks\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>AI Workbench now supports <a href=\"https://docs.docker.com/compose/\">Docker Compose</a>. Users can work with multicontainer applications and workflows with the same ease of configuration, reproducibility, and portability that AI Workbench provides for single-container environments.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"3819\" height=\"2247\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1.jpg\" alt=\"Screenshot of a graphical UI showing affordances for adding a Docker Compose file to an AI Workbench Project.\" class=\"wp-image-91260\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1.jpg 3819w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-300x177.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-625x368.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-179x105.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-768x452.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-1536x904.jpg 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-2048x1205.jpg 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-645x380.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-500x294.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-153x90.jpg 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-362x213.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-187x110.jpg 187w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ai-workbench-environment-management-tab-docker-compose-1-1024x602.jpg 1024w\" sizes=\"(max-width: 3819px) 100vw, 3819px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 2. The Docker Compose feature in the AI Workbench Environment Management tab</em></em></figcaption></figure></div>\n\n\n<p>The basic idea is to add a Docker Compose-based \u201cstack\u201d that is managed by AI Workbench and connects to the main development container. To add the stack, a user just needs to add the appropriate Docker Compose file to the project repository and do some configuration in the Desktop App or CLI.</p>\n\n\n\n<p>We\u2019re using Docker Compose for a few reasons. First, we didn\u2019t want to develop in a vacuum, and that\u2019s why we\u2019ve been <a href=\"https://www.docker.com/blog/optimizing-ai-application-development-docker-desktop-nvidia-ai-workbench/\">collaborating with the Docker team</a> on features like a <a href=\"https://developer.nvidia.com/blog/nvidia-ai-workbench-simplifies-using-gpus-on-windows/\">managed Docker Desktop install</a>.&nbsp;</p>\n\n\n\n<p>Second, we want users to be able to work with the multicontainer applications outside of AI Workbench, and Docker Compose is the easiest way to do that. The vision for this feature is to enable streamlined, powerful development and compute for multicontainer applications within AI Workbench that can then be stood up outside of AI Workbench with a simple <code>docker-compose</code> up command.&nbsp;</p>\n\n\n\n<p>This multicontainer feature is new and will continue to evolve. We would love to get feedback and help you sort out any issues through the <a href=\"https://forums.developer.nvidia.com/c/ai-data-science/nvidia-ai-workbench/671\">NVIDIA AI Workbench Developer Forum</a>.&nbsp;</p>\n\n\n\n<p><a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/projects/compose.html\">Learn more about how Docker Compose works</a>.</p>\n\n\n\n<h3 id=\"web_application_sharing_through_secure_urls\"  class=\"wp-block-heading\">Web application sharing through secure URLs<a href=\"#web_application_sharing_through_secure_urls\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>AI Workbench enables users to easily spin up managed web applications that are built into a project. The process is fairly simple: create or clone a project with the web app installed, start the project, then start the app, and it appears in your browser.&nbsp;</p>\n\n\n\n<p>This approach is great for a developer UX, but it wasn\u2019t good for rapid prototyping UX and collaboration. If you wanted another user to access and test your application, you either asked them to install AI Workbench, clone the project and run it, or you had to fully extract the application to run it and make it available to the user. The first is a speed bump for the user, and the second is a speed bump for the developer.&nbsp;</p>\n\n\n\n<p>We eliminated these speed bumps with a simple feature that enables you to set a remote AI Workbench to enable external access and to create single-use, secure URLs for running web applications in a project on that remote. You just need to make sure the user has access to port 10000 on the remote, and the application will be directly accessible. All they have to do is click the link and go to the app.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"3777\" height=\"2166\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1.jpg\" alt=\"A command line interface with AI Workbench commands showing how to open a project, start JupyterLab and then generate a URL to share JupyterLab with another user.\n\" class=\"wp-image-91262\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1.jpg 3777w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-300x172.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-625x358.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-179x103.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-768x440.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-1536x881.jpg 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-2048x1174.jpg 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-645x370.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-500x287.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-157x90.jpg 157w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-362x208.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-192x110.jpg 192w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cli-ai-workbench-1-1024x587.jpg 1024w\" sizes=\"(max-width: 3777px) 100vw, 3777px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 3. Developers can now give end users direct access to applications running in an AI Workbench Project on a remote through secure, one-time-use URLs</em></em></figcaption></figure>\n\n\n\n<p>Enabling this kind of access is useful for rapid prototyping and collaboration. That\u2019s why various SaaS offerings provide this as a managed service. The difference with AI Workbench is that you can provide this access on your own resources and in your own network, for example on data center resources or a shared server. It doesn\u2019t have to be in the cloud.&nbsp;</p>\n\n\n\n<p>AI Workbench keeps things secure by restricting this access to a single browser and to a single application that\u2019s running in the project. This means a user can\u2019t share the URL with someone else, and they are constrained to the web app that you shared with them.</p>\n\n\n\n<p><a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/collaborate/app-sharing.html\">Learn more about how application sharing works.</a></p>\n\n\n\n<h3 id=\"dark_mode_and_localized_windows_installation\"  class=\"wp-block-heading\">Dark mode and localized Windows installation<a href=\"#dark_mode_and_localized_windows_installation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Many users requested a dark mode option because it\u2019s easier on the eyes. It\u2019s now available and can be selected through the Settings window that is now available directly from within the Desktop App. <a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/reference/settings.html\">Learn more about how dark mode works</a>.</p>\n\n\n\n<p>Windows users are by far our main demographic for the local installs, and not all Windows users are using the English language pack, and this blocked AI Workbench install due to how we handled some WSL commands. In particular, we\u2019ve had users working in Cyrillic or Chinese that were blocked on Windows. We adjusted how we handle non-English language packs, and it should work well now. If you were previously blocked by this, give it a try now. If it still doesn\u2019t work for you, let us know in the <a href=\"https://forums.developer.nvidia.com/c/ai-data-science/nvidia-ai-workbench/671\">NVIDIA AI Workbench Developer Forum</a> so we can continue to improve this capability.</p>\n\n\n\n<h2 id=\"new_ai_workbench_projects&nbsp;\"  class=\"wp-block-heading\">New AI Workbench projects&nbsp;<a href=\"#new_ai_workbench_projects&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>This release introduces new example projects designed to jumpstart your AI development journey, detailed below.&nbsp; An <a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/overview/projects.html\">AI Workbench project</a> is a structured Git repository that defines a containerized development environment in AI Workbench. AI Workbench projects provide:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Effortless setup and GPU configuration:</strong> Simply clone a project from GitHub or GitLab, and AI Workbench handles the rest with automatic GPU configuration.&nbsp;</li>\n\n\n\n<li><strong>Development integrations: </strong>Seamless support for popular development environments such as Jupyter and VS Code, as well as support for user-configured web applications.</li>\n\n\n\n<li><strong>Containerized and customizable environments:</strong> Projects are containerized, isolated, and easily modifiable. Adapt example projects to suit your specific needs while ensuring consistency and reproducibility.&nbsp;</li>\n</ul>\n\n\n\n<p><a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/quickstart/example-projects.html\">Explore NVIDIA AI Workbench example projects</a>.</p>\n\n\n\n<h3 id=\"multimodal_virtual_assistant_example_project\"  class=\"wp-block-heading\"><strong>Multimodal virtual assistant</strong> <strong>example project</strong><a href=\"#multimodal_virtual_assistant_example_project\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>This project enables users to build their own virtual assistant using a multimodal <a href=\"https://www.nvidia.com/en-us/glossary/retrieval-augmented-generation/\">retrieval-augmented generation (RAG)</a> pipeline with fallback to web search. Users can interact with two RAG-based applications to learn more about AI Workbench, converse with the user documentation, troubleshoot their own installation, or even focus the RAG pipeline to their own, custom product.&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Control-Panel:</strong> Customizable Gradio app for working with product documentation allows uploading webpages, PDFs, images, and videos to a persistent vector store and query them. For inference, users can select between cloud endpoints like on the NVIDIA API Catalog or use self-hosted endpoints to run their own inference.&nbsp;</li>\n\n\n\n<li><strong>Public-Chat:</strong> With product documents loaded, the Gradio app is a simplified, &#8220;read-only&#8221; chatbot that you can share with end users through the new AI Workbench App Sharing feature.&nbsp;</li>\n</ul>\n\n\n\n<div><figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"800\" height=\"450\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/public-chat-web-app-query-virtual-assistant.gif\" alt=\"A GIF demonstrating how a user can submit a query to the virtual assistant and see the generated response.\" class=\"wp-image-91253\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 4. Using the Public-Chat web app, a read-only, pared down chat application that is meant to be more consumable and shareable to end users</em></em></figcaption></figure></div>\n\n\n\n<h3 id=\"competition-kernel_example_project\"  class=\"wp-block-heading\">Competition-Kernel example project<a href=\"#competition-kernel_example_project\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>This project provides an easy, local experience when working on Kaggle competitions. You can easily leverage your local machine or a cloud instance to work on competition datasets, write code, build out models, and submit results, all through AI Workbench. The Competition Kernel project offers:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>A managed experience to develop and test on your own GPUs and set up and customize in minutes.</li>\n\n\n\n<li>Easy version control and tracking of code through GitHub or GitLab and very easy collaboration.</li>\n\n\n\n<li>The power of using a local, dedicated IDE: robust debugging, intelligent code completion, extensive customization options.</li>\n\n\n\n<li>Easy plugin to existing data sources (external or your own).</li>\n\n\n\n<li>No Internet? No problem. Develop while offline.</li>\n</ul>\n\n\n\n<h2 id=\"get_started&nbsp;&nbsp;\"  class=\"wp-block-heading\">Get started&nbsp;&nbsp;<a href=\"#get_started&nbsp;&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>This release of NVIDIA AI Workbench marks a significant step forward in providing a frictionless experience for AI development across GPU systems. New features from this release, including expanded Git support, support for multicontainer environments, and secure web app sharing, streamline developing and collaborating on AI workloads. Explore these features in the three new example projects available with this release or create your own projects.&nbsp;</p>\n\n\n\n<p>To get started with AI Workbench, <a href=\"https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/workbench/\">install the application from the webpage</a>. For more information about installing and updating, see the <a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/installation/windows.html#install-ai-workbench\">NVIDIA AI Workbench documentation</a>.\u00a0</p>\n\n\n\n<p>Explore a range of <a href=\"https://docs.nvidia.com/ai-workbench/user-guide/latest/quickstart/example-projects.html\">NVIDIA AI Workbench example projects</a>, from data science to RAG.</p>\n\n\n\n<p>Visit the <a href=\"https://forums.developer.nvidia.com/c/ai-data-science/nvidia-ai-workbench/671\">NVIDIA AI Workbench Developer Forum</a> to report issues and learn more about how other developers are using AI Workbench.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>NVIDIA AI Workbench is a free development environment manager that streamlines data science, AI, and machine learning (ML) projects on systems of choice. The goal is to provide a frictionless way to create, compute, and collaborate on and across PCs, workstations, data centers, and clouds. The basic user experience is straightforward: This post explores highlights &hellip; <a href=\"https://developer.nvidia.com/blog/frictionless-collaboration-and-rapid-prototyping-in-hybrid-environments-with-nvidia-ai-workbench/\">Continued</a></p>\n", "protected": false}, "author": 1840, "featured_media": 91237, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1513803", "discourse_permalink": "https://forums.developer.nvidia.com/t/frictionless-collaboration-and-rapid-prototyping-in-hybrid-environments-with-nvidia-ai-workbench/312176", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 696, 3110], "tags": [453, 4134, 3613], "coauthors": [3466, 3685, 3227], "class_list": ["post-91234", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-center-cloud", "category-data-science", "category-generative-ai", "tag-featured", "tag-nim-agent-blueprint", "tag-retrieval-augmented-generation-rag"], "acf": {"post_industry": ["General"], "post_products": ["AI Workbench", "NIM"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["Best practice"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llm-visual.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nJw", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91234"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1840"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91234"}], "version-history": [{"count": 18, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91234/revisions"}], "predecessor-version": [{"id": 91438, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91234/revisions/91438"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91237"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91234"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91234"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91234"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91234"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 86011, "date": "2024-11-04T08:00:00", "date_gmt": "2024-11-04T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=86011"}, "modified": "2024-11-14T11:39:51", "modified_gmt": "2024-11-14T19:39:51", "slug": "build-a-video-search-and-summarization-agent-with-nvidia-ai-blueprint", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/build-a-video-search-and-summarization-agent-with-nvidia-ai-blueprint/", "title": {"rendered": "Build a Video Search and Summarization Agent with NVIDIA AI Blueprint"}, "content": {"rendered": "\n<p><em>This post was originally published July 29, 2024 but has been extensively revised with NVIDIA AI Blueprint information.</em></p>\n\n\n\n<p>Traditional video analytics applications and their development workflow are typically built on fixed-function, limited models that are designed to detect and identify only a select set of predefined objects.</p>\n\n\n\n<p>With <a href=\"https://www.nvidia.com/en-us/glossary/generative-ai/\">generative AI</a>, NVIDIA NIM microservices, and foundation models, you can now build applications with fewer models that have broad perception and rich contextual understanding.</p>\n\n\n\n<p>The new class of generative AI models, <a href=\"https://www.nvidia.com/en-us/glossary/vision-language-models/\">vision language models (VLM)</a>, powers <a href=\"https://www.nvidia.com/en-us/use-cases/visual-ai-agents/\">visual AI agents</a> that can understand natural language prompts and perform visual question answering. By combining VLMs, LLMs, and the latest Graph-RAG techniques, you can build a powerful visual AI agent that is capable of long-form video understanding.</p>\n\n\n\n<p>These visual AI agents will be deployed throughout factories, warehouses, retail stores, airports, traffic intersections, and more. They\u2019ll help operations teams make better decisions using richer insights generated from natural interactions.</p>\n\n\n\n<p>In this post, we show you how to seamlessly build an AI agent for long-form video understanding using <a href=\"https://build.nvidia.com/nvidia/video-search-and-summarization\">NVIDIA AI Blueprint for Video Search and Summarization</a>. You can apply for <a href=\"https://developer.nvidia.com/nim-agent-blueprint/video-search-and-summarization-early-access\">early access</a> to this new AI Blueprint.</p>\n\n\n\n<h2 id=\"releasing_nvidia_ai_blueprint_for_video_search_and_summarization\"  class=\"wp-block-heading\">Releasing NVIDIA AI Blueprint for Video Search and Summarization<a href=\"#releasing_nvidia_ai_blueprint_for_video_search_and_summarization\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/EAhe3aqcRQk?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. Build Visual AI Agents with Vision Language Models</em></figcaption></figure>\n\n\n\n<p>NVIDIA AI Blueprints, powered by NVIDIA NIM, are reference workflows for canonical generative AI use cases. <a href=\"https://www.nvidia.com/en-us/ai/#referrer=ai-subdomain\">NVIDIA NIM</a> is a set of microservices that includes industry-standard APIs, domain-specific code, optimized inference engines, and enterprise runtime. It delivers multiple VLMs for building a visual AI agent that can process live or archived images or videos to extract actionable insight using natural language.</p>\n\n\n\n<p>The new <a href=\"https://build.nvidia.com/nvidia/video-search-and-summarization\">AI Blueprint for Video Search and Summarization</a> accelerates the development of visual AI agents by providing a recipe for long-form video understanding using VLMs, LLMs, and the latest RAG techniques.</p>\n\n\n\n<p>To interact with the agent, a set of easy-to-use REST APIs are available to enable video summarization, interactive Q&amp;A over videos, and custom alerts on live streams to find specific events. The REST APIs can be used to integrate the agent into your own application and are used by the reference UI for quick testing.</p>\n\n\n\n<p>The models used in the blueprint can come from the <a href=\"https://build.nvidia.com/explore/discover\">NVIDIA API Catalog</a> of model preview APIs and downloadable NIM microservices. For example, the AI Blueprint uses the NVIDIA-hosted <a href=\"https://build.nvidia.com/meta/llama-3_1-70b-instruct\">llama-3_1-70b-instruct</a> NIM microservice as the LLM for NVIDIA NeMo Guardrails, Context-Aware RAG (CA-RAG), and Graph-RAG modules. You can choose from a wide range of different LLMs and VLMs from the <a href=\"https://build.nvidia.com/explore/vision\">API Catalog</a>, either NVIDIA-hosted or locally deployed.</p>\n\n\n\n<h2 id=\"visual_ai_agent_for_video_search_and_summarization\"  class=\"wp-block-heading\">Visual AI agent for video search and summarization<a href=\"#visual_ai_agent_for_video_search_and_summarization\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Building a visual AI agent capable of understanding long-form videos requires a combination of VLMs and LLMs ensembled together with datastores. The blueprint provides a recipe for combining all of these components to enable scalable and GPU-accelerated video understanding agents that can perform several tasks such as summarization, Q&amp;A, and detecting events on live streaming video.</p>\n\n\n\n<p>The blueprint consists of the following components:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Stream handler:</strong> Manages the interaction and synchronization with the other components such as NeMo Guardrails, CA-RAG, the VLM pipeline, chunking, and the Milvus Vector DB.</li>\n\n\n\n<li><strong>NeMo Guardrails:</strong> Filters out invalid user prompts. It makes use of the REST API of an LLM NIM microservice.</li>\n\n\n\n<li><strong>VLM pipeline</strong> \u2013 Decodes video chunks generated by the stream handler, generates the embeddings for the video chunks using an NVIDIA Tensor RT-based visual encoder model, and then makes use of a VLM to generate per-chunk response for the user query. It is based on the NVIDIA DeepStream SDK.</li>\n\n\n\n<li><strong>VectorDB:</strong> Stores the intermediate per-chunk VLM response.</li>\n\n\n\n<li><strong>CA-RAG module:</strong> Extracts useful information from the per-chunk VLM response and aggregates it to generate a single unified summary. CA-RAG (Context Aware-Retrieval-Augmented Generation) uses the REST API of an LLM NIM microservice.</li>\n\n\n\n<li><strong>Graph-RAG module:</strong> Captures the complex relationships present in the video and stores important information in a graph database as sets of nodes and edges. This is then queried by an LLM for interactive Q&amp;A.</li>\n</ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture.png\"><img loading=\"lazy\" decoding=\"async\" width=\"1015\" height=\"696\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture.png\" alt=\"A diagram shows the architecture of the visual search and summarization agent. It includes the data flow of how videos are processed and used to generate summaries, alerts and Q&amp;A. \" class=\"wp-image-91153\" style=\"width:625px;height:auto\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture.png 1015w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-300x206.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-625x429.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-168x115.png 168w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-768x527.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-645x442.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-438x300.png 438w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-131x90.png 131w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-362x248.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/summarization-vision-ai-agent-architecture-160x110.png 160w\" sizes=\"(max-width: 1015px) 100vw, 1015px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 1. High-level architecture of the summarization vision AI agent</em></figcaption></figure></div>\n\n\n<p>Here\u2019s more information about the video ingestion and retrieval pipeline and how the blueprint is capable of summarization, Q&amp;A, and alerts over live streams and long videos.</p>\n\n\n\n<h3 id=\"video_ingestion\"  class=\"wp-block-heading\">Video ingestion<a href=\"#video_ingestion\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>To summarize a video or perform Q&amp;A, a comprehensive index of the video must be built that captures all the important information. This is done by combining VLMs and LLMs to produce dense captions and metadata to build a knowledge graph of the video. This video ingestion pipeline is GPU-accelerated and scales with more GPUs to lower processing time.</p>\n\n\n\n<h4 class=\"wp-block-heading\">VLM pipeline and CA-RAG</h4>\n\n\n\n<p>Most VLMs today accept only a limited number of frames, for example, 8/10/100. They also can\u2019t accurately generate captions for longer videos. For longer videos such as hour-long videos, sampled frames could be 10s of seconds apart or even longer. This can result in some details getting missed or actions not getting recognized.</p>\n\n\n\n<p>A solution to this problem is to create smaller chunks from long videos, analyze the chunks individually using VLMs to produce dense captions, and then summarize and aggregate results to generate a single summary for the entire file. This part of the ingestion process is the VLM pipeline and CA-RAG module.&nbsp;</p>\n\n\n\n<p>This strategy of chunking and captioning can also be applied to live streams. The blueprint includes a streaming pipeline that receives streaming data from an RTSP server. The NVIDIA AI Blueprint continuously generates video-chunk segments based on the user-configured chunk duration. The VLM pipeline then generates the captions for these chunks.</p>\n\n\n\n<p>The NVIDIA AI Blueprint keeps on gathering the captions from the VLM pipeline. When enough chunks are processed based on the user-configured summary duration, the chunks gathered are sent to CA-RAG for summarization and aggregation. The blueprint continues processing the next chunks. The summaries are streamed to the client using HTTP server-sent events.</p>\n\n\n\n<h4 class=\"wp-block-heading\">Knowledge graph and Graph-RAG module&nbsp;</h4>\n\n\n\n<p>To capture the complex information produced by the VLM, a knowledge graph is built and stored during video ingestion. Use an LLM to convert the dense captions in a set of nodes, edges, and associated properties. This knowledge graph is stored in a graph database. By using Graph-RAG techniques, an LLMcan access this information to extract key insights for summarization, Q&amp;A, and alerts and go beyond what VLMs&nbsp;are capable of on their own.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"948\" height=\"568\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video.png\" alt=\"Diagram shows orange and purple circles connected by action words. Worker carrying box, worker dropped box, person inspects restricted zone, and box near pallets are some examples.\" class=\"wp-image-91145\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video.png 948w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-300x180.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-625x374.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-179x107.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-768x460.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-645x386.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-500x300.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-150x90.png 150w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-362x217.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/knowledge-graph-warehouse-video-184x110.png 184w\" sizes=\"(max-width: 948px) 100vw, 948px\" /><figcaption class=\"wp-element-caption\"><em>Figure 3. The knowledge graph produced from a short warehouse video</em></figcaption></figure></div>\n\n\n<h3 id=\"video_retrieval&nbsp;\"  class=\"wp-block-heading\">Video retrieval&nbsp;<a href=\"#video_retrieval&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>When the video has been ingested, the databases behind the CA-RAG and Graph-RAG modules contain an immense amount of information about the objects, events, and descriptions of what occurred in the video. This information can be queried and consumed by an LLM for several tasks, including summarization, Q&amp;A, and alerts. </p>\n\n\n\n<p>For each of these tasks, the blueprint exposes simple REST APIs that can be called to integrate with your application. A reference UI is also provided to enable you to quickly experiment with the features of the blueprint and tune the agent with several configuration options.</p>\n\n\n\n<h3 id=\"summarization\"  class=\"wp-block-heading\">Summarization<a href=\"#summarization\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>When a video file has been uploaded to the agent through the APIs, call the <code>summarize</code> endpoint to get a summary of the video. The blueprint takes care of all the heavy lifting while providing a lot of configurable parameters.</p>\n\n\n\n<p>When submitting the <code>summarize</code> request, there are prompts used to tune the outputs. This controls the VLM dense captioning and the LLM-based caption aggregation to produce the final summary.&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Prompt (VLM):</strong> Prompt given to the VLM to produce dense captions. This prompt can be tuned to tell the VLM exactly what type of objects, events, and actions it should pay attention to.&nbsp;&nbsp;</li>\n\n\n\n<li><strong>Caption summarization (LLM):</strong> An LLM prompt used to combine the VLM captions. This can be used to control how fine-grained the captions should be and the level of detail to include.&nbsp;</li>\n\n\n\n<li><strong>Summary aggregation (LLM):</strong> Produces the final summary output based on the aggregated captions. This prompt should be tuned to specify an output format, length of the summary, and a list of any key pieces of information that should be included in the output.&nbsp;</li>\n</ul>\n\n\n\n<p>In addition to the prompt configuration, the strategy to chunk the video is also important to tune based on your use case. There are a few different options depending on whether the summarization is over a video file or a live stream.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">Video files</h4>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>chunk_duration</code>: The entire video is divided into <code>chunk_duration</code> length segments, <em>N</em> (VLM-dependent) frames are sampled from this chunk and sent to VLM for inference. The chunk duration should be small enough that the <em>N</em> frames can capture the event.</li>\n\n\n\n<li><code>chunk_overlap</code>: If an event occurs at the chunk intersection, then the sampled frames might not capture the complete event and the model can\u2019t detect it. The NVIDIA AI Blueprint alleviates this problem by using a sliding window approach where <code>chunk_overlap</code> is the overlap duration between the chunks. (Default: <code>0</code>).</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\">Streams</h4>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>chunk_duration</code>: Similar to video files, the live stream is divided into segments of <code>chunk_duration</code> and sent to VLM for inference. The chunk duration should be small enough that the <em>N</em> frames can capture the event.</li>\n\n\n\n<li><code>summary_duration</code>: The duration for which the user wants a summary. This enables the user to control the duration of the stream for which the summary should be produced. For instance, if <code>chunk_duration</code> is 1 min and the summary duration is 30 min., then the stream is divided into 1-min. chunks for VLM inference. The VLM output of 30 chunks is aggregated to provide the user with a 30-min. concise summary.</li>\n</ul>\n\n\n\n<p>These are just guidelines and the actual parameter must be tuned for specific use cases. It\u2019s a tradeoff between accuracy and performance. Smaller chunk sizes result in better descriptions but take longer to process.</p>\n\n\n\n<h3 id=\"q&amp;a\"  class=\"wp-block-heading\">Q&amp;A<a href=\"#q&amp;a\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The knowledge graph built during video ingestion can be queried by an LLM to provide a natural language interface into the video. This enables users to ask open-ended questions over the input video and have a chatbot experience. In the reference UI, this feature is available after the video has been ingested.&nbsp;</p>\n\n\n\n<p>The LLM used to power Q&amp;A is configurable and can be adjusted through the blueprint configuration after deployment. It gives you the control to choose a model that best suits your local deployment or point it to an LLM deployed in the cloud.&nbsp;</p>\n\n\n\n<p>The prompts given to the LLM to retrieve the information needed from the knowledge are adjustable and can be tuned to improve the accuracy of the responses.&nbsp;</p>\n\n\n\n<h3 id=\"alerts\"  class=\"wp-block-heading\">Alerts<a href=\"#alerts\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>In addition to video files, the blueprint can also accept a video live stream as input. For live streaming use cases, it is often critical to know when certain events take place in near real-time. To accomplish this, the blueprint enables live streams to be registered and alert rules can be set to monitor the stream. These alert rules are in natural language and are used to trigger notifications when user-defined events occur.&nbsp;</p>\n\n\n\n<p>For example, a camera set in a forest could be set with alert rules to detect when animals come into view or if a fire breaks out. When the stream is registered and the alert rules are set, the agent monitors the stream. If it detects that any of the alert rules are true, then it triggers a notification that can be received through the APIs.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/N1UOqr7Ga_A?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 2. Build Visual AI Agents for Video Search and Summarization</em></figcaption></figure>\n\n\n\n<h2 id=\"getting_started\"  class=\"wp-block-heading\">Getting started<a href=\"#getting_started\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Build powerful VLM-based AI agents using <a href=\"https://build.nvidia.com/nvidia/video-search-and-summarization\">NVIDIA AI Blueprint for Video Search and Summarization</a>. REST APIs provide ease of integration of this workflow and VLMs in existing customer applications. Apply for <a href=\"https://developer.nvidia.com/ai-blueprint-for-video-search-and-summarization-early-access/join\">early access to this AI Blueprint</a> now and see the <a href=\"https://forums.developer.nvidia.com/c/accelerated-computing/intelligent-video-analytics/visual-ai-agent/680\">Visual AI Agents forum</a> for technical questions.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>This post was originally published July 29, 2024 but has been extensively revised with NVIDIA AI Blueprint information. Traditional video analytics applications and their development workflow are typically built on fixed-function, limited models that are designed to detect and identify only a select set of predefined objects. With generative AI, NVIDIA NIM microservices, and foundation &hellip; <a href=\"https://developer.nvidia.com/blog/build-a-video-search-and-summarization-agent-with-nvidia-ai-blueprint/\">Continued</a></p>\n", "protected": false}, "author": 1925, "featured_media": 86302, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1457517", "discourse_permalink": "https://forums.developer.nvidia.com/t/build-vlm-powered-visual-ai-agents-using-nvidia-nim-and-nvidia-via-microservices/301586", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724, 3110, 63], "tags": [3965, 2932, 3737, 3953], "coauthors": [3616, 3948, 3949, 3950, 3951, 3952, 995, 1095, 564], "class_list": ["post-86011", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-computer-vision", "category-generative-ai", "category-robotics", "tag-ai-agent", "tag-large-language-models", "tag-microservices", "tag-vlms"], "acf": {"post_industry": ["Healthcare & Life Sciences", "Manufacturing", "Smart Cities / Spaces"], "post_products": ["Metropolis", "NIM"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/07/via-microservices-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-mnh", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Computer Vision / Video Analytics", "link": "https://developer.nvidia.com/blog/category/computer-vision/", "id": 2724}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/86011"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1925"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=86011"}], "version-history": [{"count": 12, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/86011/revisions"}], "predecessor-version": [{"id": 91431, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/86011/revisions/91431"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/86302"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=86011"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=86011"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=86011"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=86011"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91412, "date": "2024-11-01T15:00:36", "date_gmt": "2024-11-01T22:00:36", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91412"}, "modified": "2024-11-14T09:10:52", "modified_gmt": "2024-11-14T17:10:52", "slug": "3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot/", "title": {"rendered": "3x Faster AllReduce with NVSwitch and TensorRT-LLM MultiShot"}, "content": {"rendered": "\n<p>Deploying generative AI workloads in production environments where user numbers can fluctuate from hundreds to hundreds of thousands \u2013 and where input sequence lengths differ with each request \u2013 poses unique challenges. To achieve low latency inference in these environments, multi-GPU setups are a must &#8211; irrespective of the GPU generation or its memory capacity. To enhance inference performance in production-grade setups, we&#8217;re excited to introduce TensorRT-LLM Multi-shot, a new multi-GPU communication protocol that leverages the <a href=\"https://www.nvidia.com/en-us/data-center/nvlink/?srsltid=AfmBOortYFyQ2kE7Y-h-aY4CEDLdD7bG2KMG71bGYLNCdIbCeoq9nns2\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA NVLink Switch</a> to significantly increase communication speeds by up to 3x. This blog outlines this new feature and how it helps developers and solution architects address the limitations of traditional multi-GPU communication methods.</p>\n\n\n\n<h3 id=\"challenges_with_traditional_allreduce_algorithms\"  class=\"wp-block-heading\">Challenges with traditional AllReduce algorithms<a href=\"#challenges_with_traditional_allreduce_algorithms\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>For low latency inference, multi-GPU is critical, regardless of the memory capacity of a single GPU. However, at low concurrency, the time GPUs spend exchanging data can outweigh the time spent on compute. For optimal performance, an efficient <a href=\"https://docs.nvidia.com/doca/archive/doca-v1.3/allreduce/index.html#:~:text=Allreduce%20is%20a%20collective%20operation,Allreduce%20operates%20in%20stages.\">AllReduce</a> operation \u2013 a collective operation that combines partial results from each participating GPU \u2013 is critical.</p>\n\n\n\n<p>Traditional approaches use ring-based algorithms, where the partial values are passed around a ring of GPUs.&nbsp; Each GPU contributes its values and passes the result to its neighbor. This process is repeated 2N-2 times where N is the number of GPUs working together, and by the end of the process, every GPU has the same summed value. A second pass over the ring is required to propagate summed values from the last GPU to the rest.&nbsp;</p>\n\n\n\n<p>The Ring approach makes efficient use of available GPU-to-GPU bandwidth per communication step, but as the number of GPUs increases, so does the number of steps. This increases latency, as all GPUs need to stay synchronized at every step of the ring. \u200cThese synchronization latencies add significant latency overhead and can make it difficult to meet more stringent latency targets.&nbsp;</p>\n\n\n\n<p>The Ring AllReduce algorithm is described below:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Ring Algorithm:\u00a0 GPU-1 \u2192 GPU-2 \u2192 \u2026 \u2192 GPU-N \u2192 GPU-1 \u2192 GPU-2 \u2192 \u2026 \u2192 GPU-(N-1)</li>\n\n\n\n<li>2N-2 steps, with full tensor send/recv each step</li>\n\n\n\n<li>Latency: 2N-2 communication steps.\u00a0 (N: # of GPUs)</li>\n\n\n\n<li>Traffic: (4N-4)/N tensor bytes of send/recvs</li>\n</ul>\n\n\n\n<h3 id=\"addressing_allreduce_communication_challenges_with_tensorrt-llm_multishot\"  class=\"wp-block-heading\">Addressing AllReduce communication challenges with TensorRT-LLM MultiShot<a href=\"#addressing_allreduce_communication_challenges_with_tensorrt-llm_multishot\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>TensorRT-LLM MultiShot is a new algorithm that reduces the O(N) latency of Ring AllReduce by up to 3x leveraging multicast in NVSwitch. Multicast is a hardware acceleration feature in NVSwitch which allows a GPU to send data once and have that data sent simultaneously to all other GPUs, minimizing the number of communication steps to two inter-GPU synchronizations while remaining bandwidth efficient. Without NVSwitch, this would take N times the communication bandwidth.&nbsp;</p>\n\n\n\n<p>TensorRT-LLM Multishot separates the AllReduce into a ReduceScatter operation followed by an AllGather operation (for more detailed descriptions of collective operations, see this <a href=\"https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/collectives.html\">documentation</a>).</p>\n\n\n\n<p>Each GPU is responsible for accumulating only a portion of the result tensor.&nbsp;</p>\n\n\n\n<p>The first step (or \u201cshot\u201d) involves each GPU sending the different slices of the tensor to the respective GPU responsible for accumulating that slice of the tensor.</p>\n\n\n\n<p>After accumulating locally, each GPU now has the correct sum accumulators for its unique slice of the output.</p>\n\n\n\n<p>In the second step (or \u201cshot\u201d), each GPU broadcasts the result slice to all other GPUs using the NVSwitch multicast capability. This minimizes the per GPU bandwidth required as the NVSwitch itself performs data amplification; each GPU sends 1/N the data and receives the full result tensor in one step.</p>\n\n\n\n<p>The entire operation only takes two communication steps, regardless of the number GPUs performing tensor parallel inference.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>TensorRT-LLM MultiShot Algorithm: GPU_N sends slices, Compute slice sum, broadcast result in single multicast operation.</li>\n\n\n\n<li>Latency: 2 communication steps (regardless of number of GPUs)</li>\n\n\n\n<li>Traffic: 2 tensor bytes of send/recv (regardless of number of GPUs)</li>\n</ul>\n\n\n\n<h3 id=\"why_this_matters\"  class=\"wp-block-heading\">Why this matters<a href=\"#why_this_matters\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Since this algorithm requires only two communication steps rather than 2N-2 (where N is the number of GPUs), MultiShot can be nearly 3x faster than Ring AllReduce. The benefits of this algorithm are particularly evident with smaller message sizes and high parallelism \u2013 the scenario needed when minimum latency is required for a great user experience.&nbsp;</p>\n\n\n\n<p>This can be used to either reduce minimum latency, or increase throughput at a given latency. In scenarios with more aggressive latency thresholds, this can lead to super-linear scaling with the number of GPUs.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1884\" height=\"1194\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X.png\" alt=\"A chart showing the reduction in latency that TensorRT-LLM MultiShot provides across message sizes.\u00a0\" class=\"wp-image-91413\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X.png 1884w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-300x190.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-625x396.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-179x113.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-768x487.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-1536x973.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-645x409.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-473x300.png 473w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-142x90.png 142w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-362x229.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-174x110.png 174w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/Figure-1.-With-TensorRT-LLM-MultiShot-AllReduce-latency-is-reduced-by-up-to-3X-1024x649.png 1024w\" sizes=\"(max-width: 1884px) 100vw, 1884px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. With TensorRT-LLM MultiShot, AllReduce latency is reduced by up to 3x.</em></figcaption></figure></div>\n\n\n<p>Achieving optimal inference performance requires careful workload analysis and a deep understanding of performance bottlenecks. By gaining that understanding \u2013 both through internal engineering work as well as through close collaboration with external developers and researchers \u2013 we can quickly and frequently optimize many aspects of our platform to deliver great performance for users.</p>\n\n\n\n<p>As we continue to identify and implement new performance optimizations \u2013 some may be extensive, others might be narrower in scope \u2013&nbsp; we will be providing regular updates on these optimizations, providing both technical motivation and quantified benefits.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Deploying generative AI workloads in production environments where user numbers can fluctuate from hundreds to hundreds of thousands \u2013 and where input sequence lengths differ with each request \u2013 poses unique challenges. To achieve low latency inference in these environments, multi-GPU setups are a must &#8211; irrespective of the GPU generation or its memory capacity. &hellip; <a href=\"https://developer.nvidia.com/blog/3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot/\">Continued</a></p>\n", "protected": false}, "author": 2408, "featured_media": 88129, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1512982", "discourse_permalink": "https://forums.developer.nvidia.com/t/3x-faster-allreduce-with-nvswitch-and-tensorrt-llm-multishot/311952", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [4150, 3110, 1903], "tags": [296, 453, 4159], "coauthors": [4157, 506, 2940, 2732, 3708], "class_list": ["post-91412", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-deployment", "category-generative-ai", "category-features", "tag-ai-inference-microservices", "tag-featured", "tag-inference-performance"], "acf": {"post_industry": ["General", "Cloud Services"], "post_products": ["NVLink", "NVSwitch", "TensorRT", "TensorRT-LLM"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/08/HGX-H200-tech-blog-1920x1080-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nMo", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91412"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2408"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91412"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91412/revisions"}], "predecessor-version": [{"id": 91422, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91412/revisions/91422"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/88129"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91412"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91412"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91412"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91412"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91198, "date": "2024-10-31T13:24:07", "date_gmt": "2024-10-31T20:24:07", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91198"}, "modified": "2024-11-14T09:10:53", "modified_gmt": "2024-11-14T17:10:53", "slug": "even-faster-and-more-scalable-umap-on-the-gpu-with-rapids-cuml", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/even-faster-and-more-scalable-umap-on-the-gpu-with-rapids-cuml/", "title": {"rendered": "Even Faster and More Scalable UMAP on the GPU with RAPIDS cuML"}, "content": {"rendered": "\n<p><a href=\"https://umap-learn.readthedocs.io/en/latest/\">UMAP</a> is a popular dimension reduction algorithm used in fields like bioinformatics, NLP topic modeling, and ML preprocessing. It works by creating a k-nearest neighbors (k-NN) graph, which is known in literature as an all-neighbors graph, to build a fuzzy topological representation of the data, which is used to embed high-dimensional data into lower dimensions.&nbsp;</p>\n\n\n\n<p><a href=\"https://github.com/rapidsai/cuml\">RAPIDS cuML</a> already contained an accelerated UMAP, which provided significant speed improvements over the original CPU-based UMAP. As we demonstrate in this post, there was still room for improvement.&nbsp;</p>\n\n\n\n<p>In this post, we explore how to use the new features introduced in RAPIDS cuML 24.10. We also dive into the details of the nn-descent algorithm and the batching process. Finally, we share benchmark results to highlight possible performance gains. By the end of this post, we hope you are excited about the benefits that RAPIDS\u2019 faster and scalable UMAP can provide.</p>\n\n\n\n<h2 id=\"challenges\"  class=\"wp-block-heading\">Challenges<a href=\"#challenges\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>One challenge we faced is that the all-neighbors graph-building phase takes a long time, especially in comparison to the other steps in the UMAP algorithm.&nbsp;</p>\n\n\n\n<p>cuML UMAP initially used only a <a href=\"https://docs.rapids.ai/api/cuvs/stable/python_api/neighbors_brute_force/\">brute-force</a> approach to compute the all-neighbors graph, which is usually referred to in literature as an <em>all-neighbors graph</em> because it involves an exhaustive vector search over all vectors in the dataset.&nbsp;</p>\n\n\n\n<p>Because it exhaustively computes distances for every pair of vectors in the dataset, brute force tends to have poor scaling. Thus, as the number of vectors in the dataset grows, the amount of time spent in this step grows quadratically (number of vectors to the power of 2) as compared to all the other steps in UMAP.&nbsp;</p>\n\n\n\n<p>Figure 1 shows the proportion of time spent in the all-neighbors graph construction for several popular datasets. The proportion spent in all-neighbors graph construction quickly becomes 99% and higher at the 1M and 5M vector scales.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1000\" height=\"250\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors.png\" alt=\"Four pie charts demonstrate the proportions of the amount of time the UMAP algorithm spends computing the all-neighbors graph compared to the time spent computing everything else. For small datasets like MNIST, over half the time (57%) is spent computing the all-neighbors graph, while larger datasets (with 1M and greater vectors) spend over 99% of the time computing the all-neighbors graph.\u00a0\" class=\"wp-image-91203\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors.png 1000w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-300x75.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-625x156.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-179x45.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-768x192.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-645x161.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-500x125.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-160x40.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-362x91.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-building-all-neighbors-440x110.png 440w\" sizes=\"(max-width: 1000px) 100vw, 1000px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Time spent building all-neighbors graph</em></figcaption></figure></div>\n\n\n<p>The second challenge we faced is that, like many algorithms in cuML, the entire dataset had to fit into the memory of the GPU.&nbsp;</p>\n\n\n\n<p>Handling large datasets, such as those that are hundreds of GB in size, can be especially challenging when only a consumer-level NVIDIA RTX GPU is available for processing. Even though the NVIDIA H100 GPU offers 80 GB of memory, this may not be sufficient for an 80-GB dataset because algorithms like UMAP require many little temporary memory allocations that can add up over the course of the algorithm.</p>\n\n\n\n<h2 id=\"accelerating_and_scaling_umap\"  class=\"wp-block-heading\">Accelerating and scaling UMAP<a href=\"#accelerating_and_scaling_umap\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>We have solved these challenges with a novel batched approximate nearest neighbor (ANN) algorithm. While the general approach can apply to any algorithm capability of searching for nearest neighbors, we used a GPU-accelerated version of a fast algorithm called nearest neighbors descent (<a href=\"https://www.cs.princeton.edu/cass/papers/www11.pdf\">nn-descent</a>) from the <a href=\"https://github.com/rapidsai/cuvs\">RAPIDS cuVS</a> library, which is great for all-neighbors graph construction.\u00a0</p>\n\n\n\n<p>ANN algorithms accelerate the all-neighbors graph-building process by trading off quality for speed. In general, approximate methods aim to reduce the number of distances that need to be computed to find the nearest neighbors. As this algorithm can compute a single all-neighbors graph in pieces, we could place larger datasets in RAM memory and pull only what we need into the GPU memory when we needed it.&nbsp;</p>\n\n\n\n<p>As we demonstrate in this post, our new approach scales UMAP in RAPIDS cuML 24.10 to massive datasets at lightspeed. What\u2019s better is that it\u2019s enabled by default, so you don\u2019t have to make any changes to your code to reap the benefits!</p>\n\n\n\n<figure class=\"wp-block-table aligncenter is-style-stripes\"><table class=\"has-fixed-layout\"><tbody><tr><td><strong>Matrix size</strong></td><td><strong>Running UMAP with brute-force</strong></td><td><strong>Running UMAP with nn-descent</strong></td></tr><tr><td>1M x 960</td><td>214.4s</td><td>9.9s (21.6x speedup)</td></tr><tr><td>8M x 384</td><td>2191.3s</td><td>34.0s (54.4x speedup)</td></tr><tr><td>10M x 96</td><td>2170.8s</td><td>53.4s (40.6x speedup)</td></tr><tr><td>20M x 384</td><td>38350.7s</td><td>122.9 (312x speedup)</td></tr><tr><td>59M x 768</td><td>Error: out of memory</td><td>575.1</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 1. Comparison of end-to-end runtime (seconds) of running UMAP with nn-descent and brute force as its all-neighbors graph-building algorithm</em></figcaption></figure>\n\n\n\n<p>Table 1 shows that UMAP can now run with datasets that don\u2019t fit on the device (50M, 768 is 153 GB). Speedup gain increases for large datasets. What used to take 10 hours to run on the GPU can be run in 2 minutes.</p>\n\n\n\n<h2 id=\"using_faster_and_scalable_umap_in_rapids_cuml\"  class=\"wp-block-heading\">Using faster and scalable UMAP in RAPIDS cuML<a href=\"#using_faster_and_scalable_umap_in_rapids_cuml\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>As mentioned earlier, no code changes are required as of cuML 24.10 to take advantage of this new feature.&nbsp;</p>\n\n\n\n<p>However, for more control, the UMAP estimator now accepts two more parameters during initialization:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>build_algo</code>: Algorithm to build the all-neighbors graph. It can be one of the following three values:\n<ul class=\"wp-block-list\">\n<li><code>auto</code>: Decides to build with brute force or nn-descent during runtime depending on the dataset size (>50K data samples uses nn-descent). Default value.</li>\n\n\n\n<li><code>brute_force_knn</code>: Builds all-neighbors graph using brute force.</li>\n\n\n\n<li><code>nn_descent</code>: Builds all-neighbors graph using nn-descent.</li>\n</ul>\n</li>\n\n\n\n<li><code>build_kwds</code>: Python dictionary type for passing parameters related to all-neighbors graph building, with the following parameters:\n<ul class=\"wp-block-list\">\n<li><code>nnd_graph_degree</code>: Graph degree when building k-nn with nn-descent. Default: <code>64</code>.</li>\n\n\n\n<li><code>nnd_intermediate_graph_degree</code>: Intermediate graph degree when building k-NN with nn-descent. Default: <code>128</code>.</li>\n\n\n\n<li><code>nnd_max_iterations</code>: Maximum number of iterations to run nn-descent. Default: <code>20</code>.</li>\n\n\n\n<li><code>nnd_termination_threshold</code>: Termination threshold to early stop nn-descent iterations. Default: <code>0.0001</code>.</li>\n\n\n\n<li><code>nnd_return_distances</code>: Whether to return distances from nn-descent. This should be set to true to use nn-descent with UMAP. Default: <code>True.</code></li>\n\n\n\n<li><code>nnd_n_clusters</code>: Number of clusters to use for the batching approach. A larger number of clusters reduces memory usage when running with larger datasets. Default: <code>2</code>.</li>\n\n\n\n<li><code>nnd_do_batch</code>: Should be set to <code>True</code> for batching. Default: <code>False</code>.</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p>You can also choose to put the data on the host instead of putting the entire data on the device using the <code>data_on_host</code> option which defaults to <code>False</code>. This is only compatible with <code>build_algo=\u201dnn_descent\u201d</code> and is not supported for building with the brute-force algorithm. </p>\n\n\n\n<p>We recommend that you put data on the host to get the most out of our batching algorithm for large datasets.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nfrom cuml.manifold.umap import UMAP\n\ndata = generate_data()\n\n# running default. Runs with NN Descent if data has more than 50K points\numap = UMAP(n_neighbors=16)\nemb\u00a0 = umap.fit_transform(data)\n\n# explicitly set build algo. Runs with this regardless of the data size. Data can be put on host\numap = UMAP(n_neighbors=16, build_algo=&quot;nn_descent&quot;, build_kwds={&quot;nnd_graph_degree&quot;: 32})\nemb = umap.fit_transform(data, data_on_host=True)\n\n# batching NN Descent with 4 clusters\numap = UMAP(n_neighbors=16, build_algo=&quot;nn_descent&quot;, build_kwds={&quot;nnd_do_batch&quot;: True, &quot;nnd_n_clusters&quot;: 4})\nemb = umap.fit_transform(data, data_on_host=True)\n</pre></div>\n\n\n<h2 id=\"why_approximate_nearest_neighbors\"  class=\"wp-block-heading\">Why approximate nearest neighbors?<a href=\"#why_approximate_nearest_neighbors\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Brute-force is an exact and exhaustive algorithm. In contrast, ANN algorithms don\u2019t guarantee finding the exact closest neighbors but they do efficiently navigate the search space to construct an approximation to the nearest neighbors much faster, trading off search speed for accuracy.</p>\n\n\n\n<p>Nearest neighbors descent (nn-descent) is an ANN algorithm that can directly approximate an all-neighbors graph. The algorithm begins by randomly initializing nearest neighbors for each data point before iteratively improving nearest neighbor approximations by exploring each point\u2019s neighbors\u2019 neighbors.\u00a0</p>\n\n\n\n<p>As noted in the <a href=\"https://dl.acm.org/doi/10.1145/1963405.1963487\">original paper</a>, nn-descent \u201ctypically converges to above 90% recall with each point comparing only to several percent of the whole dataset on average\u201d. In short, ANN algorithms generally find clever ways to reduce the number of distances that must be computed.</p>\n\n\n\n<p>We used nn-descent from the <a href=\"https://github.com/rapidsai/cuvs\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA cuVS library</a> to construct all-neighbors graphs for UMAP. For large datasets, this method accelerates the all-neighbors graph-building process by hundreds of times, while still maintaining functionally equivalent results.</p>\n\n\n\n<h2 id=\"using_batching_to_scale_all-neighbors_graph_construction\"  class=\"wp-block-heading\">Using batching to scale all-neighbors graph construction<a href=\"#using_batching_to_scale_all-neighbors_graph_construction\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Managing a large dataset by keeping it on the host and processing it in batches on the device may seem straightforward. However, a key challenge when building k-NN subgraphs with a certain subset of the dataset is that data samples with similar indices are not guaranteed to be close in distance. This means you can\u2019t simply slice the dataset into batches.</p>\n\n\n\n<p>We solved this problem with a batching approach that is inspired by literature on the popular <a href=\"https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/\">DiskANN</a> algorithm. We first perform a balanced k-means clustering on a subsample of the dataset to extract centroids for a predefined number of clusters. Then, using this information, we partition the dataset into batches based on their closest clusters.&nbsp;</p>\n\n\n\n<p>This approach ensures that data points in each batch are more likely to be closed to each other, improving the likelihood that nearest neighbors are found within the same batch. The remaining part of this section explains each step of the batching process in detail:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Extract the cluster centroids</li>\n\n\n\n<li>Find data points for each cluster</li>\n\n\n\n<li>Build subgraphs of cluster data points</li>\n\n\n\n<li>Merge the k-NN subgraph with the global all-neighbors graph</li>\n</ul>\n\n\n\n<h3 id=\"extract_the_cluster_centroids\"  class=\"wp-block-heading\">Extract the cluster centroids<a href=\"#extract_the_cluster_centroids\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>We first extracted the cluster centroids from the dataset. Because we assumed that a large dataset doesn\u2019t fit on a GPU device, we left the data in host memory and randomly subsampled a set of points to ensure that the subset fits in the GPU device memory. Usually, 10% of the dataset is a large enough subsample to find a usable set of centroids.\u00a0</p>\n\n\n\n<p>Using the <code>nnd_n_clusters</code> parameters provided by the user, we ran balanced k-means on the sampled subset to identify the specified number of cluster centers.</p>\n\n\n\n<h3 id=\"find_data_points_for_each_cluster\"  class=\"wp-block-heading\">Find data points for each cluster<a href=\"#find_data_points_for_each_cluster\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Next, we determined the top two closest cluster centers for each data point and then inverted the indices to find the data points that belonged to each cluster. This process resulted in each data point being assigned to two separate clusters.&nbsp;</p>\n\n\n\n<p>This approach ensures that there is overlap in the neighborhoods for each cluster, increasing the likelihood that the final neighborhoods will include at least an acceptable number of the neighbors that we might have expected if we had computed the exact results.</p>\n\n\n\n<h3 id=\"build_subgraphs_of_cluster_data_points\"  class=\"wp-block-heading\">Build subgraphs of cluster data points<a href=\"#build_subgraphs_of_cluster_data_points\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>When we knew the data points that belonged to each cluster, we proceeded to iteratively build subgraphs on the data points for each cluster. This means that for each cluster, we gathered the data points for that cluster in the GPU\u2019s memory and ran NN-descent on this subset to construct the all-neighbors graph for that cluster.</p>\n\n\n\n<h3 id=\"merge_the_k-nn_subgraph_with_the_global_all-neighbors_graph\"  class=\"wp-block-heading\">Merge the k-NN subgraph with the global all-neighbors graph<a href=\"#merge_the_k-nn_subgraph_with_the_global_all-neighbors_graph\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>After the all-neighbors graph for a cluster was built, we merged this k-NN subgraph with the global all-neighbors graph. To do this efficiently, we used a custom CUDA kernel that merged the two subgraphs without allocating additional device memory.&nbsp;</p>\n\n\n\n<p>After iterating through all the clusters in this way, the global all-neighbors graph was returned as the final result. As this graph is generally much smaller than the input dataset, it could be copied safely into the GPU\u2019s memory space even when the input dataset was much too large to fit.</p>\n\n\n\n<h2 id=\"performance_improvements\"  class=\"wp-block-heading\">Performance improvements<a href=\"#performance_improvements\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>We evaluated the performance impact of using cuML UMAP and the new batched all-neighbors graph construction method.\u00a0</p>\n\n\n\n<p>For these experiments, we used an NVIDIA H100 GPU with 80 GB of memory. These comparisons are against the GPU version of UMAP, and so these speedups are not from a CPU-to-GPU comparison but improvements to the existing GPU implementation.\u00a0</p>\n\n\n\n<p>Figure 2 illustrates the total runtime of UMAP in cuML, comparing the new NN-descent strategy with the brute-force all-neighbors graph construction strategy.<strong> </strong>For a dataset with 20M points and 384 dimensions, we gained 311x speedup using NN-descent, reducing UMAP\u2019s total runtime on the GPU from 10 hours to just 2 minutes!</p>\n\n\n\n<p>Figure 2 is in log scale because the speedups are so high.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1000\" height=\"573\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings.png\" alt=\"A bar chart shows the time to compute UMAP embeddings when computing the all-neighbors graph with brute-force compared to NN-descent. The chart demonstrates that our new batching approach to constructing the all-neighbors graph results in massive speedups.\" class=\"wp-image-91205\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings.png 1000w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-300x172.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-625x358.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-179x103.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-768x440.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-645x370.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-500x287.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-157x90.png 157w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-362x207.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/time-compute-umap-embeddings-192x110.png 192w\" sizes=\"(max-width: 1000px) 100vw, 1000px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. Time to compute UMAP embeddings</em></figcaption></figure></div>\n\n\n<p>We also observe that the UMAP algorithm for a dataset as large as 50M points with 768 dimensions is now able to be run on the GPU, even though this dataset is 150 GB\u2013 much larger than the amount of memory in the GPU.\u00a0</p>\n\n\n\n<p>This feat is achieved with the batching algorithm by partitioning the dataset into five clusters. In contrast, the brute-force all-neighbors graph building algorithm runs out of memory because it attempts to load the entire dataset onto the device at one time.<s>&nbsp;</s></p>\n\n\n\n<p>While this new technique can improve UMAP\u2019s speed and scalability, we need to maintain quality to ensure the low-dimensional embeddings can be used effectively. To measure quality, we turn to the <a href=\"https://scikit-learn.org/dev/modules/generated/sklearn.manifold.trustworthiness.html\">trustworthiness score</a>. Trustworthiness is a score between 0 and 1 that indicates how well the local nearest neighbors structure is retained in the low-dimensional UMAP embedded space as compared to the nearest neighbors of the original vectors before running UMAP. In this metric, higher is better.</p>\n\n\n\n<p>Figure 3 shows that these significant speedups and benefits come without sacrificing the quality of the UMAP embedding results. We can see that there are no significant changes in the trustworthiness score as we increase the numbers of batches.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"640\" height=\"480\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality.png\" alt=\"A line plot shows the original non-batched version of the k-NN graph construction algorithm and three batches of 5, 10, and 15 batches. There is no substantial impact to the trustworthiness scores even when the vectors are chunked across 15 batches.\" class=\"wp-image-91206\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality.png 640w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/changes-umap-embedding-quality-147x110.png 147w\" sizes=\"(max-width: 640px) 100vw, 640px\" /><figcaption class=\"wp-element-caption\"><em>Figure 3. Evaluation of the changes to UMAP embedding quality over increasing numbers of batches</em></figcaption></figure></div>\n\n\n<h2 id=\"conclusion\"  class=\"wp-block-heading\">Conclusion<a href=\"#conclusion\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>We are excited to share these performance results with the data science community. Given UMAP\u2019s popularity across various domains, we believe that these new features in RAPIDS cuML will significantly accelerate workflows and help computational scientists uncover insights that are only possible by processing large-scale datasets on the GPU.</p>\n\n\n\n<p>To get started with cuML and install the <code>conda</code> and <code>pip</code> packages, as well as ready-to-go Docker containers, see the <a href=\"https://docs.rapids.ai/install\">RAPIDS Installation Guide</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>UMAP is a popular dimension reduction algorithm used in fields like bioinformatics, NLP topic modeling, and ML preprocessing. It works by creating a k-nearest neighbors (k-NN) graph, which is known in literature as an all-neighbors graph, to build a fuzzy topological representation of the data, which is used to embed high-dimensional data into lower dimensions.&nbsp; &hellip; <a href=\"https://developer.nvidia.com/blog/even-faster-and-more-scalable-umap-on-the-gpu-with-rapids-cuml/\">Continued</a></p>\n", "protected": false}, "author": 2407, "featured_media": 91307, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1512398", "discourse_permalink": "https://forums.developer.nvidia.com/t/even-faster-and-more-scalable-umap-on-the-gpu-with-rapids-cuml/311851", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [696], "tags": [453, 145], "coauthors": [4156, 1793, 2497], "class_list": ["post-91198", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-science", "tag-featured", "tag-graph-algorithms"], "acf": {"post_industry": "", "post_products": ["cuML", "RAPIDS"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Benchmark"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/umap-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nIW", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Data Science", "link": "https://developer.nvidia.com/blog/category/data-science/", "id": 696}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91198"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2407"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91198"}], "version-history": [{"count": 10, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91198/revisions"}], "predecessor-version": [{"id": 91443, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91198/revisions/91443"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91307"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91198"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91198"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91198"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91198"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90989, "date": "2024-10-31T13:20:01", "date_gmt": "2024-10-31T20:20:01", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90989"}, "modified": "2024-11-14T11:40:37", "modified_gmt": "2024-11-14T19:40:37", "slug": "build-multimodal-visual-ai-agents-powered-by-nvidia-nim", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/build-multimodal-visual-ai-agents-powered-by-nvidia-nim/", "title": {"rendered": "Build Multimodal Visual AI Agents Powered by NVIDIA NIM"}, "content": {"rendered": "\n<p>The exponential growth of visual data\u2014ranging from images to PDFs to streaming videos\u2014has made manual review and analysis virtually impossible. Organizations are struggling to transform this data into actionable insights at scale, leading to missed opportunities and increased risks.</p>\n\n\n\n<p>To solve this challenge, vision-language models (VLMs) are emerging as powerful tools, combining visual perception of images and videos with text-based reasoning. Unlike traditional <a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\">large language models</a> (LLMs) that only process text, VLMs empower you to build <a href=\"https://www.nvidia.com/en-us/use-cases/visual-ai-agents/\">visual AI agents</a> that understand and act on complex multimodal data, enabling real-time decision-making and automation.</p>\n\n\n\n<p>Imagine having an intelligent AI agent that can analyze remote camera footage to detect early signs of wildfires or scan business documents to extract critical information buried within charts, tables, and images\u2014all autonomously. </p>\n\n\n\n<p>With <a href=\"https://build.nvidia.com/explore/vision\">NVIDIA NIM microservices</a>, building these advanced visual AI agents is easier and more efficient than ever. Offering flexible customization, streamlined API integration, and smooth deployment, NIM microservices enable you to create dynamic agents tailored to your unique business needs.</p>\n\n\n\n<p>In this post, we guide you through the process of designing and building intelligent visual AI agents using NVIDIA NIM microservices. We introduce the different types of vision AI models available, share four sample applications\u2014streaming video alerts, structured text extraction, multimodal search, and few-shot classification\u2014and provide Jupyter notebooks to get you started. For more information about bringing these models to life, see the <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows\">/NVIDIA/metropolis-nim-workflows</a> GitHub repo.&nbsp;</p>\n\n\n\n<h2 id=\"types_of_vision_ai_models\"  class=\"wp-block-heading\">Types of vision AI models<a href=\"#types_of_vision_ai_models\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>To build a robust visual AI agent, you have the following core types of vision models at your disposal: </p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>VLMs</li>\n\n\n\n<li>Embedding models</li>\n\n\n\n<li>Computer vision (CV) models</li>\n</ul>\n\n\n\n<p>These models serve as essential building blocks for developing intelligent visual AI agents. While the VLM functions as the core engine of each agent, CV and embedding models can enhance its capabilities, whether by improving accuracy for tasks like object detection or parsing complex documents.</p>\n\n\n\n<p>In this post, we use <a href=\"https://build.nvidia.com/explore/vision\">vision NIM microservices</a> to access these models. Each vision NIM microservice can be easily integrated into your workflows through simple REST APIs, allowing for efficient model inference on text, images, and videos. To get started, you can experiment with hosted preview APIs on <a href=\"http://build.nvidia.com\">build.nvidia.com</a>, without needing a local GPU.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"557\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-1024x557.gif\" alt=\"GIF shows the llama-3.2-vision-90b model summarizing an image.\u00a0\" class=\"wp-image-91046\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-1024x557.gif 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-300x163.gif 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-625x340.gif 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-179x97.gif 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-768x418.gif 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-1536x836.gif 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-645x351.gif 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-500x272.gif 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-160x87.gif 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-362x197.gif 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llama-3.2-vision-90b-model-202x110.gif 202w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1.The llama-3.2-vision-90b model on build.nvidia.com</em></figcaption></figure></div>\n\n\n<h3 id=\"vision_language_models\"  class=\"wp-block-heading\">Vision language models<a href=\"#vision_language_models\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>VLMs bring a new dimension to language models by adding vision capabilities, making them multimodal. These models can process images, videos, and text, enabling them to interpret visual data and generate text-based outputs. VLMs are versatile and can be fine-tuned for specific use cases or prompted for tasks such as Q&amp;A based on visual inputs.&nbsp;</p>\n\n\n\n<p>NVIDIA and its partners offer several VLMs as NIM microservices each differing in size, latency, and capabilities (Table 1).&nbsp;</p>\n\n\n\n<figure class=\"wp-block-table aligncenter is-style-stripes\"><table class=\"has-fixed-layout\"><tbody><tr><td><strong>Company</strong></td><td><strong>Model</strong></td><td><strong>Size</strong></td><td><strong>Description</strong></td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/vila\">VILA</a></td><td>40B</td><td>A powerful general-purpose model built on SigLIP and Yi that is suitable for nearly any use case.&nbsp;</td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/neva-22b\">Neva</a></td><td>22B</td><td>A medium-sized model combining NVGPT and CLIP and offering the functionality of much larger multimodal models.&nbsp;</td></tr><tr><td>Meta</td><td><a href=\"https://build.nvidia.com/meta/llama-3.2-90b-vision-instruct\">Llama 3.2</a></td><td>90B/11B</td><td>The first vision-capable Llama model in two sizes, excelling in a range of vision-language tasks and supporting higher-resolution input.&nbsp;</td></tr><tr><td>Microsoft</td><td><a href=\"https://build.nvidia.com/microsoft/phi-3_5-vision-instruct\">phi-3.5-vision</a></td><td>4.2B</td><td>A small, fast model that excels at OCR and is capable of processing multiple images.&nbsp;</td></tr><tr><td>Microsoft</td><td><a href=\"https://build.nvidia.com/microsoft/microsoft-florence-2\">Florence-2</a></td><td>0.7B</td><td>A multi-task model capable of captioning, object detection, and segmentation using simple text prompts.&nbsp;</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 1. VLM NIM microservices</em></figcaption></figure>\n\n\n\n<h3 id=\"embedding_models\"  class=\"wp-block-heading\">Embedding models<a href=\"#embedding_models\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Embedding models convert input data (such as images or text) into dense feature-rich vectors known as embeddings. These embeddings encapsulate the essential properties and relationships within the data, enabling tasks like similarity search or classification. Embeddings are typically stored in <a href=\"https://www.nvidia.com/en-us/glossary/vector-database/\">vector databases</a> where GPU-accelerated search can quickly retrieve relevant data.&nbsp;</p>\n\n\n\n<p>Embedding models play a crucial role in creating intelligent agents. For example, they support <a href=\"https://www.nvidia.com/en-us/glossary/retrieval-augmented-generation/\">retrieval-augmented generation</a> (RAG) workflows, enabling agents to pull relevant information from diverse data sources and improve accuracy through in-context learning.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-table aligncenter is-style-stripes\"><table class=\"has-fixed-layout\"><tbody><tr><td><strong>Company</strong></td><td><strong>Model</strong></td><td><strong>Description</strong></td><td><strong>Use Cases</strong></td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/nvclip\">NV-CLIP</a></td><td>Multimodal foundation model generating text and image embeddings</td><td>Multimodal search, Zero-shot classification</td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/nv-dinov2\">NV-DINOv2</a></td><td>Vision foundation model generating high-resolution image embeddings</td><td>Similarity search, Few-shot classification</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 2.</em><strong><em> </em></strong><em>Embedding NIM microservices</em></figcaption></figure>\n\n\n\n<h3 id=\"computer_vision_models\"  class=\"wp-block-heading\">Computer vision models<a href=\"#computer_vision_models\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>CV models focus on specialized tasks like image classification, object detection, and optical character recognition (OCR). These models can augment VLMs by adding detailed metadata, improving the overall intelligence of AI agents.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-table aligncenter is-style-stripes\"><table class=\"has-fixed-layout\"><tbody><tr><td><strong>Company</strong></td><td><strong>Model</strong></td><td><strong>Description</strong></td><td><strong>Use Cases</strong></td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/nv-grounding-dino\">Grounding Dino</a></td><td>Open-vocabulary object detection</td><td>Detect anything</td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/ocdrnet\">OCDRNet</a></td><td>Optical character detection and recognition</td><td>Document parsing</td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/visual-changenet\">ChangeNet</a></td><td>Detects pixel-level changes between two images&nbsp;</td><td>Defect detection,&nbsp;satellite imagery analysis</td></tr><tr><td>NVIDIA</td><td><a href=\"https://build.nvidia.com/nvidia/retail-object-detection\">Retail Object Detection</a></td><td>Pretrained to detect common retail items&nbsp;</td><td>Loss prevention</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 3.</em><strong><em> </em></strong><em>Computer vision NIM microservices</em></figcaption></figure>\n\n\n\n<h2 id=\"build_visual_ai_agents_with_vision_nim_microservices\"  class=\"wp-block-heading\">Build visual AI agents with vision NIM microservices<a href=\"#build_visual_ai_agents_with_vision_nim_microservices\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Here are real-world examples of how the vision NIM microservices can be applied to create powerful visual AI agents.&nbsp;</p>\n\n\n\n<p>To make application development with NVIDIA NIM microservices more accessible, we have published a collection of examples on GitHub. These examples demonstrate how to use NIM APIs to build or integrate them into your applications. Each example includes a Jupyter notebook tutorial and demo that can be easily launched, even without GPUs.</p>\n\n\n\n<p>On the <a href=\"https://build.nvidia.com/explore/discover\">NVIDIA API Catalog</a>, select a model page, such as <a href=\"https://build.nvidia.com/meta/llama-3_1-405b-instruct\">Llama 3.1 405B</a>. Choose <strong>Get API Key</strong> and <a href=\"https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&amp;ProductFamily=NVAIEnterprise\">enter your business email</a> for a 90-day <a href=\"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\">NVIDIA AI Enterprise</a> license, or use your personal email to <a href=\"https://developer.nvidia.com/blog/access-to-nvidia-nim-now-available-free-to-developer-program-members/\">access NIM</a> through the <a href=\"https://developer.nvidia.com/developer-program\">NVIDIA Developer Program</a>.</p>\n\n\n\n<p>On the <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main\">/NVIDIA/metropolis-nim-workflows</a> GitHub repo, explore the Jupyter notebook tutorials and demos. These workflows showcase how vision NIM microservices can be combined with other components, like vector databases and LLMs to build powerful AI agents that solve real-world problems. With your API key, you can easily recreate the workflows showcased in this post, giving you hands-on experience with Vision NIM microservices.</p>\n\n\n\n<p>Here are a few example workflows:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/nim_workflows/vlm_alerts\">VLM streaming video alerts agent</a></li>\n\n\n\n<li><a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/nim_workflows/vision_text_extraction\">Structured text extraction agent</a></li>\n\n\n\n<li><a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/nim_workflows/nvdinov2_few_shot\">Few-shot classification with NV-DINOv2 agent</a></li>\n\n\n\n<li><a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/nim_workflows/nvclip_multimodal_search\">Multimodal search with NV-CLIP agent</a></li>\n</ul>\n\n\n\n<h3 id=\"vlm_streaming_video_alerts_agent\"  class=\"wp-block-heading\">VLM streaming video alerts agent<a href=\"#vlm_streaming_video_alerts_agent\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>With vast amounts of video data generated every second, it\u2019s impossible to manually review footage for key events like package deliveries, forest fires, or unauthorized access.&nbsp;</p>\n\n\n\n<p>This workflow shows how to use VLMs, Python, and OpenCV to build an AI agent that <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/blob/main/nim_workflows/vlm_alerts/README.md\">autonomously monitors live streams for user-defined events</a>. When an event is detected, an alert is generated, saving countless hours of manual video review. Thanks to the flexibility of VLMs, new events can be detected by changing the prompt\u2014no need for custom CV models to be built and trained for each new scenario..</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/spzj4JxLcs8?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. Visual AI Agent Powered by NVIDIA NIM</em></figcaption></figure>\n\n\n\n<p>In Figure 2, the VLM runs in the cloud while the video streaming pipeline operates locally. This setup enables the demo to run on almost any hardware, with the heavy computation offloaded to the cloud through NIM microservices.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1.png\"><img loading=\"lazy\" decoding=\"async\" width=\"956\" height=\"851\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1.png\" alt=\"An architecture diagram shows the input of a video stream to frame decode and subsampling step, while a user alert creates a request for the VLM NIM microservice. The response is parsed and goes to overlay generation and a WebSocket server for the alert notification.\" class=\"wp-image-91314\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1.png 956w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-300x267.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-625x556.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-129x115.png 129w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-768x684.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-645x574.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-337x300.png 337w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-101x90.png 101w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-362x322.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/streaming-video-alert-agent-architecture-1-124x110.png 124w\" sizes=\"(max-width: 956px) 100vw, 956px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 2. Streaming video alert agent architecture</em></figcaption></figure></div>\n\n\n<p>Here are the steps for building this agent:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li><strong>Load and process the video stream</strong>: Use OpenCV to load a video stream or file, decode it, and subsample frames.</li>\n\n\n\n<li><strong>Create REST API endpoints:</strong> Use FastAPI to create control REST API endpoints where users can input custom prompts.</li>\n\n\n\n<li><strong>Integrate with the VLM API:</strong> A wrapper class handles interactions with the VLM API by sending video frames and user prompts. It forms the NIM API requests and parses the response.&nbsp;</li>\n\n\n\n<li><strong>Overlay responses on video:</strong> The VLM response is overlaid onto the input video, streamed out using OpenCV for real-time viewing.&nbsp;</li>\n\n\n\n<li><strong>Trigger alerts:</strong> Send the parsed response over a WebSocket server to integrate with other services, triggering notifications based on detected events.&nbsp;</li>\n</ol>\n\n\n\n<p>For more information about building a VLM-powered streaming video alert agent, see the <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/blob/main/nim_workflows/vlm_alerts/README.md\">/NVIDIA/metropolis-nim-workflows</a> notebook tutorial and demo on GitHub. You can experiment with different VLM NIM microservices to find the best model for your use case.&nbsp;</p>\n\n\n\n<p>For more information about how VLMs can transform edge applications with <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/\">NVIDIA Jetson</a> and <a href=\"https://developer.nvidia.com/embedded-computing\">Jetson Platform Services</a>, see <a href=\"https://developer.nvidia.com/blog/develop-generative-ai-powered-visual-ai-agents-for-the-edge/\">Develop Generative AI-Powered Visual AI Agents for the Edge</a> and explore additional resources on the <a href=\"https://developer.nvidia.com/embedded/jetpack/jetson-platform-services-get-started\">Jetson Platform Services</a> page.</p>\n\n\n\n<h3 id=\"structured_text_extraction_agent\"  class=\"wp-block-heading\">Structured text extraction agent<a href=\"#structured_text_extraction_agent\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Many business documents are stored as images rather than searchable formats like PDFs. This presents a significant challenge when it comes to searching and processing these documents, often requiring manual review, tagging, and organizing.&nbsp;</p>\n\n\n\n<p>While optical character detection and recognition (OCDR) models have been around for a while, they often return cluttered results that fail to retain the original formatting or interpret its visual data. This becomes especially challenging when working with documents in irregular formats, such as photo IDs, which come in various shapes and sizes.&nbsp;</p>\n\n\n\n<p>Traditional CV models make processing such documents time-consuming and costly. However, by combining the flexibility of VLMs and LLMs with the precision of OCDR models, you can build a <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/nim_workflows/vision_text_extraction\">powerful text-extraction pipeline to autonomously parse documents</a> and store user-defined fields in a database.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1.png\"><img loading=\"lazy\" decoding=\"async\" width=\"951\" height=\"830\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1.png\" alt=\"An architecture diagram shows form requests and responses to and from the OCDR, VLM, and LLM NIM microservices, plus the steps of combining OCD metadata with the prompt, the LLM formatting prompt, and the parsing of the formatted response.\" class=\"wp-image-91315\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1.png 951w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-300x262.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-625x545.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-132x115.png 132w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-768x670.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-645x563.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-344x300.png 344w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-103x90.png 103w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-362x316.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-agent-architecture-1-126x110.png 126w\" sizes=\"(max-width: 951px) 100vw, 951px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 3. Structured text extraction agent architecture</em></figcaption></figure></div>\n\n\n<p>Here are the structured text-extraction pipeline building steps:&nbsp;</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li><strong>Document input:</strong> Provide an image of the document to an OCDR model, such as OCDRNet or Florence, which returns metadata for all the detected characters in the document.&nbsp;</li>\n\n\n\n<li><strong>VLM integration: </strong>The VLM processes the user\u2019s prompt specifying the desired fields and analyzes the document. It uses the detected characters from the OCDR model to generate a more accurate response.&nbsp;</li>\n\n\n\n<li><strong>LLM formatting:</strong> The response of the VLM is passed to an LLM, which formats the data into JSON, presenting it as a table.&nbsp;</li>\n\n\n\n<li><strong>Output and storage:</strong> The extracted fields are now in a structured format, ready to be inserted into a database or stored for future use.&nbsp;</li>\n</ol>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id.png\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"768\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-1024x768.png\" alt=\"Screenshots of the microservice extracting text from a photo ID.\u00a0The screenshots include specifying the model options for VLM, OCDR, and LLM, plus the user-defined fields and the structured output, filled out with the information from the actual ID.\" class=\"wp-image-91049\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-1024x768.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-768x576.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-1536x1152.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-645x484.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-362x271.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/structured-text-extraction-example-photo-id.png 1667w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 4. Structured text extraction example with vision NIM microservices</em></figcaption></figure></div>\n\n\n<p>The preview APIs make it easy to experiment by combining multiple models to build complex pipelines. From the demo UI, you can switch between different VLMs, OCDR, and LLM models available on <a href=\"http://build.nvidia.com\">build.nvidia.com</a> for quick experimentation.&nbsp;</p>\n\n\n\n<h3 id=\"few-shot_classification_with_nv-dinov2&nbsp;\"  class=\"wp-block-heading\">Few-shot classification with NV-DINOv2&nbsp;<a href=\"#few-shot_classification_with_nv-dinov2&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>NV-DINOv2 generates embeddings from high-resolution images, making it ideal for tasks requiring detailed analysis, such as defect detection with only a few sample images. This workflow demonstrates how to build a <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/workflows/nvdinov2_few_shot\">scalable few-shot classification pipeline</a> using NV-DINOv2 and a Milvus vector database.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"531\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-1024x531.png\" alt=\"An architecture diagram shows how to embed and store few-shot examples and how to inference new images.\" class=\"wp-image-91316\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-1024x531.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-300x156.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-625x324.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-179x93.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-768x398.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-1536x797.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-645x335.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-500x259.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-160x83.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-362x188.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1-212x110.png 212w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/few-shot-classification-nv-dinov2-1.png 1822w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 5. Few-shot classification with NV-DINOv2</em></figcaption></figure></div>\n\n\n<p>Here is how the few-shot classification pipeline works:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li><strong>Define classes and upload samples:</strong> Users define classes and upload a few sample images for each. NV-DINOv2 generates embeddings from these images, which are then stored in a Milvus vector database along with the class labels.&nbsp;</li>\n\n\n\n<li><strong>Predict new classes: </strong>When a new image is uploaded, NV-DINOv2 generates its embedding, which is compared with the stored embeddings in the vector database. The closest neighbors are identified using the k-nearest neighbors (k-NN) algorithm, and the majority class among them is predicted.\u00a0</li>\n</ol>\n\n\n\n<h3 id=\"multimodal_search_with_nv-clip\"  class=\"wp-block-heading\">Multimodal search with NV-CLIP<a href=\"#multimodal_search_with_nv-clip\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>NV-CLIP offers a unique advantage: the ability to embed both text and images, enabling <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows/tree/main/nim_workflows/nvclip_multimodal_search\">multimodal search</a>. By converting text and image inputs into embeddings within the same vector space, NV-CLIP facilitates the retrieval of images that match a given text query. This enables highly flexible and accurate search results.\u00a0</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"749\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-1024x749.gif\" alt=\"GIF shows a search for school bus images using natural language prompts with NV-CLIP.\u00a0\" class=\"wp-image-91051\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-1024x749.gif 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-300x220.gif 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-625x457.gif 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-157x115.gif 157w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-768x562.gif 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-645x472.gif 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-410x300.gif 410w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-123x90.gif 123w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-362x265.gif 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nv-clip-multimodal-search-150x110.gif 150w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 6. Multimodal search (image and text) with NV-CLIP</em></figcaption></figure></div>\n\n\n<p>In this workflow, users upload a folder of images, which are embedded and stored in a vector database. Using the UI, they can type a query, and NV-CLIP retrieves the most similar images based on the input text.&nbsp;</p>\n\n\n\n<p>More advanced agents can be built using this approach with VLMs to create multimodal RAG workflows, enabling visual AI agents to build on past experiences and improve responses.\u00a0</p>\n\n\n\n<h2 id=\"get_started_with_visual_ai_agents_today&nbsp;\"  class=\"wp-block-heading\">Get started with visual AI agents today&nbsp;<a href=\"#get_started_with_visual_ai_agents_today&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Ready to dive in and start building your own visual AI agents? Use the code provided in the <a href=\"https://github.com/NVIDIA/metropolis-nim-workflows\">/NVIDIA/metropolis-nim-workflows</a> GitHub repo as a foundation to develop your own custom workflows and AI solutions powered by NIM microservices. Let the example inspire new applications that solve your specific challenges.</p>\n\n\n\n<p>For any technical questions or support, join our community and engage with experts in the <a href=\"https://forums.developer.nvidia.com/c/accelerated-computing/intelligent-video-analytics/visual-ai-agent/680\">NVIDIA Visual AI Agent forum</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>The exponential growth of visual data\u2014ranging from images to PDFs to streaming videos\u2014has made manual review and analysis virtually impossible. Organizations are struggling to transform this data into actionable insights at scale, leading to missed opportunities and increased risks. To solve this challenge, vision-language models (VLMs) are emerging as powerful tools, combining visual perception of &hellip; <a href=\"https://developer.nvidia.com/blog/build-multimodal-visual-ai-agents-powered-by-nvidia-nim/\">Continued</a></p>\n", "protected": false}, "author": 1925, "featured_media": 91320, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1512397", "discourse_permalink": "https://forums.developer.nvidia.com/t/build-multimodal-visual-ai-agents-powered-by-nvidia-nim/311850", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [3110], "tags": [3965, 453, 1950, 354, 3953], "coauthors": [3616], "class_list": ["post-90989", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-generative-ai", "tag-ai-agent", "tag-featured", "tag-image-recognition", "tag-image-segmentation", "tag-vlms"], "acf": {"post_industry": ["Manufacturing", "Retail / Consumer Packaged Goods", "Smart Cities / Spaces"], "post_products": ["AI Enterprise", "Metropolis", "NIM"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/metropolis-and-iva-ngc-featured.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nFz", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90989"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1925"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90989"}], "version-history": [{"count": 6, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90989/revisions"}], "predecessor-version": [{"id": 91328, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90989/revisions/91328"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91320"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90989"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90989"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90989"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90989"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91133, "date": "2024-10-31T09:06:07", "date_gmt": "2024-10-31T16:06:07", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91133"}, "modified": "2024-11-14T09:10:55", "modified_gmt": "2024-11-14T17:10:55", "slug": "deep-learning-ai-model-identifies-breast-cancer-spread-without-surgery", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/deep-learning-ai-model-identifies-breast-cancer-spread-without-surgery/", "title": {"rendered": "Deep Learning AI Model Identifies Breast Cancer Spread without Surgery"}, "content": {"rendered": "\n<p>A new <a href=\"https://pubs.rsna.org/doi/10.1148/rycan.230107\">deep learning model</a> could reduce the need for surgery when diagnosing whether cancer cells are spreading, including to nearby lymph nodes\u2014also known as metastasis. Developed by researchers from the University of Texas Southwestern Medical Center, the AI tool analyzes time-series MRIs and clinical data to identify metastasis, providing crucial, noninvasive support for doctors in treatment planning. The advancement could lead to more timely and accurate cancer assessments, helping many patients avoid unnecessary surgery and improve outcomes.&nbsp;</p>\n\n\n\n<p>Metastatic breast cancer is responsible for the majority of breast cancer-related deaths. About one in three women in the US diagnosed with early-stage breast cancer develops metastatic cancer. However, early detection and treatment can slow disease progression, help doctors and patients manage symptoms, and maximize the effectiveness of treatments.</p>\n\n\n\n<p>Doctors often rely on sentinel lymph node biopsies (SLNB) when checking whether cancer has spread to the lymph nodes. The procedure involves injecting dye and a radioactive solution near the cancer site to identify the sentinel nodes, which drain into the tumor area first. These nodes are then surgically removed and biopsied. If cancer cells are found in the sentinel nodes, it shows that the cancer is spreading to the lymphatic system and could spread further. This information helps doctors determine the most appropriate treatment for the patient.&nbsp;</p>\n\n\n\n<p>While SLNB is a proven method, it&#8217;s invasive and comes with risks related to anesthesia, radiation exposure, swelling, pain, and limited movement near the incision.&nbsp;</p>\n\n\n\n<p>To create a noninvasive and reliable alternative to SLNB, the researchers developed a custom four-dimensional convolutional neural network (4D CNN). They trained the model using dynamic contrast-enhanced MRI (DCE-MRI) along with clinical datasets from 350 women recently diagnosed with breast cancer that spread to lymph nodes.</p>\n\n\n\n<p>The researchers used the <a href=\"https://portal.biohpc.swmed.edu/content/about/systems/\">Nucleus Compute Cluster,</a> part of the University of Texas Southwestern Medical Center&#8217;s high-performance computing infrastructure, to build and train the complex 4D deep learning model employing <a href=\"https://www.nvidia.com/en-us/data-center/a100/\">NVIDIA A100 Tensor Core</a> and <a href=\"https://www.nvidia.com/en-us/data-center/v100/\">NVIDIA V100 Tensor Core GPUs</a> </p>\n\n\n\n<p>\u201cThe deep learning model we built was a complex 4D model and GPUs were essential for us to achieve high training throughput as well as for our data preprocessing pipeline for image enhancement and noise reduction,\u201d said NVIDIA Senior HPC Engineer Paniz Karbasi, a study coauthor and former Computational Scientist at the University of Texas Southwestern Medical Center.</p>\n\n\n\n<div class=\"wp-block-image aligncenter\">\n<figure class=\"size-full is-resized\"><img decoding=\"async\" class=\"wp-image-75722\" style=\"width: 602px;\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/MRI-breast-cancer.png\" alt=\"Four boxes showing how the model processes breast cancer MRIs .\" height=\"576\" />\n<figcaption class=\"wp-element-caption\"><em>Figure 1. A volumetric dynamic contrast-enhanced MR image involves tumor delineation, cropping to a cuboidal volume, and enhancing the tumor by calculating difference images between time points</em></figcaption>\n</figure>\n</div>\n\n\n\n<p>This AI model processes data in four dimensions, examining data from 3D MRI scans while accounting for changes over time. The model learns \u200cfeatures of tumors and nearby lymph nodes by analyzing multiple images over time and integrating clinical data such as age, tumor grade, and breast cancer markers. By doing so, it can accurately identify patterns associated with cancer-free or cancer-affected lymph nodes.</p>\n\n\n\n<p>\u201cThe most important aspect of our study is that for imaging data we solely focus on data related to the primary tumor, without any additional axillary imaging,\u201d said study lead author Dogan Polat, an Interventional Radiology Resident at Mount Sinai Health Systems. Dr. Polat led the study while at the University of Texas Southwestern Medical Center. \u201cWe aim to decrease the need for additional imaging and reduce the number of invasive procedures for patients,\u201d said Dr. Polat.&nbsp;</p>\n\n\n\n<p>It identifies lymph node metastasis with 89% accuracy, outperforming radiologists and other imaging-based models. It also has the potential to prevent breast cancer patients from undergoing unnecessary sentinel node biopsies, and axillary lymph node dissection (ALND), reducing the risks, complications, and resources associated with the procedure.&nbsp;</p>\n\n\n\n<p>According to Polat, the next steps for the researchers include deploying the model to gather real-world data, which will help validate its effectiveness and identify areas for further refinement and broader application.&nbsp;</p>\n\n\n\n<p>Read the study <a href=\"https://pubs.rsna.org/doi/10.1148/rycan.230107?_gl=1*he76ww*_gcl_au*MTU2MjI0MzI4Ni4xNzI5NTQyODAw*corpRollup_ga*NjI2MDQ1ODAuMTcyOTU0MjgwMA..*corpRollup_ga_EQ32SZ84M3*MTcyOTgwODk2My42LjEuMTcyOTgxMTYxOS41Ny4wLjA.\"><em>Machine Learning Prediction of Lymph Node Metastasis in Breast Cancer: Performance of a Multi-institutional MRI-based 4D Convolutional Neural Network</em></a><em>.</em></p>\n", "protected": false}, "excerpt": {"rendered": "<p>A new deep learning model could reduce the need for surgery when diagnosing whether cancer cells are spreading, including to nearby lymph nodes\u2014also known as metastasis. Developed by researchers from the University of Texas Southwestern Medical Center, the AI tool analyzes time-series MRIs and clinical data to identify metastasis, providing crucial, noninvasive support for doctors &hellip; <a href=\"https://developer.nvidia.com/blog/deep-learning-ai-model-identifies-breast-cancer-spread-without-surgery/\">Continued</a></p>\n", "protected": false}, "author": 1115, "featured_media": 91144, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1512318", "discourse_permalink": "https://forums.developer.nvidia.com/t/deep-learning-ai-model-identifies-breast-cancer-spread-without-surgery/311833", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724, 696, 4146, 1903], "tags": [3941, 453, 90, 1877], "coauthors": [2315], "class_list": ["post-91133", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-computer-vision", "category-data-science", "category-development", "category-features", "tag-ai-impact", "tag-featured", "tag-medical-imaging", "tag-research"], "acf": {"post_industry": ["Healthcare & Life Sciences"], "post_products": ["A100", "V100"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["News"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Breast-cancer-cells-e1730236106594.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nHT", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Computer Vision / Video Analytics", "link": "https://developer.nvidia.com/blog/category/computer-vision/", "id": 2724}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91133"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1115"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91133"}], "version-history": [{"count": 20, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91133/revisions"}], "predecessor-version": [{"id": 91761, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91133/revisions/91761"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91144"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91133"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91133"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91133"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91133"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91186, "date": "2024-10-30T12:57:15", "date_gmt": "2024-10-30T19:57:15", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91186"}, "modified": "2024-11-14T10:09:53", "modified_gmt": "2024-11-14T18:09:53", "slug": "teaching-robots-to-tackle-household-chores", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/teaching-robots-to-tackle-household-chores/", "title": {"rendered": "Teaching Robots to Tackle Household Chores"}, "content": {"rendered": "\n<p>Robotics could make everyday life easier by taking on repetitive or time-consuming tasks. At NVIDIA GTC 2024, researchers from Stanford University unveiled BEHAVIOR-1K, a major benchmark designed to train robots to perform 1,000 real-world-inspired activities\u2014such as folding laundry, cooking breakfast, and cleaning up after a party.&nbsp;</p>\n\n\n\n<p>Using OmniGibson, a cutting-edge simulation environment for accelerating embodied AI research built on the <a href=\"https://www.nvidia.com/en-us/omniverse/\">NVIDIA Omniverse</a> platform, they focus on training robots in practical skills that can be directly applied to real-world settings\u2014from assisting in homes to workplaces and beyond.</p>\n\n\n\n<p>Part of a broader initiative to make robotics practical for everyday assistance, the BEHAVIOR-1K benchmark focuses on bringing advanced robotic capabilities closer to reality and freeing up time for people to engage in activities they enjoy.</p>\n\n\n\n<script src=\"https://api-prod.nvidia.com/search/nvidia-search-library.js\"></script>\n \n\n<div id=\"nvidia-event-details-widget\"></div>\n<style>\n.nvidia-search-widget .cleanslate , .nvidia-search-widget .player-overlay {\ndisplay:none;\n}\n</style>\n \n\n<script>\n \n NvidiaSearchLibrary.EventSessionDetailsWidget.mount({\n          site: 'https://www.nvidia.com',\n          language: 'en-us',\n          sessionId: 'gtc24-s62698',\n          jwtToken: '',\n \u2002\u2002\u2002\u2002voltronApiUrl:  'https://api-prod.nvidia.com/services/nod/api/v1/',\n          apiUrl: 'https://api-prod.nvidia.com/search/graphql',\n           onLogin: () => { },\n          onLogout: () => { },\n       \n          onSeeAllSessions: (speakerName) => {\n            window.location.href =  'https://www.nvidia.com/en-us/on-demand/search/?q=\"' + speakerName+'\"';\n          },\n          searchApiUrl: 'https://api-prod.nvidia.com/search/graphql',\n          searchToken: '',\n          uiConfId: '50468382',\n          showSessionRating: false,\n          anonToken: '',\n        });\n \n</script>\n\n\n\n<p>Follow along with a <a href=\"https://developer.download.nvidia.com/devblogs/Subseasonal-Weather-Forecasting-GTC2024.pdf\" target=\"_blank\" rel=\"noreferrer noopener\">PDF of the session</a>, which provides a detailed look at how BEHAVIOR-1K leverages insights from surveys involving over 1,400 participants to define meaningful everyday activities.\u00a0</p>\n\n\n\n<p>The session covers how the benchmark enables robots to learn tasks that people want help with, optimizing for performance and for practical impact on daily living. Key highlights include:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Activity definitions and OmniGibson simulation</strong>: Insights into how BEHAVIOR-1K combines human-defined tasks with realistic simulation environments to ensure robots learn in everyday life settings.</li>\n\n\n\n<li><strong>Scaling robotics training</strong>: Techniques for large-scale training across 50 fully interactive environments, incorporating over 1,200 object categories and 5,000+ 3D models to provide robots with diverse and realistic experiences.</li>\n\n\n\n<li><strong>Improving realism in AI training</strong>: Incorporating various object states, complex interactions, and realistic physical properties, making sure that robots are ready for real-world applications.</li>\n\n\n\n<li><strong>Survey insights and human-centered task design</strong>: Understanding what people want robots to help with through participant data, ensuring that BEHAVIOR-1K remains aligned with human needs.</li>\n</ul>\n\n\n\n<p>Watch the session <a href=\"https://www.nvidia.com/en-us/on-demand/session/gtc24-s62698/about:blank\" target=\"_blank\" rel=\"noreferrer noopener\">Tired of Household Chores? Teach Robots to Perform 1,000 Everyday Activities With BEHAVIOR</a>, explore more videos on NVIDIA On-Demand, and gain valuable skills and insights from industry experts by joining the <a href=\"https://developer.nvidia.com/developer-program\">NVIDIA Developer Program</a>.</p>\n\n\n\n<p><em>This content was partially crafted with the assistance of generative AI and LLMs. It underwent careful review and was edited by the NVIDIA Technical Blog team to ensure precision, accuracy, and quality.</em></p>\n", "protected": false}, "excerpt": {"rendered": "<p>Robotics could make everyday life easier by taking on repetitive or time-consuming tasks. At NVIDIA GTC 2024, researchers from Stanford University unveiled BEHAVIOR-1K, a major benchmark designed to train robots to perform 1,000 real-world-inspired activities\u2014such as folding laundry, cooking breakfast, and cleaning up after a party.&nbsp; Using OmniGibson, a cutting-edge simulation environment for accelerating embodied &hellip; <a href=\"https://developer.nvidia.com/blog/teaching-robots-to-tackle-household-chores/\">Continued</a></p>\n", "protected": false}, "author": 1115, "featured_media": 91211, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1511945", "discourse_permalink": "https://forums.developer.nvidia.com/t/teaching-robots-to-tackle-household-chores/311744", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [3110, 63, 503, 1903], "tags": [453, 3986], "coauthors": [2315], "class_list": ["post-91186", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-generative-ai", "category-robotics", "category-simulation-modeling-design", "category-features", "tag-featured", "tag-nvidia-on-demand"], "acf": {"post_industry": ["General", "Academia / Education"], "post_products": ["Omniverse"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["Video"], "post_collections": ["GTC March 2024"]}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/robots-chores-BEHAVIOR1K-e1730318187631.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nIK", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Robotics", "link": "https://developer.nvidia.com/blog/category/robotics/", "id": 63}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91186"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1115"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91186"}], "version-history": [{"count": 9, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91186/revisions"}], "predecessor-version": [{"id": 91951, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91186/revisions/91951"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91211"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91186"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91186"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91186"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91186"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90642, "date": "2024-10-30T10:54:45", "date_gmt": "2024-10-30T17:54:45", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90642"}, "modified": "2024-11-14T09:10:56", "modified_gmt": "2024-11-14T17:10:56", "slug": "high-throughput-ai-driven-drug-discovery-pipeline", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/high-throughput-ai-driven-drug-discovery-pipeline/", "title": {"rendered": "High Throughput AI-Driven Drug Discovery Pipeline"}, "content": {"rendered": "\n<p>The integration of AI in drug discovery is revolutionizing the way researchers approach the development of new treatments for various diseases. Traditional methods are often time-consuming and costly, with the process of bringing a new drug to market taking up to 15 years and costing between $1\u20132B.&nbsp;</p>\n\n\n\n<p>By using AI and advanced computational tools, researchers can now accelerate the identification of new drugs, significantly reducing both the time and cost involved in the drug discovery process.&nbsp;</p>\n\n\n\n<h2 id=\"challenges_of_traditional_drug_discovery\"  class=\"wp-block-heading\">Challenges of traditional drug discovery<a href=\"#challenges_of_traditional_drug_discovery\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>In conventional drug discovery workflows, researchers first identify a biological target, such as a protein involved in disease progression, and then search for molecules that can modulate this target. The complexity of biological systems, combined with the vast number of potential chemical structures, estimated at around 10<sup>60</sup>, makes this a daunting task.&nbsp;</p>\n\n\n\n<p>Traditional computer-aided drug discovery (CADD) methods often rely on simplified models and assumptions that fail to capture the intricacies of drug-target interactions, leading to high attrition rates in clinical trials.</p>\n\n\n\n<h2 id=\"an_ai-driven_approach_to_virtual_screening\"  class=\"wp-block-heading\">An AI-driven approach to virtual screening<a href=\"#an_ai-driven_approach_to_virtual_screening\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p><a href=\"https://www.innoplexus.com/\">Innoplexus</a> is a registered NVIDIA Inception startup.<strong> </strong>Their proprietary deep learning method uses <a href=\"https://www.nvidia.com/en-us/ai/#referrer=ai-subdomain\">NVIDIA NIM microservices</a> to streamline the drug discovery process. They also use NVIDIA H100 GPU clusters featuring the following components:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Accelerator:</strong> NVIDIA H100 Tensor Core GPU</li>\n\n\n\n<li><strong>Memory:</strong> 80-GB HBM3 (High-Bandwidth Memory)</li>\n\n\n\n<li><strong>Interconnect: </strong>NVIDIA NVLink 4.0</li>\n\n\n\n<li><strong>Cluster configuration:</strong> Scalable, multi-node clusters with high-speed interconnects for distributed training and inference</li>\n</ul>\n\n\n\n<p>This approach is informed by the NVIDIA NIM Agent Blueprint for generative virtual screening, which enables the rapid, AI-driven generation of novel molecular structures for accelerated molecular simulations and docking with NIM microservices.&nbsp;</p>\n\n\n\n<p>Combining Innoplexus&#8217; expertise with NVIDIA&#8217;s cutting-edge AI technology fundamentally transforms how innovative treatments are discovered and brought to market\u2014making this process faster, more efficiently, and more precise.</p>\n\n\n\n<p>To address the urgent need for novel therapies for neurodegenerative diseases associated with TDP-43 aggregation, Innoplexus developed an AI-driven drug discovery pipeline.&nbsp;</p>\n\n\n\n<h2 id=\"innoplexus\u2019s_deep_learning_method\"  class=\"wp-block-heading\">Innoplexus\u2019s deep learning method<a href=\"#innoplexus\u2019s_deep_learning_method\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Innoplexus\u2019 method employs custom-designed artificial neural networks (ANNs) for protein target prediction, trained on large-scale datasets of protein sequences, structural information, and molecular interactions.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"661\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-1024x661.png\" alt=\"Diagram shows the AG workflow pipeline from structure-based and ligand-based drug discovery, to using NIM microservices for protein prediction.\" class=\"wp-image-91065\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-1024x661.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-300x194.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-625x404.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-179x115.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-768x496.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-1536x992.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-645x416.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-465x300.png 465w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-139x90.png 139w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-362x234.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1-170x110.png 170w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-structure-ligand-based-drug-discovery-1.png 1744w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /></figure></div>\n\n\n<p class=\"has-text-align-center\"><em>Figure 1.</em> <em>The workflow for structure and ligand-based drug discovery using NVIDIA NIM microservices</em></p>\n\n\n\n<p>Innoplexus uses the following NVIDIA NIM microservices:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://build.nvidia.com/deepmind/alphafold2\">AlphaFold2</a> for protein structure prediction</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/nvidia/molmim-generate\">MolMIM</a> for optimized lead generation</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/mit/diffdock\">DiffDock</a> for molecular docking</li>\n</ul>\n\n\n\n<p>By combining these advanced AI tools, Innoplexus aims to streamline the drug discovery process and identify promising candidates that can effectively target TDP-43 and mitigate the progression of these debilitating diseases. This innovative approach has the potential to accelerate the development of new treatments and improve the lives of patients affected by neurodegenerative conditions.</p>\n\n\n\n<h3 id=\"alphafold2_for_protein_structure_prediction\"  class=\"wp-block-heading\">AlphaFold2 for protein structure prediction<a href=\"#alphafold2_for_protein_structure_prediction\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>A protein sequence provided by the user is processed through the <a href=\"https://build.nvidia.com/deepmind/alphafold2\">AlphaFold2</a> NIM microservice, which accurately determines the 3D structure of the target protein. This step involves aligning the sequence with known proteins, offering multiple alignment configurations for improved accuracy.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"440\" height=\"394\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein.png\" alt=\"Image shows the 3D structure of a target protein.\" class=\"wp-image-90981\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein.png 440w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein-300x269.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein-128x115.png 128w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein-335x300.png 335w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein-101x90.png 101w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein-362x324.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-structure-protein-123x110.png 123w\" sizes=\"(max-width: 440px) 100vw, 440px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. AlphaFold2 predicts the 3D structure of the protein from its amino acid sequence</em></figcaption></figure></div>\n\n\n<h3 id=\"molmim_for_optimized_lead_generation\"  class=\"wp-block-heading\">MolMIM for optimized lead generation<a href=\"#molmim_for_optimized_lead_generation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>An initial chemical structure is passed through the <a href=\"https://build.nvidia.com/nvidia/molmim-generate\">MolMIM</a> NIM microservice, which generates new molecular structures optimized for specific properties such as drug-likeness (QED), solubility (penalized log P), and molecular similarity.\u00a0</p>\n\n\n\n<p>The generated molecules are iteratively optimized in multiple cycles, depending on your requirements.</p>\n\n\n\n<h3 id=\"diffdock_for_molecular_docking\"  class=\"wp-block-heading\">DiffDock for molecular docking<a href=\"#diffdock_for_molecular_docking\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Molecular docking helps in determining the optimum site on the target protein where the drug binds. The optimized molecules and the target protein structure are processed by <a href=\"https://build.nvidia.com/mit/diffdock\">DiffDock</a>, which predicts the binding poses of the molecules to the protein.&nbsp;</p>\n\n\n\n<p>You can define the number of poses and other docking constraints, enabling a comprehensive analysis of potential drug-target interactions.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"570\" height=\"369\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction.png\" alt=\"Image shows 3D structure of a molecule interacting with a protein.\" class=\"wp-image-90982\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction.png 570w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction-300x194.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction-179x115.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction-463x300.png 463w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction-139x90.png 139w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction-362x234.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/3d-molecule-protein-interaction-170x110.png 170w\" sizes=\"(max-width: 570px) 100vw, 570px\" /><figcaption class=\"wp-element-caption\"><em>Figure 3. Diffdock predicts the 3D structure of how the molecule interacts with the protein</em></figcaption></figure></div>\n\n\n<h2 id=\"post-processing_admet_pipeline\"  class=\"wp-block-heading\">Post-processing ADMET pipeline<a href=\"#post-processing_admet_pipeline\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>After DiffDock, the top 1K small molecules are further screened using the proprietary ADMET (Absorption, Distribution, Metabolism, Excretion, and Toxicity) pipeline, which assesses the pharmacokinetic and pharmacodynamic properties of the molecules.&nbsp;</p>\n\n\n\n<p>This pipeline includes the following components:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>ADMET Prediction:</strong> The proprietary model predicts the ADMET properties of the molecules, including solubility, permeability, metabolism, and toxicity.</li>\n\n\n\n<li><strong>Filtering and Ranking:</strong> Molecules are filtered and ranked based on their predicted ADMET properties, ensuring that only the most promising candidates are selected for further development.</li>\n</ul>\n\n\n\n<h2 id=\"innoplexus_admet_model\"  class=\"wp-block-heading\">Innoplexus ADMET model<a href=\"#innoplexus_admet_model\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The ADMET model is a custom-designed neural network that uses a large dataset of molecular structures and their corresponding ADMET properties.&nbsp;</p>\n\n\n\n<p>The model is trained using advanced techniques:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Multi-task learning:</strong> The model is trained on multiple ADMET tasks simultaneously, improving its overall performance and accuracy.</li>\n\n\n\n<li><strong>Transfer learning:</strong> The model is fine-tuned on a large dataset of molecular structures, enabling it to generalize well to new, unseen molecules.</li>\n</ul>\n\n\n\n<h2 id=\"workflow_optimization\"  class=\"wp-block-heading\">Workflow optimization<a href=\"#workflow_optimization\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The pipeline is optimized for performance:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Data parallelism:</strong> Distributed training and inference across multiple GPUs and nodes.</li>\n\n\n\n<li><strong>Model parallelism:</strong> Splitting large models across multiple GPUs and nodes.</li>\n\n\n\n<li><strong>Pipeline parallelism:</strong> Overlapping computation and communication between pipeline stages.</li>\n</ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"786\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-1024x786.png\" alt=\"Bar chart shows the time taken in hours for GPUs on measures such as ADMET profiling for 10K molecules; molecular docking of generated molecules; and optimizing molecule generation towards drug-like properties.\" class=\"wp-image-91067\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-1024x786.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-300x230.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-625x480.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-150x115.png 150w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-768x590.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-1536x1179.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-645x495.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-391x300.png 391w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-117x90.png 117w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-362x278.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1-143x110.png 143w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/gpu-stats-1.png 1594w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 4. GPU-accelerated computing enables fast, efficient compute-intensive operations</em></figcaption></figure></div>\n\n\n<p>The application of GPUs and the approaches for accelerated computing facilitated in performing the compute-intensive operations of this solution fast, and making it feasible to complete within practical timelines.</p>\n\n\n\n<h2 id=\"real-world_applications_and_implications\"  class=\"wp-block-heading\">Real-world applications and implications<a href=\"#real-world_applications_and_implications\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Rapid compound identification with Innoplexus\u2019AI-driven pipeline powered with NVIDIA H100 clusters, accelerates virtual screening of generated molecules in addition to molecular docking up to 10x, enabling researchers to perform the following tasks:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Screen 5.8M small molecules in 5\u20138 hours duration.</li>\n\n\n\n<li>Identify the top 1% of compounds with high therapeutic potential from ADMET profiling in a few hours for a million compounds.&nbsp;</li>\n\n\n\n<li>Optimize lead compounds with 90% accuracy.</li>\n</ul>\n\n\n\n<p>By harnessing the power of AI and high-performance computing, you can rapidly explore vast chemical spaces and pinpoint promising candidates for therapeutic development, significantly accelerating the drug discovery process.</p>\n\n\n\n<h2 id=\"get_started\"  class=\"wp-block-heading\">Get started<a href=\"#get_started\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>AI and high-performance computing are set to transform the field of drug discovery, enabling faster, more accurate identification of potential drug candidates.&nbsp;</p>\n\n\n\n<p>By combining cutting-edge neural network algorithms, generative models, and advanced molecular docking techniques, the Innoplexus virtual screening pipeline offers a powerful tool for accelerating the discovery of new drugs, ultimately improving patient outcomes and reducing the cost and time associated with bringing new therapies to market.</p>\n\n\n\n<p><a href=\"https://build.nvidia.com/nvidia/generative-virtual-screening-for-drug-discovery/blueprintcard\">Get started</a> with the NVIDIA NIM Agent Blueprint for generative virtual screening and learn more about <a href=\"https://www.innoplexus.com/\">Innoplexus</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>The integration of AI in drug discovery is revolutionizing the way researchers approach the development of new treatments for various diseases. Traditional methods are often time-consuming and costly, with the process of bringing a new drug to market taking up to 15 years and costing between $1\u20132B.&nbsp; By using AI and advanced computational tools, researchers &hellip; <a href=\"https://developer.nvidia.com/blog/high-throughput-ai-driven-drug-discovery-pipeline/\">Continued</a></p>\n", "protected": false}, "author": 2410, "featured_media": 90644, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1511908", "discourse_permalink": "https://forums.developer.nvidia.com/t/high-throughput-ai-driven-drug-discovery-pipeline/311739", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [3110], "tags": [2385, 453], "coauthors": [4160, 4161, 4162, 4163, 3527], "class_list": ["post-90642", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-generative-ai", "tag-drug-discovery", "tag-featured"], "acf": {"post_industry": ["Healthcare & Life Sciences"], "post_products": ["NIM"], "post_learning_levels": ["General Interest"], "post_content_types": ["Spotlight"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/innoplexus-admet-pipeline-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nzY", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90642"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2410"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90642"}], "version-history": [{"count": 6, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90642/revisions"}], "predecessor-version": [{"id": 91068, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90642/revisions/91068"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90644"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90642"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90642"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90642"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90642"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91056, "date": "2024-10-29T15:01:56", "date_gmt": "2024-10-29T22:01:56", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91056"}, "modified": "2024-10-31T12:07:37", "modified_gmt": "2024-10-31T19:07:37", "slug": "protect-your-network-with-secure-boot-in-sonic", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/protect-your-network-with-secure-boot-in-sonic/", "title": {"rendered": "Protect Your Network with Secure Boot in SONiC"}, "content": {"rendered": "\n<p>NVIDIA technology helps organizations build and maintain secure, scalable, and high-performance network infrastructure. Advances in AI, with NVIDIA at the forefront, contribute every day to security advances. One way NVIDIA has taken a more direct approach to network security is through a secure network operating system (NOS).</p>\n\n\n\n<p>A secure network operating system (NOS) is a specialized type of NOS focused on robust security features to protect network infrastructure from a wide range of threats.&nbsp;</p>\n\n\n\n<p>Different systems offer various security features. Some provide built-in firewalls, VPNs, or monitoring tools. Some offer advanced threat detection and response features. Some offer hardened security at the boot level, preventing attacks before the operating system even loads. One of these features is called<strong> </strong>Secure Boot.</p>\n\n\n\n<h2 id=\"secure_boot\"  class=\"wp-block-heading\">Secure Boot<a href=\"#secure_boot\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>NVIDIA is increasingly supporting the security standard Secure Boot in more platforms. Secure Boot is a security UEFI (Unified Extensible Firmware Interface) feature that aims to protect against unauthorized firmware or software from running during the boot process and during firmware updates. <a href=\"https://www.nvidia.com/en-us/networking/spectrumx/\">NVIDIA Spectrum-4</a> switches and <a href=\"https://www.nvidia.com/en-us/networking/products/data-processing-unit/\">NVIDIA BlueField-2</a> DPUs and up now fully support UEFI Secure Boot.</p>\n\n\n\n<p>Unsigned or improperly signed code is prevented from executing at the boot level, preventing rootkits, bootkits, firmware attacks, and other malicious activity being loaded before the OS or security mechanisms are initialized, where an attacker could potentially gain full control of the core system. Gaining such a level of access allows an attacker to do almost anything.&nbsp;</p>\n\n\n\n<p>Secure Boot also significantly raises the barrier for attackers attempting to exploit physical access to devices. Even if an attacker can physically access the device, they cannot alter the boot components without the proper keys, protecting against tangible modifications such as replacing CPUs or hard drives.</p>\n\n\n\n<p>Secure Boot works by establishing a \u201cchain of trust\u201d starting from the hardware level and extending through the firmware and bootloader. Each component in the boot process verifies the next, and must be signed and checked before execution. If the signatures are valid and match known trusted keys, the system proceeds with the boot process. Otherwise, all unsigned code will be rejected by firmware and the system either halts or provides a warning. This includes an attacker attempting to install their own operating system outright.</p>\n\n\n\n<h2 id=\"secure_boot_in_the_sonic_network_operating_system\"  class=\"wp-block-heading\">Secure Boot in the SONiC network operating system<a href=\"#secure_boot_in_the_sonic_network_operating_system\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Secure Boot is supported within <a href=\"https://sonicfoundation.dev/\">SONiC</a> (Software for Open Networking in the Cloud), the Linux-based, open-source, hardware-agnostic network operating system. NVIDIA is the second-largest contributor to the SONiC project, behind only Microsoft, and supports SONiC in many ways. Learn more about <a href=\"https://www.nvidia.com/en-us/networking/ethernet-switching/sonic/\">NVIDIA and SONiC</a>. </p>\n\n\n\n<p>The big advantage of SONiC Secure Boot functionality over other systems is autonomy. Being open-source, SONiC enables customizable boot processes, unlike many traditional or proprietary systems, where you are only able to modify so much if at all.&nbsp;</p>\n\n\n\n<p>Running SONiC is not dependent on any vendors as signing entities. You\u2019re free to sign your image with your own private keys, so you know only the firmware you explicitly authorize can be installed. This also adds an extra layer against vendor lock-in. You can design your distribution to only run with certain vendors or boxes, applying one more knowledge barrier for an attacker to cross, as many boxes often require proprietary or special knowledge to access and use.&nbsp;</p>\n\n\n\n<p>Figure 1 shows the high-level architecture flow design for Secure Boot in SONiC. The production sign process works slightly differently from development, in which components are signed in an external signing server rather than within its own. An external signing server provides an isolated environment for extra security, scalability in large environments and controlled updates and management. At runtime, boot components are verified throughout the process.&nbsp;&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1159\" height=\"881\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic.jpg\" alt=\"This diagram shows the high-level development and production signing flow during the build process, and runtime flow when the system is booted. \n\" class=\"wp-image-91061\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic.jpg 1159w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-300x228.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-625x475.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-151x115.jpg 151w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-768x584.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-645x490.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-395x300.jpg 395w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-118x90.jpg 118w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-362x275.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-145x110.jpg 145w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/build-signing-process-sonic-1024x778.jpg 1024w\" sizes=\"(max-width: 1159px) 100vw, 1159px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Flow of the SONiC build signing process</em></figcaption></figure>\n\n\n\n<p><a href=\"https://github.com/sonic-net/SONiC/blob/master/doc/secure_boot/hld_secure_boot.md\">Read more about how Secure Boot works in SONiC</a> and how to implement it.</p>\n\n\n\n<h2 id=\"get_started_securing_your_boxes\"  class=\"wp-block-heading\">Get started securing your boxes<a href=\"#get_started_securing_your_boxes\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>NVIDIA strongly recommends using UEFI secure boot in any case due the increased security it enables. Reach out to your NVIDIA sales representative or <a href=\"https://www.nvidia.com/en-us/networking/support/\">NVIDIA Networking Support</a> for more information about how to implement Secure Boot.&nbsp;</p>\n\n\n\n<p>To learn more, check out the following resources:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://www.nvidia.com/en-us/on-demand/session/other2024-sonic/\">NVIDIA Pure SONiC Virtual Workshop</a></li>\n\n\n\n<li><a href=\"https://nvdam.widen.net/s/rcnnmcp8xg/networking-sonic-workshop-lab-guide-oct-2024\">NVIDIA SONiC Workshop Lab Walkthrough Guide</a></li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/blog/building-pure-sonic-image/\">Building your own SONiC Image</a></li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/blog/exploring-sonic-on-nvidia-air/\">Try SONiC on NVIDIA Air</a></li>\n\n\n\n<li><a href=\"https://github.com/sonic-net/SONiC/blob/master/doc/secure_boot/hld_secure_boot.md\">Secure Boot in SONiC Guide</a></li>\n\n\n\n<li><a href=\"https://github.com/sonic-net/sonic-buildimage/blob/master/rules/config\">SONiC Build Configuration Options</a></li>\n\n\n\n<li><a href=\"https://docs.nvidia.com/networking/display/bluefielddpubspv422/uefi+secure+boot\">Secure Boot on NVIDIA BlueField DPUs</a></li>\n</ul>\n", "protected": false}, "excerpt": {"rendered": "<p>NVIDIA technology helps organizations build and maintain secure, scalable, and high-performance network infrastructure. Advances in AI, with NVIDIA at the forefront, contribute every day to security advances. One way NVIDIA has taken a more direct approach to network security is through a secure network operating system (NOS). A secure network operating system (NOS) is a &hellip; <a href=\"https://developer.nvidia.com/blog/protect-your-network-with-secure-boot-in-sonic/\">Continued</a></p>\n", "protected": false}, "author": 2162, "featured_media": 91058, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1511166", "discourse_permalink": "https://forums.developer.nvidia.com/t/protect-your-network-with-secure-boot-in-sonic/311616", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1205], "tags": [1466, 1634, 453, 3566, 1641], "coauthors": [3885], "class_list": ["post-91056", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-networking-communications", "tag-bluefield", "tag-ethernet", "tag-featured", "tag-network-security", "tag-sonic"], "acf": {"post_industry": ["Hardware / Semiconductor"], "post_products": ["General"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["Best practice"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/data-center-sonic-logo.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nGE", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Networking / Communications", "link": "https://developer.nvidia.com/blog/category/networking-communications/", "id": 1205}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91056"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2162"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91056"}], "version-history": [{"count": 11, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91056/revisions"}], "predecessor-version": [{"id": 91326, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91056/revisions/91326"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91058"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91056"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91056"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91056"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91056"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91077, "date": "2024-10-29T10:56:55", "date_gmt": "2024-10-29T17:56:55", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91077"}, "modified": "2024-10-31T09:21:07", "modified_gmt": "2024-10-31T16:21:07", "slug": "ai-powered-devices-track-howls-to-save-wolves", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/ai-powered-devices-track-howls-to-save-wolves/", "title": {"rendered": "AI-Powered Devices Track Howls to Save Wolves"}, "content": {"rendered": "\n<p>A new cell-phone-sized device\u2014which can be deployed in vast, remote areas\u2014is using AI to identify and geolocate wildlife to help conservationists track endangered species, including wolves around Yellowstone National Park.&nbsp;</p>\n\n\n\n<p>The battery-powered devices\u2014dubbed GrizCams\u2014are designed by a small Montana startup, Grizzly Systems. Together with biologists, they\u2019re deploying a constellation of the devices across the Greater Yellowstone ecosystem to record audio and video of when and where wolves or wolf packs howl.&nbsp;</p>\n\n\n\n<p>Once fully deployed, the data can help scientists and conservationists better understand wolf behavior and create new strategies for deterring wolves from attacking livestock.</p>\n\n\n\n<p>Conservationists retrieve audio data from SD cards on remote recorders every few months. That data is fed into and analyzed by AI models trained using terabytes of data of howling wolves. The model\u2014a convolutional neural network\u2014converts the audio into a spectrogram, which analyzes the data, identifying different aspects of a wolf\u2019s howl and geolocating where the sounds originated.\u00a0</p>\n\n\n\n<p>Grizzly Systems trained the model using <a href=\"https://www.nvidia.com/en-us/data-center/a100/\">NVIDIA A100 Tensor Core GPUs</a> in the Azure cloud and PyTorch framework running <a href=\"https://developer.nvidia.com/gpu-accelerated-libraries\">NVIDIA CUDA-X libraries</a>. For inferencing, they use <a href=\"https://developer.nvidia.com/triton-inference-server\">NVIDIA Triton Inference Server</a> and ONNX Runtime for model optimization, with an <a href=\"https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/\">NVIDIA RTX 4090</a> for on-prem storage of sensitive data and local inference.\u00a0</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/3bu8lN0uvtI?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;start=7&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. A wolf pack recorded in 2023 in Yellowstone National Park vocalizes in chorus and asynchronously</em></figcaption></figure>\n\n\n\n<p class=\"has-text-align-left\">Grizzly Systems CEO, Jeff Reed, PhD, highlighted how the system monitors large tracts of land 24 hours a day, every day of the year. The devices can help perennially under-resourced wildlife managers and state and federal agencies monitor lands that often lack personnel.</p>\n\n\n\n<p>The AI model can identify varied pitches and intonations of wolf vocalizations, which can carry more than six kilometers from where they originate. Knowing where a pack moves by tracking their howls can help conservationists identify a wolf\u2019s territorial boundaries.\u00a0</p>\n\n\n\n<p>While the model can\u2019t yet identify individual wolves from their howls, Reed said future iterations of the technology will have that capability.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" width=\"975\" height=\"548\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam.png\" alt=\"A workflow showing pictures of animals, representing data the GrizCam picks up, and, next to those images, a sketch representing how the GrizCam hardware and software process that data and share it with cloud-based LLMs for analysis.\" class=\"wp-image-91078\" style=\"width:841px;height:auto\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam.png 975w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-300x169.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-625x351.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-179x101.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-768x432.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-645x363.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-362x203.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/Diagram-GrizCam-196x110.png 196w\" sizes=\"(max-width: 975px) 100vw, 975px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. GrizCam collects sounds or video, runs through an on-device thin model layer, and analyzes data on a cloud-based LLM</em></figcaption></figure></div>\n\n\n<p>Today, the GrizCams make up one part of a larger conservation effort aimed at balancing competing interests in the land.&nbsp;</p>\n\n\n\n<p>These include the small but growing wolf population in Montana, which needs wild prey for food; the billion-dollar Yellowstone eco-tourism economy, which relies upon healthy wildlife populations; and the ranchers who need to protect their livestock, and whose land offers critical habitat for wildlife.</p>\n\n\n\n<p>\u201cWolves, grizzlies, elk can be a hassle to a rancher because they might kill their livestock, or tear down their fences,\u201d said Reed, who before starting up Grizzly Systems three years ago, spent his career working in the tech industry. \u201cOn the flip side, those ranches also provide critical habitat for wildlife on private lands around Yellowstone.</p>\n\n\n\n<p>\u201cIf our devices can detect a lone wolf coming through a ranchland because we have AI on it, then we can playback the sound of guardian dogs barking, or a gunshot, or a large territorial wolf pack, which can \u201cencourage\u201d that wolf to move out of that area. But that requires vigilance throughout the day and the night\u2014and nobody is sitting outside 24/7\u2014which is where AI comes in.\u201d</p>\n\n\n\n<p>Another way AI is helping conservationists is by streamlining the data collection process.&nbsp;</p>\n\n\n\n<p>The remote recorders\u2014which can also be deployed with video capabilities\u2014run a very thin-layer AI on-device, which weeds out most motion that would otherwise trigger false-positive recordings. The recorders can ignore wind rustling through grass or trees, or bright light reflecting off snow\u2014two common stimuli that trigger false-positive recordings on remote devices.</p>\n\n\n\n<p>As a result, the GrizCam\u2019s batteries last longer and require less servicing by wildlife managers and landowners.</p>\n\n\n\n<p>AI is also useful to conservationists as it quickly sifts through terabytes of recorded data to quickly identify and flag relevant audio or visual signatures.&nbsp;</p>\n\n\n\n<p>While the on-device AI cuts down on unwanted recordings, it nevertheless records sounds and imagery of biological activity\u2014including birds, elk, or bears moving across terrain and making noises.&nbsp;&nbsp;</p>\n\n\n\n<p>\u201cThese acoustic recorders are gathering data with AI, they\u2019re recording 24-7, every day for a year across 50 or so recorders,\u201d said Reed. \u201cWith AI, we can crunch through the data, go through and identify wolves or other endangered species if they\u2019re there, and then work with conservationists to say, \u2018okay, we gotta go protect this area and do some additional conservation over there.\u2019\u201d</p>\n\n\n\n<p>Grizzly Systems plans to continue its close collaboration with conservationists. It also foresees its rugged edge devices&#8217; relevance for a variety of industrial use cases, including remote surveillance.</p>\n\n\n\n<p>Reed points out that 97% of the Earth\u2019s surface lacks access to an electrical outlet. A rugged recorder can monitor oil and gas rigs, as well as remote electrical transformers, which, in very rural areas, can attract vandals who take them offline.&nbsp;&nbsp;</p>\n\n\n\n<p>\u201cAI is a great example of how, if we can get it right, with battery life and ruggedness, we can monitor illegal activity that hurts us all,\u201d Reed said. \u201cPoaching, illegal wildlife trafficking, illegal logging or mining in the Amazon\u2014 this is activity that ends up hurting the vast majority of people and the planet\u2013and which technology can help prevent.\u201d</p>\n\n\n\n<p>Read more about the <a href=\"https://www.thelanguagesoflife.com/crywolf\">partnership</a> between Grizzly Systems and Yellowstone National Park.</p>\n\n\n\n<p>Check out additional reporting on <a href=\"https://www.washingtonpost.com/climate-solutions/2024/10/12/yellowstone-wolves-howls-bioacoustics/\">wolf conservation</a> and <a href=\"https://yellowstonian.org/the-secret-chorus-language-of-yellowstone-wolves/\">decoding wolf verbalizations</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>A new cell-phone-sized device\u2014which can be deployed in vast, remote areas\u2014is using AI to identify and geolocate wildlife to help conservationists track endangered species, including wolves around Yellowstone National Park.&nbsp; The battery-powered devices\u2014dubbed GrizCams\u2014are designed by a small Montana startup, Grizzly Systems. Together with biologists, they\u2019re deploying a constellation of the devices across the Greater &hellip; <a href=\"https://developer.nvidia.com/blog/ai-powered-devices-track-howls-to-save-wolves/\">Continued</a></p>\n", "protected": false}, "author": 2156, "featured_media": 91093, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1511091", "discourse_permalink": "https://forums.developer.nvidia.com/t/ai-powered-devices-track-howls-to-save-wolves/311595", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724, 2758, 3110, 1903], "tags": [3941, 453], "coauthors": [3876], "class_list": ["post-91077", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-computer-vision", "category-edge-computing", "category-generative-ai", "category-features", "tag-ai-impact", "tag-featured"], "acf": {"post_industry": ["Smart Cities / Spaces"], "post_products": ["A100", "RTX GPU", "Triton Inference Server"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["Spotlight"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/wolf-howling-e1730224047800.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nGZ", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91077"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2156"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91077"}], "version-history": [{"count": 9, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91077/revisions"}], "predecessor-version": [{"id": 91097, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91077/revisions/91097"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91093"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91077"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91077"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91077"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91077"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90647, "date": "2024-10-29T09:00:00", "date_gmt": "2024-10-29T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90647"}, "modified": "2024-10-31T11:32:20", "modified_gmt": "2024-10-31T18:32:20", "slug": "enhanced-security-and-streamlined-deployment-of-ai-agents-with-nvidia-ai-enterprise", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/enhanced-security-and-streamlined-deployment-of-ai-agents-with-nvidia-ai-enterprise/", "title": {"rendered": "Enhanced Security and Streamlined Deployment of AI Agents with NVIDIA AI Enterprise"}, "content": {"rendered": "\n<p>AI agents are emerging as the newest way for organizations to increase efficiency, improve productivity, and accelerate innovation. These agents are more advanced than prior AI applications, with the ability to autonomously reason through tasks, call out to other tools, and incorporate both enterprise data and employee knowledge to produce valuable business outcomes. They\u2019re being embedded into applications customized for each organization&#8217;s needs.&nbsp;</p>\n\n\n\n<p>The latest release of <a href=\"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\">NVIDIA AI Enterprise</a> includes several new features that help make AI agents more secure, stable, and easier to deploy.</p>\n\n\n\n<h2 id=\"simplified_management_of_ai_agent_pipelines\"  class=\"wp-block-heading\">Simplified management of AI agent pipelines<a href=\"#simplified_management_of_ai_agent_pipelines\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The newly launched <a href=\"https://developer.nvidia.com/blog/managing-ai-inference-pipelines-on-kubernetes-with-nvidia-nim-operator/\">NVIDIA NIM Operator</a> simplifies the deployment and management of <a href=\"https://www.nvidia.com/en-us/ai/\">NIM microservices</a> used to deploy AI pipelines on Kubernetes. NIM Operator automates the deployment of AI pipelines and enhances performance with capabilities such as intelligent model pre-caching for lower initial inference latency and faster autoscaling.&nbsp;</p>\n\n\n\n<p>You can choose to autoscale based on CPU, GPU, or NIM-specific metrics, such as NIM max requests, KVcache, and so on.&nbsp;</p>\n\n\n\n<p>It also simplifies the upgrade process by providing easy rolling upgrades. Change the version number of the NIM microservice and the NIM Operator updates the deployments in the cluster.&nbsp;</p>\n\n\n\n<p>NVIDIA now offers the following deployment paths to deploy NIM microservices for production AI pipelines:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://docs.nvidia.com/nim/large-language-models/latest/deploy-helm.html\">Helm</a></li>\n\n\n\n<li><a href=\"https://blogs.nvidia.com/blog/kserve-nim-inference/\">KServe</a></li>\n\n\n\n<li><a href=\"https://docs.nvidia.com/nim-operator/latest/index.html\">NIM Operator</a>&nbsp;</li>\n</ul>\n\n\n\n<h2 id=\"security_and_api_stability_for_ai_models\"  class=\"wp-block-heading\">Security and API stability for AI models<a href=\"#security_and_api_stability_for_ai_models\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>NVIDIA AI Enterprise includes monthly feature branch releases for AI and data science software which contain top-of-tree software updates and are ideal for AI developers who want the latest features.&nbsp;</p>\n\n\n\n<p>This software is maintained by NVIDIA for one month until the next version is released, and available security fixes are applied before each release. Although this is great for customers who want to stay on the leading edge with the newest capabilities, there\u2019s no guarantee that APIs will not change from month to month. This can make it challenging to build enterprise solutions that need to be both secure and reliable over time, as developers may need to adjust applications after an update.</p>\n\n\n\n<p>To address this need, NVIDIA AI Enterprise also includes <a href=\"https://docs.nvidia.com/ai-enterprise/planning-resource/release-branches/latest/release-branches.html\">production branches</a> of AI software. Production branches ensure API stability and regular security updates and are meant for deploying AI in production when stability is required. Production branches are released every 6 months and have a 9-month lifecycle.&nbsp;</p>\n\n\n\n<p>Throughout the 9-month lifecycle of each production branch, NVIDIA continuously monitors critical and high common vulnerabilities and exposures (CVEs) and releases monthly security patches. By doing so, the AI frameworks, libraries, models, and tools included in NVIDIA AI Enterprise can be updated for security fixes while eliminating the risk of breaking an API.&nbsp;</p>\n\n\n\n<p>The new release is expected to add these NIM microservices to production branches:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Meta\u2019s Llama 3.1 family of models:\n<ul class=\"wp-block-list\">\n<li>Llama-3.1-Instruct-8B</li>\n\n\n\n<li>Llama-3.1-Instruct-70B</li>\n\n\n\n<li>Llama-3.1-Instruct-405B</li>\n</ul>\n</li>\n\n\n\n<li>Mistral AI\u2019s Mistral 7B and mixture of experts (MoE) 8x7B and 8x22B models:\n<ul class=\"wp-block-list\">\n<li>Mixtral-8x7B</li>\n\n\n\n<li>Mixtral-8x22B</li>\n\n\n\n<li>Mistral-7B</li>\n</ul>\n</li>\n\n\n\n<li>NVIDIA Nemotron-4-340B family of models for synthetic data generation:\n<ul class=\"wp-block-list\">\n<li>Nemotron-4-340B-Instruct</li>\n\n\n\n<li>Nemotron-4-340B-Reward</li>\n</ul>\n</li>\n\n\n\n<li>NVIDIA NeMo Retriever QA E5 Embedding v5 text embedding model:\n<ul class=\"wp-block-list\">\n<li>NV-EmbedQA-E5-v5</li>\n</ul>\n</li>\n</ul>\n\n\n\n<p>You can build AI agents using these microservices with the confidence that NVIDIA will secure and maintain them without breaking any application dependencies during the lifetime of that production branch.</p>\n\n\n\n<p>These NIM microservices join numerous other AI libraries and frameworks already on a production branch:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>PyTorch</li>\n\n\n\n<li>TensorFlow</li>\n\n\n\n<li>RAPIDS</li>\n\n\n\n<li>NVIDIA TensorRT</li>\n\n\n\n<li>NVIDIA Triton Inference Server</li>\n\n\n\n<li>NVIDIA Morpheus</li>\n\n\n\n<li>NVIDIA Holoscan</li>\n</ul>\n\n\n\n<p>Other AI frameworks that are new to a production branch with this release include the following:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Deepstream for AI-based video and image understanding and multi-sensor processing</li>\n\n\n\n<li>DGL and PyG for training graph neural networks</li>\n</ul>\n\n\n\n<h2 id=\"ai_for_healthcare\"  class=\"wp-block-heading\">AI for healthcare<a href=\"#ai_for_healthcare\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Customers in highly regulated industries often require software to be supported for even longer periods. For these customers, NVIDIA AI Enterprise also includes long-term support branches (LTSB), which are supported with stable APIs for 3 years.</p>\n\n\n\n<p>LTSB 1 coincided with the first release of NVIDIA AI Enterprise in 2021 and includes foundational AI components:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>PyTorch</li>\n\n\n\n<li>TensorFlow</li>\n\n\n\n<li>RAPIDS</li>\n\n\n\n<li>TensorRT</li>\n\n\n\n<li>Triton Inference Server</li>\n\n\n\n<li>Infrastructure software, such as vGPU driver</li>\n</ul>\n\n\n\n<p>LTSB 2, as part of this latest release of NVIDIA AI Enterprise, adds <a href=\"https://www.nvidia.com/en-us/clara/holoscan/\">Holoscan</a>, which includes Holoscan SDK and Holoscan Deployment Stack.</p>\n\n\n\n<p>Holoscan is the NVIDIA AI sensor processing platform that combines hardware systems for low-latency sensor and network connectivity, optimized libraries for data processing and AI, and core capabilities to run real-time streaming, imaging, and other applications.&nbsp; Holoscan SDK includes C++ and Python APIs to create sensor processing workflows with inherent support for sensor I/O, compute, AI inferencing, and visualization, while leveraging NVIDIA GPU acceleration.&nbsp;</p>\n\n\n\n<p>One of the most prevalent uses of Holoscan is for medical devices, such as those for medical imaging and robotic surgery. As medical devices have strict requirements for long-term supportability, the addition of Holoscan to long-term support combined with long-life hardware enables device manufacturers to build the next generation of intelligent AI-enabled medical devices, with faster time to market and lower cost of maintenance.&nbsp;</p>\n\n\n\n<p>The Holoscan platform with LTSB is an effective solution for other industries beyond medical devices, wherever an industrial-grade production-ready platform is needed to build AI-enabled sensor processing products.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"399\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-1024x399.png\" alt=\"The diagram shows the relationship between feature, production, and long-term support branch by month.\" class=\"wp-image-90652\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-1024x399.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-300x117.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-625x243.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-179x70.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-768x299.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-1536x598.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-645x251.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-500x195.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-160x62.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-362x141.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options-283x110.png 283w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-support-branch-options.png 1999w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Software support branch options in NVIDIA AI Enterprise</em></figcaption></figure></div>\n\n\n<h2 id=\"more_ways_to_deploy_nim_microservices\"  class=\"wp-block-heading\">More ways to deploy NIM microservices<a href=\"#more_ways_to_deploy_nim_microservices\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>NVIDIA AI Enterprise is supported o both on-premises and public cloud services. You can deploy NIM microservices and other software containers into self-managed Kubernetes running on cloud instances, but many prefer to use Kubernetes managed by the cloud provider.&nbsp;</p>\n\n\n\n<p>Google Cloud has now integrated <a href=\"https://developer.nvidia.com/blog/scale-high-performance-ai-inference-with-google-kubernetes-engine-and-nvidia-nim/\">NVIDIA NIM into Google Kubernetes Engine</a> to provide enterprise customers with a simplified path for deploying optimized models directly from the Google Cloud Marketplace.</p>\n\n\n\n<h2 id=\"availability\"  class=\"wp-block-heading\">Availability<a href=\"#availability\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The next version of NVIDIA AI Enterprise is available now. License holders can download production branch versions of most AI software containers right away but the NIM microservices are expected to be added to the production branch at the end of November. As always, you also get the benefit of enterprise support, which includes guaranteed response times and access to NVIDIA experts for timely issue resolution.\u00a0</p>\n\n\n\n<p>For more information, see <a href=\"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/get-started/\">NVIDIA AI Enterprise Getting Started</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>AI agents are emerging as the newest way for organizations to increase efficiency, improve productivity, and accelerate innovation. These agents are more advanced than prior AI applications, with the ability to autonomously reason through tasks, call out to other tools, and incorporate both enterprise data and employee knowledge to produce valuable business outcomes. They\u2019re being &hellip; <a href=\"https://developer.nvidia.com/blog/enhanced-security-and-streamlined-deployment-of-ai-agents-with-nvidia-ai-enterprise/\">Continued</a></p>\n", "protected": false}, "author": 1379, "featured_media": 90651, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1511021", "discourse_permalink": "https://forums.developer.nvidia.com/t/enhanced-security-and-streamlined-deployment-of-ai-agents-with-nvidia-ai-enterprise/311576", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [4150, 3110], "tags": [3965, 453], "coauthors": [2784], "class_list": ["post-90647", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-deployment", "category-generative-ai", "tag-ai-agent", "tag-featured"], "acf": {"post_industry": ["General"], "post_products": ["AI Enterprise", "NIM"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvaie-kv-press-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nA3", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90647"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1379"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90647"}], "version-history": [{"count": 7, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90647/revisions"}], "predecessor-version": [{"id": 91070, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90647/revisions/91070"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90651"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90647"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90647"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90647"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90647"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 91036, "date": "2024-10-28T12:23:49", "date_gmt": "2024-10-28T19:23:49", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=91036"}, "modified": "2024-10-31T11:32:58", "modified_gmt": "2024-10-31T18:32:58", "slug": "upcoming-webinar-enhance-generative-ai-model-accuracy-through-high-quality-data-processing", "status": "publish", "type": "post", "link": "https://nvda.ws/3UreHhQ", "title": {"rendered": "Upcoming Webinar: Enhance Generative AI Model Accuracy Through High-Quality Data Processing"}, "content": {"rendered": "\n<p>Learn how to build scalable data processing pipelines to create high-quality datasets.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Learn how to build scalable data processing pipelines to create high-quality datasets.</p>\n", "protected": false}, "author": 1921, "featured_media": 91037, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1510279", "discourse_permalink": "https://forums.developer.nvidia.com/t/upcoming-webinar-enhance-generative-ai-model-accuracy-through-high-quality-data-processing/311428", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/3UreHhQ", "_links_to_target": "_blank"}, "categories": [3110], "tags": [791, 453, 1958], "coauthors": [3612], "class_list": ["post-91036", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-generative-ai", "tag-data-preprocessing", "tag-featured", "tag-news"], "acf": {"post_industry": ["General"], "post_products": ["NeMo", "NeMo Curator"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["News"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llm-social-nemo-retriever-webinar-content-3450414-1600x900-1.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nGk", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Data Science", "link": "https://developer.nvidia.com/blog/category/data-science/", "id": 696}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91036"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1921"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=91036"}], "version-history": [{"count": 3, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91036/revisions"}], "predecessor-version": [{"id": 91041, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/91036/revisions/91041"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/91037"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=91036"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=91036"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=91036"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=91036"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90842, "date": "2024-10-28T11:30:00", "date_gmt": "2024-10-28T18:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90842"}, "modified": "2024-10-31T11:33:13", "modified_gmt": "2024-10-31T18:33:13", "slug": "an-introduction-to-model-merging-for-llms", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/an-introduction-to-model-merging-for-llms/", "title": {"rendered": "An Introduction to Model Merging for LLMs"}, "content": {"rendered": "\n<p>One challenge organizations face when customizing <a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\">large language models (LLMs)</a> is the need to run multiple experiments, which produces only one useful model. While the cost of experimentation is typically low, and the results well worth the effort, this experimentation process does involve \u201cwasted\u201d resources, such as compute assets spent without their product being utilized, dedicated developer time, and more.</p>\n\n\n\n<p>Model merging combines the weights of multiple customized LLMs, increasing resource utilization and adding value to successful models. This approach provides two key solutions:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Reduces experimentation waste by repurposing &#8220;failed experiments&#8221;</li>\n\n\n\n<li>Offers a cost-effective alternative to join training</li>\n</ul>\n\n\n\n<p>This post explores how models are customized, how model merging works, different types of model merging, and how model merging is iterating and evolving.</p>\n\n\n\n<h2 id=\"revisiting_model_customization&nbsp;\"  class=\"wp-block-heading\">Revisiting model customization&nbsp;<a href=\"#revisiting_model_customization&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>This section provides a brief overview of how models are customized and how this process can be leveraged to help build an intuitive understanding of model merging.&nbsp;</p>\n\n\n\n<p>Note that some of the concepts discussed are oversimplified for the purpose of building this intuitive understanding of model merging. It is suggested that you familiarize yourself with customization techniques, transformer architecture, and training separately before diving into model merging. See, for example, <a href=\"https://developer.nvidia.com/blog/selecting-large-language-model-customization-techniques/\">Mastering LLM Techniques: Customization</a>.&nbsp;</p>\n\n\n\n<h3 id=\"the_role_of_weight_matrices_in_models\"  class=\"wp-block-heading\">The role of weight matrices in models<a href=\"#the_role_of_weight_matrices_in_models\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Weight matrices are essential components in many popular model architectures, serving as large grids of numbers (weights, or parameters) that store the information necessary for the model to make predictions.</p>\n\n\n\n<p>As data flows through a model, it passes through multiple layers, each containing its own weight matrix. These matrices transform the input data through mathematical operations, enabling the model to learn from and adapt to the data.</p>\n\n\n\n<p>To modify a model\u2019s behavior, the weights within these matrices must be updated. Although the specifics of weight modification are not essential, it\u2019s crucial to understand that each customization of a base model results in a unique set of updated weights.</p>\n\n\n\n<h3 id=\"task_customization\"  class=\"wp-block-heading\">Task customization<a href=\"#task_customization\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>When fine-tuning an LLM for a specific task, such as summarization or math, the updates made to the weight matrices are targeted towards improving performance on that particular task. This implies that the modifications to the weight matrices are localized to specific regions, rather than being uniformly distributed.</p>\n\n\n\n<p>To illustrate this concept, consider a simple analogy where the weight matrices are represented as a sports field that is 100 yards in length. When customizing the model for summarization, the updates to the weight matrices might concentrate on specific areas, such as the 10-to-30 yard lines. In contrast, customizing the model for math might focus updates on a different region, like the 70-to-80 yard lines.</p>\n\n\n\n<p>Interestingly, when customizing the model for a related task, such as summarization in the French language, the updates might overlap with the original summarization task, affecting the same regions of the weight matrices (the 25-to-35 yard lines, for example). This overlap suggests an important insight: different task customizations can significantly impact the same areas of the weight matrices.</p>\n\n\n\n<p>While the previous example is purposefully oversimplified, the intuition is accurate. Different task customizations will lead to different parts of the weight matrices being updated, and customization for similar tasks might lead to changing the same parts of their respective weight matrices.</p>\n\n\n\n<p>This understanding can inform strategies for customizing LLMs and leveraging knowledge across tasks.</p>\n\n\n\n<h2 id=\"model_merging\"  class=\"wp-block-heading\">Model merging<a href=\"#model_merging\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Model merging is a loose grouping of strategies that relates to combining two or more models, or model updates, into a single model for the purpose of saving resources or improving task-specific performance.&nbsp;</p>\n\n\n\n<p>This discussion focuses primarily on the implementation of these techniques through an open-source library developed by <a href=\"https://www.arcee.ai/\">Arcee AI</a> called <a href=\"https://github.com/arcee-ai/mergekit\">mergekit</a>. This library simplifies the implementation of various merging strategies.&nbsp;</p>\n\n\n\n<p>Many methods are used to merge models, in various levels of complexity. Here, we\u2019ll focus on four main merging methods:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Model Soup</li>\n\n\n\n<li>Spherical Linear Interpolation (SLERP)</li>\n\n\n\n<li>Task Arithmetic (using Task Vectors)</li>\n\n\n\n<li>TIES leveraging DARE</li>\n</ol>\n\n\n\n<h3 id=\"model_soup\"  class=\"wp-block-heading\">Model Soup<a href=\"#model_soup\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The Model Soup method involves averaging the resultant model weights created by hyperparameter optimization experiments, as explained in <a href=\"https://arxiv.org/abs/2203.05482\">Model Soups: Averaging Weights of Multiple Fine-Tuned Models Improves Accuracy Without Increasing Inference Time</a>.</p>\n\n\n\n<p>Originally tested and verified through computer vision models, this method has shown promising results for LLMs as well. In addition to generating some additional value out of the experiments, this process is simple and not compute intensive.&nbsp;</p>\n\n\n\n<p>There are two ways to create Model Soup: naive and greedy. The naive approach involves merging all models sequentially, regardless of their individual performance. In contrast, the greedy implementation follows a simple algorithm:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Rank models by performance on the desired task</li>\n\n\n\n<li>Merge the best performing model with the second best performing model</li>\n\n\n\n<li>Evaluate the merged model\u2019s performance on the desired task</li>\n\n\n\n<li>If the merged model performs better, continue with the next model; otherwise, skip the current model and try again with the next best model</li>\n</ul>\n\n\n\n<p>This greedy approach ensures that the resulting Model Soup is at least as good as the best individual model.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"625\" height=\"452\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-625x452.png\" alt=\"Graph showing performance along two axes, accuracy and generalization.\" class=\"wp-image-90964\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-625x452.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-300x217.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-159x115.png 159w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-768x556.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-645x467.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-415x300.png 415w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-124x90.png 124w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-362x262.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method-152x110.png 152w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-soup-method.png 807w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. The Model Soup method outperforms the constituent models using the greedy model Soup Model merging technique&nbsp;</em></em></figcaption></figure></div>\n\n\n<p>Each step of creating a Model Soup is implemented by simple weighted and normalized linear averaging of two or more model weights. Both the weighting and normalization are optional, though recommended. The implementation of this from the <code>mergekit</code> library is as follows:&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nres = (weights * tensors).sum(dim=0)\nif self.normalize:\n\tres = res / weights.sum(dim=0)\n</pre></div>\n\n\n<p>While this method has shown promising results in the computer vision and language domains, it faces some serious limitations. Specifically, there is no guarantee that the model will be more performant. The linear averaging can lead to degraded performance or loss of generalizability.&nbsp;</p>\n\n\n\n<p>The next method, SLERP, addresses some of those specific concerns.</p>\n\n\n\n<h3 id=\"slerp&nbsp;\"  class=\"wp-block-heading\">SLERP&nbsp;<a href=\"#slerp&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Spherical Linear Interpolation, or SLERP, is a method introduced in a 1985 paper titled <a href=\"https://www.cs.cmu.edu/~kiranb/animation/p245-shoemake.pdf\">Animating Rotation with Quaternion Curves</a>. It\u2019s a \u201csmarter\u201d way of computing the average between two vectors. In a technical sense, it helps compute the shortest path between two points on a curved surface.&nbsp;</p>\n\n\n\n<p>This method excels at combining two models. The classic example is imagining the shortest path between two points on the Earth. Technically, the shortest path would be a straight line that goes through the Earth, but in reality it\u2019s a curved path on the surface of the Earth. SLERP computes this smooth path to use for averaging two models together while maintaining their unique model weight \u201csurfaces.\u201d</p>\n\n\n\n<p>The following code snippet is the core of the SLERP algorithm, and is what provides such a good interpolation between the two models:&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n# Calculate initial angle between v0 and v1\ntheta_0 = np.arccos(dot)\nsin_theta_0 = np.sin(theta_0)\n\n# Angle at timestep t\ntheta_t = theta_0 * t\nsin_theta_t = np.sin(theta_t)\n\n# Finish the slerp algorithm\ns0 = np.sin(theta_0 - theta_t) / sin_theta_0\ns1 = sin_theta_t / sin_theta_0\nres = s0 * v0_copy + s1 * v1_copy\n\nreturn maybe_torch(res, is_torch)\n</pre></div>\n\n\n<h3 id=\"task_arithmetic_using_task_vectors\"  class=\"wp-block-heading\">Task Arithmetic (using Task Vectors)<a href=\"#task_arithmetic_using_task_vectors\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>This group of model merging methods utilizes Task Vectors to combine models in various ways, increasing in complexity.</p>\n\n\n\n<h4 class=\"wp-block-heading\">Task Vectors: Capturing customization updates</h4>\n\n\n\n<p>Recalling how models are customized, updates are made to the model\u2019s weights, and those updates are captured in the base model matrices. Instead of considering the final matrices as a brand new model, they can be viewed as the difference (or delta) between the base weights and the customized weights. This introduces the concept of a task vector,a structure containing the delta between the base and customized weights.</p>\n\n\n\n<p>This is the same intuition behind Low Rank Adaptation (LoRA), but without the further step of factoring the matrices representing the weight updates.&nbsp;</p>\n\n\n\n<p>Task Vectors can be simply obtained from customization weights by subtracting out the base model weights.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">Task Interference: Conflicting updates</h4>\n\n\n\n<p>Recalling the sports field example, there is a potential for overlap in the updated weights between different customizations. There is some intuitive understanding that customization done for the same task would lead to a higher rate of conflicting updates than customization done for two, or more, separate tasks.</p>\n\n\n\n<p>This \u201cconflicting update\u201d idea is more formally defined as Task Interference and it relates to the potential collision of important updates between two, or more, Task Vectors.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">Task Arithmetic</h4>\n\n\n\n<p>As introduced in the paper <a href=\"https://arxiv.org/abs/2212.04089\">Editing Models with Task Arithmetic</a>, Task Arithmetic represents the simplest implementation of a task vector approach. The process is as follows:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Obtain two or more task vectors and merge them linearly as seen in Model Soup.&nbsp;</li>\n\n\n\n<li>After the resultant merged task vector is obtained, it is added into the base model.</li>\n</ol>\n\n\n\n<p>This process is simple and effective, but has a key weakness: no attention is paid to the potential interference between the task vectors intended to be merged.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">TIES-Merging</h4>\n\n\n\n<p>As introduced in the paper <a href=\"https://arxiv.org/abs/2306.01708\">TIES-Merging: Resolving Interference When Merging Models</a>, TIES (TrIm Elect Sign and Merge) is a method that takes the core ideas of Task Arithmetic and combines it with heuristics for resolving potential interference between the Task Vectors.&nbsp;</p>\n\n\n\n<p>The general procedure is to consider, for each weight in the Task Vectors being merged, the magnitude of each incoming weight, then the sign of each incoming weight, and then averaging the remaining weights.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"759\" height=\"290\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram.png\" alt=\"Diagram of the TIES process, including examples of each step and the final set of Task Vectors\n\" class=\"wp-image-90847\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram.png 759w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-300x115.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-625x239.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-179x68.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-645x246.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-500x191.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-160x61.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-362x138.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/ties-process-diagram-288x110.png 288w\" sizes=\"(max-width: 759px) 100vw, 759px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 2. A visual representation of the TIES process</em></em></figcaption></figure>\n\n\n\n<p>This method seeks to resolve interference by enabling the models that had the most significant weight updates for any given weight update take precedence during the merging process. In essence, the models that \u201ccared\u201d more about that weight would be prioritized over the models that did not.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">DARE</h4>\n\n\n\n<p>Introduced in the paper <a href=\"https://arxiv.org/abs/2311.03099\">Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</a>, DARE isn\u2019t directly a model merging technique. Rather, it\u2019s an augment that can be considered alongside other approaches. DARE derives from the following:</p>\n\n\n\n<p><strong>D</strong>rops delta parameters with a ratio p <strong>A</strong>nd <strong>RE</strong>scales the remaining ones by 1/(1 &#8211; p) to approximate the original embeddings.</p>\n\n\n\n<p>Instead of trying to address the problem of interference through heuristics, DARE approaches it from a different perspective. In essence, it randomly drops a large number of the updates found in a specific task vector by setting them to 0, and then rescales the remaining weight proportional to the ratio of the dropped weights.</p>\n\n\n\n<p>DARE has been shown to be effective even when dropping upwards of 90%, or even 99% of the task vector weights.&nbsp;</p>\n\n\n\n<h2 id=\"increase_model_utility_with_model_merging\"  class=\"wp-block-heading\">Increase model utility with model merging<a href=\"#increase_model_utility_with_model_merging\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The concept of model merging offers a practical way to maximize the utility of multiple LLMs, including task-specific fine-tuning done by a larger community. Through techniques like Model Soup, SLERP, Task Arithmetic, TIES-Merging, and DARE, organizations can effectively merge multiple models in the same family in order to reuse experimentation and cross-organizational efforts.&nbsp;</p>\n\n\n\n<p>As the techniques behind model merging are better understood and further developed, they are poised to become a cornerstone of the development of performant LLMs. While this post has only scratched the surface, more techniques are constantly under development, including some <a href=\"https://arxiv.org/abs/2403.13187\">evolution-based methods</a>. Model merging is a budding field in the generative AI landscape, as more applications are being tested and proven.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>One challenge organizations face when customizing large language models (LLMs) is the need to run multiple experiments, which produces only one useful model. While the cost of experimentation is typically low, and the results well worth the effort, this experimentation process does involve \u201cwasted\u201d resources, such as compute assets spent without their product being utilized, &hellip; <a href=\"https://developer.nvidia.com/blog/an-introduction-to-model-merging-for-llms/\">Continued</a></p>\n", "protected": false}, "author": 2077, "featured_media": 90844, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1510264", "discourse_permalink": "https://forums.developer.nvidia.com/t/an-introduction-to-model-merging-for-llms/311425", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [3110, 4147], "tags": [453, 3650], "coauthors": [3791, 3328], "class_list": ["post-90842", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-generative-ai", "category-models", "tag-featured", "tag-llm-techniques"], "acf": {"post_industry": ["General"], "post_products": ["General"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["Tutorial"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llm-icons.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nDc", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90842"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2077"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90842"}], "version-history": [{"count": 8, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90842/revisions"}], "predecessor-version": [{"id": 90965, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90842/revisions/90965"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90844"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90842"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90842"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90842"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90842"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90872, "date": "2024-10-28T09:00:00", "date_gmt": "2024-10-28T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90872"}, "modified": "2024-11-11T12:00:23", "modified_gmt": "2024-11-11T20:00:23", "slug": "creating-rag-based-question-and-answer-llm-workflows-at-nvidia", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/creating-rag-based-question-and-answer-llm-workflows-at-nvidia/", "title": {"rendered": "Creating RAG-Based Question-and-Answer LLM Workflows at NVIDIA"}, "content": {"rendered": "\n<p>The rapid development of solutions using retrieval augmented generation (RAG) for question-and-answer LLM workflows has led to new types of system architectures. Our work at NVIDIA using AI for internal operations has led to several important findings for finding alignment between system capabilities and user expectations.&nbsp;</p>\n\n\n\n<p>We found that regardless of the intended scope or use case, users generally want to be able to execute non-RAG tasks like performing document translation, editing emails, or even writing code. A vanilla RAG application might be implemented so that it executes a retrieval pipeline on every message, leading to excess usage of tokens and unwanted latency as irrelevant results are included.&nbsp;</p>\n\n\n\n<p>We also found that users really appreciate having access to a web search and summarization capability, even if the application is designed for accessing internal private data. As a example, we used <a href=\"https://docs.perplexity.ai/home\">Perplexity\u2019s search API </a>to meet this need.</p>\n\n\n\n<p>In this post, we share a basic architecture for addressing these issues, using routing and multi-source RAG to produce a chat application that is capable of answering a broad range of questions. This is a slimmed-down version of an application and there are many ways to build a RAG-based application, but this can help get you going. For more information, see the <a href=\"https://github.com/NVIDIA/GenerativeAIExamples/tree/main/community/routing-multisource-rag\">/NVIDIA/GenerativeAIExamples</a> GitHub repo.</p>\n\n\n\n<p>In particular, we highlight how to use LlamaIndex, NVIDIA NIM microservices, and Chainlit to rapidly deploy this application. You can use this project as inspiration for the <a href=\"https://developer.nvidia.com/llamaindex-developer-contest\">NVIDIA and LlamaIndex Developer Contest</a>, showcasing innovative uses of these technologies in real-world applications and a chance to win exciting prizes.</p>\n\n\n\n<p>We found a tremendous amount of synergy between these technologies. NVIDIA NIM microservices and their LlamaIndex connectors make it effortless to develop LLM applications with self-managed or hosted LLMs. Chainlit and LlamaIndex <code>Workflow</code> events fit together nicely due to their shared event-driven architecture, which makes it easy to provide a user interface with detailed information on the full trace of an LLM response. We outline more of the system details in this post.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"700\" height=\"507\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow.png\" alt=\"A flowchart shows components including Chainlit for user interface and chat history, and LlamaIndex for dense retrieval, web search, and query routing.\" class=\"wp-image-90920\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow.png 700w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-300x217.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-625x453.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-159x115.png 159w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-645x467.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-414x300.png 414w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-124x90.png 124w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-362x262.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/system-architecture-rag-workflow-152x110.png 152w\" sizes=\"(max-width: 700px) 100vw, 700px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. System architecture for the chat application</em></figcaption></figure></div>\n\n\n<h2 id=\"nim_inference_microservices_for_llm_deployment\"  class=\"wp-block-heading\">NIM inference microservices for LLM deployment<a href=\"#nim_inference_microservices_for_llm_deployment\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Our project was built around NVIDIA NIM microservices for several models, including the following:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://build.nvidia.com/meta/llama-3_1-70b-instruct\">Meta\u2019s llama-3.1-70b-instruct</a></li>\n\n\n\n<li><a href=\"https://build.nvidia.com/nvidia/nv-embed-v1/modelcard\">NVIDIA&#8217;s nv-embed-v1</a> for text embeddings</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/nvidia/nv-rerankqa-mistral-4b-v3\">Mistral&#8217;s nv-rerankqa-mistral-4b-v3</a> for reranking</li>\n</ul>\n\n\n\n<p>Despite not having any machine learning engineers or LLM inference specialists on our team, we requested and deployed our own instance of llama-3.1-70b-instruct using a NIM container running on an NVIDIA A100-equipped node (8 GPUs) in just a few hours. This helped us circumvent issues with availability and latency that we found with some enterprise LLM APIs.&nbsp;</p>\n\n\n\n<p>To try out the NIM APIs, sign up for an account at <a href=\"http://build.nvidia.com\">build.nvidia.com</a> and obtain an API key. To use the API key in this project, make sure it is available in a <code>.env</code> file located in the project directory. LlamaIndex connectors for NVIDIA models and APIs are available in the <a href=\"https://docs.llamaindex.ai/en/stable/examples/llm/nvidia/\">Python package</a> <code>llama-index-llms-nvidia</code>. For more information about the performance benefits for NIM-based LLM deployment, see <a href=\"https://developer.nvidia.com/blog/optimizing-inference-efficiency-for-llms-at-scale-with-nvidia-nim-microservices/\">Optimizing Inference Efficiency for LLMs at Scale with NVIDIA NIM Microservices</a>.&nbsp;</p>\n\n\n\n<h3 id=\"llamaindex_workflow_events\"  class=\"wp-block-heading\">LlamaIndex <code>Workflow</code> events<a href=\"#llamaindex_workflow_events\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Our first version of this application was built around <a href=\"https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/\">LlamaIndex\u2019s ChatEngine</a> class, which provided a turnkey solution for deploying a conversational AI assistant backed by a vector database. While this worked well, we found that we wanted to inject additional steps to augment context and toggle features in a way that required more extensibility.&nbsp;</p>\n\n\n\n<p>Fortunately, LlamaIndex <code>Workflow</code> events provided precisely the solution that we needed with its event-driven, step-based approach for controlling an application&#8217;s execution flow. We found it much easier and faster to extend our application as <code>Workflow</code> events while still retaining key LlamaIndex functionality such as vector stores and retrievers when necessary.</p>\n\n\n\n<p>Figure 2 shows our <code>Workflow</code> event, which we explain more about later in this post.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1408\" height=\"911\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph.png\" alt=\"A diagram shows the connections between different steps of the Workflow event, beginning with query routing and ending with final response synthesis.\" class=\"wp-image-90945\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph.png 1408w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-300x194.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-625x404.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-179x115.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-768x497.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-645x417.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-464x300.png 464w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-139x90.png 139w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-362x234.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-170x110.png 170w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow_graph-1024x663.png 1024w\" sizes=\"(max-width: 1408px) 100vw, 1408px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. LlamaIndex Workflow event used to answer user questions&nbsp;</em></figcaption></figure></div>\n\n\n<h3 id=\"user_interface_via_chainlit\"  class=\"wp-block-heading\">User interface via Chainlit<a href=\"#user_interface_via_chainlit\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p><a href=\"https://github.com/Chainlit/chainlit\">Chainlit</a> includes several features that helped speed up our development and deployment. It supports progress indicators and step summaries using the <code>chainlit.Step</code> decorator, and <code>LlamaIndexCallbackHandler</code> enables automatic tracing. We used a <code>Step</code> decorator for each LlamaIndex <code>Workflow</code> event to expose the application&#8217;s inner workings without overwhelming the user.\u00a0</p>\n\n\n\n<p>Chainlit&#8217;s support for enterprise authentication and PostgreSQL data layer was also crucial for production.&nbsp;</p>\n\n\n\n<h2 id=\"setting_up_the_project_environment_dependencies_and_installation\"  class=\"wp-block-heading\">Setting up the project environment, dependencies, and installation<a href=\"#setting_up_the_project_environment_dependencies_and_installation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>To deploy this project, clone the repository located at <a href=\"https://github.com/NVIDIA/GenerativeAIExamples/tree/main/community/routing-multisource-rag\">/NVIDIA/GenerativeAIExamples</a> and create a virtual Python environment, running the following commands to create and activate the environment before installing dependencies:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nmkdir .venv\npip -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n</pre></div>\n\n\n<h3 id=\"configuration\"  class=\"wp-block-heading\">Configuration<a href=\"#configuration\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>After you\u2019ve installed the dependencies, make sure that you have a <code>.env</code> file located in the top-level directory of the project with values for the following:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>NVIDIA_API_KEY</code>: Required. You can get an API key for NVIDIA\u2019s services from <a href=\"http://build.nvidia.com\">build.nvidia.com</a>.</li>\n\n\n\n<li><code>PERPLEXITY_API_KEY</code>. Optional. If it is not provided, then the application runs without using Perplexity\u2019s search API. To obtain an API key for Perplexity, follow the <a href=\"https://docs.perplexity.ai/home\">instructions</a>.</li>\n</ul>\n\n\n\n<h3 id=\"project_structure\"  class=\"wp-block-heading\">Project structure<a href=\"#project_structure\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>We organized the project code into separate files:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>LlamaIndex <code>Workflow</code> (<code>workflow.py</code>): Routes queries and aggregates responses from multiple sources.&nbsp;</li>\n\n\n\n<li>Document ingestion (<code>ingest.py</code>): Loads documents into a Milvus Lite database, which is a simple way to start with Milvus without containers. Milvus Lite\u2019s main limitation is inefficient vector lookup so consider switching to a dedicated cluster when document collections grow. The ingestion module uses LlamaIndex\u2019s <code>SimpleDirectoryReader</code> to parse and load PDFs.</li>\n\n\n\n<li>Chainlit application (<code>chainlit_app.py</code>): The Chainlit application contains functions triggered by events, with the main function (<code>on_message</code>) activating on user messages.</li>\n\n\n\n<li>Configuration (<code>config.py</code>): To play around with different model types, edit the default values. Here, you can select different models for routing and chat completion as well as the number of past messages used from chat history for each completion, and the type of model used by Perplexity for web search and summarization.</li>\n</ul>\n\n\n\n<p>You can also tweak the prompts listed in <code>prompts.py</code> to fit your use case.</p>\n\n\n\n<h2 id=\"building_the_core_functionality\"  class=\"wp-block-heading\">Building the core functionality<a href=\"#building_the_core_functionality\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>This application integrates LlamaIndex and NIM microservices via Chainlit. To show how to implement this logic, we\u2019ll work through the following steps:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Creating the user interface</li>\n\n\n\n<li>Implementing the <code>Workflow</code> event</li>\n\n\n\n<li>Integrating NIM microservices</li>\n</ul>\n\n\n\n<h3 id=\"creating_the_user_interface\"  class=\"wp-block-heading\">Creating the user interface<a href=\"#creating_the_user_interface\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Here\u2019s how this project is implemented, beginning with the Chainlit application in <code>chainlit_app.py</code>. Create a list of <code>Starter</code> objects in the <code>set_starter</code> function to prepopulate initial questions as clickable buttons. These help guide users on possible actions or questions and can route them to specific features.</p>\n\n\n\n<p>The main chat functionality, managed in the main function, handles message history using the <code>cl.user_session</code> variable. This isn\u2019t required for Chainlit to show conversation history but enabled us to keep state on the client side rather than within LlamaIndex objects.&nbsp;</p>\n\n\n\n<p>This approach made prototyping more straightforward and facilitated transitioning to a traditional user-frontend-backend application, unlike the stateful LlamaIndex <code>ChatEngine</code>, which complicates REST API deployment.</p>\n\n\n\n<p>When the Workflow is invoked using <code>workflow.run</code>, a series of asynchronous function calls is triggered through the Workflow, which requires only the current user query and the past chat messages as inputs. When a streaming response is generated, use the <code>stream_token</code> method on Chainlit\u2019s <code>Message</code> class to show it in the user interface. We also added a small amount of HTML with styling to show the token count and time elapsed.</p>\n\n\n\n<h3 id=\"implementing_the_workflow_event\"  class=\"wp-block-heading\">Implementing the Workflow event<a href=\"#implementing_the_workflow_event\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The RAG logic is contained within the <code>QueryFlow</code> class in <code>workflow.py</code>, composed of multiple steps defined as methods of <code>QueryFlow</code>. Each method is triggered when the events in its signature occur. Passing lists of nodes between steps using the nodes attribute was an easy way to structure the Workflow. A node represents a discrete unit of information within LlamaIndex.</p>\n\n\n\n<p>Here are the Workflow steps:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>workflow_start</code>: Adds the user query and chat history to the workflow\u2019s context (<code>ctx.data</code>) and routes between RAG and non-RAG queries using <code>LLMTextCompletionProgram</code>. Depending on the result, it generates either <code>RawQueryEvent</code> (triggers RAG logic) or <code>ShortcutEvent</code> (triggers immediate response synthesis).</li>\n\n\n\n<li><code>rewrite_query</code>: Transforms the user\u2019s query for better search results by removing instruction keywords like &#8220;email&#8221; and &#8220;table&#8221; that can hinder document lookup. It triggers T<code>ransformedQueryEvent</code> for the Milvus retrieval and Perplexity search steps.</li>\n\n\n\n<li><code>embed_query</code>: Produces a vector embedding for the transformed query.</li>\n\n\n\n<li><code>milvus_retrieve</code>: Uses the vector embedding for a vector search.</li>\n\n\n\n<li><code>pplx_retrieve</code>: Uses the LlamaIndex connector for the Perplexity search API to get web search results, summarized as a single node.</li>\n\n\n\n<li><code>collect_nodes</code>: Combines results from Milvus and Perplexity retrievals. This step triggers once both retrieval events are completed. Adding a reranker here could prioritize high-value nodes.</li>\n</ul>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nready = ctx.collect_events(\n            qe,\n            expected=&#x5B;\n                MilvusQueryEvent,\n                PerplexityQueryEvent,\n            ],\n        )\n\n        if ready is None:\n            logger.info(&quot;Still waiting for all input events!&quot;)\n            return None\n</pre></div>\n\n\n<ul class=\"wp-block-list\">\n<li><code>response_synthesis</code>: Builds a prompt string with past chat history context and retrieved documents. We manually form this string, though LlamaIndex templating could also be used. This step triggers <code>StopEvent</code>, ending the <code>Workflow</code> event and returning a response to the Chainlit application by generating <code>CompletionResponse</code> objects for each token produced by the LLM.</li>\n</ul>\n\n\n\n<p>To summarize, a user\u2019s query first goes through a routing step in which the LLM decides if it is worthwhile to use retrieval to look up documents to answer the query. If not, a follow-up completion call is used to produce an answer.&nbsp;</p>\n\n\n\n<p>This branch is triggered when users want to use the LLM to perform tasks that don\u2019t need retrieval, such as editing an email or summarizing a passage of existing text. If retrieval is selected, the user\u2019s query is transformed into a more search-appropriate form. This is then used for vector lookup of ingested documents using the NVIDIA embedding model as well as a Milvus vector store.&nbsp;</p>\n\n\n\n<p>The texts returned from these steps are then augmented with the results of a search using Perplexity\u2019s API, which can find data from the web to form its answers. Finally, these results are used for response synthesis. Figure 2 shows the diagram generated using <code>llama-index-utils-workflow</code>.</p>\n\n\n\n<h3 id=\"integrating_nim_microservices\"  class=\"wp-block-heading\">Integrating NIM microservices<a href=\"#integrating_nim_microservices\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Using NVIDIA NIM microservices for LLM and embedding functionality was quick, thanks to the connectors available from the <code>llama-index-llms-nvidia</code> and <code>llama-index-embeddings-nvidia</code> packages.&nbsp;</p>\n\n\n\n<p>As there\u2019s a range of models available from build.nvidia.com, we could pick the small, fast-executing model Meta\u2019s meta/llama-3.1-8b-instruct for routing queries while also using a larger model, Mistral\u2019s mistralai/mistral-large-2-instruct with superior reasoning abilities to produce the final response.&nbsp;</p>\n\n\n\n<p>Another good choice for a high-performing, large model would be Meta\u2019s meta/llama-3.1-405b-instruct.</p>\n\n\n\n<p>A great advantage for using NIM microservices is that if you want to move to an on-premises or self-managed LLM inference deployment, there are no code changes required beyond setting the base_url parameter for the LLM creation. Otherwise, it\u2019s identical!&nbsp;</p>\n\n\n\n<p>You can toggle between the NVIDIA inference public-facing APIs documented at <a href=\"https://build.nvidia.com\">build.nvidia.com</a> or a self-managed Llama 3.1 deployments. This gives a great deal of flexibility to try several models for prototyping before deciding what type of NIM microservice that you want to manage and deploy yourselves.\u00a0</p>\n\n\n\n<h2 id=\"extra_features\"  class=\"wp-block-heading\">Extra features<a href=\"#extra_features\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>While some of these are beyond the scope of this post, here are a few more features that are easy to add on to enhance value:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Multimodal ingestion </strong>by using vision-language models (VLMs) to read tables, perform optical character recognition, and caption images. You can find many of these at <a href=\"https://build.nvidia.com/explore/vision\">Vision Language Models</a>.</li>\n\n\n\n<li><strong>User chat history </strong>with Chainlit\u2019s Postgres connector. To persist user conversations, you can supply PostgreSQL connection details to Chainlit using the functionality of <code>chainlit.data_layer</code>.</li>\n\n\n\n<li><strong>RAG reranking </strong>with the <a href=\"https://build.nvidia.com/nvidia/rerank-qa-mistral-4b\">NVIDIA Mistral-based reranker</a>.</li>\n\n\n\n<li><strong>Adding citations</strong> by prompting the LLM to use HTML styling to show hyperlinked citations with answers.</li>\n\n\n\n<li><strong>Error handling and timeout management</strong> to enhance reliability. While APIs like Perplexity are powerful for answering a broad range of queries, their execution time can be highly variable due to the complexity of the underlying components involved. Setting reasonable timeouts and gracefully recovering when such answers are not available rapidly is an important step towards a production-ready application.</li>\n</ul>\n\n\n\n<h2 id=\"explore_advanced_chat_functionality_with_the_nvidia_and_llamaindex_developer_contest\"  class=\"wp-block-heading\">Explore advanced chat functionality with the NVIDIA and LlamaIndex Developer Contest<a href=\"#explore_advanced_chat_functionality_with_the_nvidia_and_llamaindex_developer_contest\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>We hope this post has been a useful resource for you as you learn more about generative AI and the ways that NIM microservices and LlamaIndex <code>Workflow</code> events can be used together for the fast development of advanced chat functionality.&nbsp;</p>\n\n\n\n<p>If you\u2019re inspired by this project, consider participating in the <a href=\"https://developer.nvidia.com/llamaindex-developer-contest\">NVIDIA and LlamaIndex Developer Contest</a> to build your own AI-powered solutions for a chance to win cash prizes, an NVIDIA GeForce RTX 4080 SUPER GPU, <a href=\"https://www.nvidia.com/en-us/training/\">DLI</a> credits, and more.</p>\n\n\n\n<p>If you\u2019re interested in learning more or exploring similar applications, consider diving into the code here, or experiment with other similar reference applications from the <a href=\"https://github.com/NVIDIA/GenerativeAIExamples\">GenerativeAI Examples</a> repo on GitHub.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>The rapid development of solutions using retrieval augmented generation (RAG) for question-and-answer LLM workflows has led to new types of system architectures. Our work at NVIDIA using AI for internal operations has led to several important findings for finding alignment between system capabilities and user expectations.&nbsp; We found that regardless of the intended scope or &hellip; <a href=\"https://developer.nvidia.com/blog/creating-rag-based-question-and-answer-llm-workflows-at-nvidia/\">Continued</a></p>\n", "protected": false}, "author": 2402, "featured_media": 90947, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1510181", "discourse_permalink": "https://forums.developer.nvidia.com/t/creating-rag-based-question-and-answer-llm-workflows-at-nvidia/311405", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1050, 3110], "tags": [453, 3737, 3613], "coauthors": [4141, 2362], "class_list": ["post-90872", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-conversational-ai", "category-generative-ai", "tag-featured", "tag-microservices", "tag-retrieval-augmented-generation-rag"], "acf": {"post_industry": ["Consumer Internet"], "post_products": ["NIM"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Tutorial"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llamaindex-workflow-chat-app-featured-1.gif", "jetpack_shortlink": "https://wp.me/pcCQAL-nDG", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90872"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2402"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90872"}], "version-history": [{"count": 6, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90872/revisions"}], "predecessor-version": [{"id": 91681, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90872/revisions/91681"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90947"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90872"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90872"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90872"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90872"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90877, "date": "2024-10-28T08:30:00", "date_gmt": "2024-10-28T15:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90877"}, "modified": "2024-10-31T11:36:06", "modified_gmt": "2024-10-31T18:36:06", "slug": "supercharging-fraud-detection-in-financial-services-with-graph-neural-networks", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/supercharging-fraud-detection-in-financial-services-with-graph-neural-networks/", "title": {"rendered": "Supercharging Fraud Detection in Financial Services with Graph Neural Networks"}, "content": {"rendered": "\n<p>Fraud in financial services is a massive problem. According to <a href=\"https://verafin.com/nasdaq-verafin-global-financial-crime-report/\">NASDAQ</a>, in 2023, banks faced $442 billion in projected losses from payments, checks, and credit card fraud. It\u2019s not just about the money, though. Fraud can tarnish a company\u2019s reputation and frustrate customers when legitimate purchases are blocked. This is called a <em>false positive</em>. Unfortunately, these errors happen more often than you\u2019d think because traditional fraud detection methods simply aren\u2019t keeping up with how sophisticated fraud has become.</p>\n\n\n\n<p>This post focuses on credit card transaction fraud, one of the most prevalent forms of financial fraud. While other types of fraud, such as identity theft, account takeover, and money laundering, are also significant concerns, credit card fraud poses a unique challenge due to its high transaction volume and broad attack surface, making it a key target for fraudsters. Financial institutions are estimated to lose $43 billion by 2026 in annual credit card losses, according to <a href=\"https://nilsonreport.com/articles/card-fraud-losses-worldwide/\">Nilson</a>.&nbsp;</p>\n\n\n\n<p>Traditional fraud detection methods, which rely on rules-based systems, or statistical methods, are reactive and increasingly ineffective in identifying sophisticated fraudulent activities. As data volumes grow and fraud tactics evolve, financial institutions need more proactive, intelligent approaches to detect and prevent fraudulent transactions.&nbsp;</p>\n\n\n\n<p>AI offers essential tools for analyzing vast amounts of transactional data, identifying abnormal behaviors, and recognizing patterns that indicate fraud. But while steps have been taken to improve detection, even more advanced techniques are needed to improve accuracy, reduce false positives, and enhance operational efficiency in fraud detection.&nbsp;</p>\n\n\n\n<p>This post introduces an end-to-end AI workflow that uses graph neural networks (GNNs) offering a flexible, high-performance solution for fraud detection. It also walks through how you can get started with model building and inference with this fraud detection workflow.</p>\n\n\n\n<h2 id=\"graph_neural_networks_for_fraud_detection\"  class=\"wp-block-heading\">Graph neural networks for fraud detection<a href=\"#graph_neural_networks_for_fraud_detection\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Traditional machine learning (ML) models, such as <a href=\"https://www.nvidia.com/en-us/glossary/xgboost/\">XGBoost</a>, have been widely used for fraud detection and have proven effective at identifying anomalous behavior in individual transactions. However, fraud detection is rarely a problem of isolated events. Fraudsters operate within complex networks, often using connections between accounts and transactions to hide their activities. This is where GNNs come in.</p>\n\n\n\n<p>GNNs are designed to work with graph-structured data, making them particularly suited for fraud detection in financial services. Imagine each account, transaction, and device as a node within a network. Instead of analyzing individual transactions only, GNNs consider the connections between these nodes\u2014revealing patterns of suspicious activity across the network.&nbsp;</p>\n\n\n\n<p>For example, suppose an account has a relationship with known fraudulent entities or is similar to other high-risk entities, GNNs can pick up on that connection and flag it for further investigation, even if the account itself seems fine.</p>\n\n\n\n<p>Combining GNNs with XGBoost offers the best of both worlds:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Higher accuracy</strong>: GNNs don\u2019t just focus on individual transactions\u2014they consider how everything is connected, catching fraud that might otherwise go undetected.</li>\n\n\n\n<li><strong>Fewer false positives</strong>: With more context, GNNs help reduce false alarms, so legitimate transactions don\u2019t get flagged unnecessarily.</li>\n\n\n\n<li><strong>Better scalability</strong>: GNNs model building scales to handle massive networks of data efficiently. But combining GNNs with XGBoost real-time fraud detection (inference) is possible even at large scales.</li>\n\n\n\n<li><strong>Explainability</strong>: Combining GNNs with XGBoost provides the power of deep learning with the explainability of decision trees.</li>\n</ul>\n\n\n\n<h2 id=\"an_end-to-end_fraud_detection_ai_workflow_using_gnns\"  class=\"wp-block-heading\">An end-to-end fraud detection AI workflow using GNNs<a href=\"#an_end-to-end_fraud_detection_ai_workflow_using_gnns\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>NVIDIA has built an end-to-end fraud detection workflow that combines traditional ML with the power of GNNs. This process builds on a standard XGBoost approach but augments it with GNN embeddings to significantly boost accuracy. While exact numbers are confidential, even a small improvement\u2014such as 1%\u2014could translate into millions of dollars in savings, making GNNs a critical part of fraud detection systems.</p>\n\n\n\n<p>The general architecture includes two main parts: the model building step and the inference process, as shown in Figure 1.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1999\" height=\"907\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow.png\" alt=\"Payment fraud detection AI workflow. Left to right: internet, data stream, model building, tagged data stream, data lake, periodic model building, inference.\" class=\"wp-image-90910\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-300x136.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-625x284.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-179x81.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-768x348.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-1536x697.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-645x293.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-500x227.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-160x73.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-362x164.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-242x110.png 242w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/payment-fraud-detection-ai-workflow-1024x465.png 1024w\" sizes=\"(max-width: 1999px) 100vw, 1999px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. Payment fraud detection AI workflow, including inference and model building</em></em></figcaption></figure></div>\n\n\n<h3 id=\"model_building_with_gnns_and_xgboost\"  class=\"wp-block-heading\">Model building with GNNs and XGBoost<a href=\"#model_building_with_gnns_and_xgboost\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The process starts with the<strong> </strong>model building<strong> </strong>phase, since a model needs to be available for inference in the workflow above, where GNNs are used to create features (embeddings) that are fed into an XGBoost model (Figure 2).</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1999\" height=\"484\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection.png\" alt=\"Flowchart of the GNN training into XGBoost workflow; (left to right): data cleaning and prep, graph creation, feature store/graph store, GNN embeddings, XGBoost, model for deployment into NVIDIA Morpheus.\" class=\"wp-image-90912\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-300x73.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-625x151.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-179x43.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-768x186.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-1536x372.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-645x156.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-500x121.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-160x39.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-362x88.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-454x110.png 454w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/model-building-ai-workflow-payment-fraud-detection-1024x248.png 1024w\" sizes=\"(max-width: 1999px) 100vw, 1999px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 2. The model building portion of the AI workflow for payment fraud detection</em></em></figcaption></figure></div>\n\n\n<h4 class=\"wp-block-heading\"><strong>Step 1: Data preparation</strong>&nbsp;</h4>\n\n\n\n<p>Incoming transaction data is cleaned and prepared, typically using tools like <a href=\"https://developer.nvidia.com/rapids\">RAPIDS</a> for efficiency. Data preparation and feature engineering have a significant impact on the performance of model building. This step requires a detailed understanding of the data and could take multiple tries to get the best results.&nbsp;</p>\n\n\n\n<p>Once a script for data preparation has been created, it can be automated in the workflow. The data preparation process should be evaluated as new data is added or periodically as data grows. The next iteration of this workflow will leverage <a href=\"https://www.nvidia.com/en-us/deep-learning-ai/solutions/data-science/apache-spark-3/\">NVIDIA RAPIDS Accelerator for Apache Spark</a> to accelerate the data processing piece of this workflow.</p>\n\n\n\n<h4 class=\"wp-block-heading\">Step 2: Graph creation&nbsp;</h4>\n\n\n\n<p>For large datasets, typical of FSI, the graph creation process converts the prepared data into a Feature Store (tabular data) and a Graph Store (structural data). This enables better host and device memory usage and peak performance. The two stores are optimized for GNN frameworks like PyG (PyTorch Geometric) and DGL (Deep Graph Library). A key benefit of using this workflow is ensuring the stores are optimized for the selected GNN framework.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n# load the edge data\nedge_data = cudf.read_csv(edge_path, header=None,\n\tnames=&#x5B;edge_src_col, edge_dst_col, edge_att_col], dtype=&#x5B;&#039;int32&#039;,&#039;int32&#039;,&#039;float&#039;])\n\n# convert to tensors\nnum_nodes = max(edge_data&#x5B;edge_src_col].max(), edge_data&#x5B; edge_dst_col].max()) + 1\nsrc_tensor = torch.as_tensor(edge_data&#x5B;edge_src_col], device=&#039;cuda&#039;)\ndst_tensor = torch.as_tensor(edge_data&#x5B;edge_dst_col], device=&#039;cuda&#039;)\n\n# save in a GraphStore\ngraph_store = cugraph_pyg.data.GraphStore()\ngraph_store&#x5B;(&quot;n&quot;, &quot;e&quot;, &quot;n&quot;), &quot;coo&quot;, False, (num_nodes, num_nodes)] = &#x5B;src_tensor, dst_tensor]\n\n...\n# load the features\nfeature_data = cudf.read_csv(feature_path)\n\n# convert to tensors\ncol_tensors = &#x5B;]\nfor c in feature_columns:\n\tt = torch.as_tensor(feature_data&#x5B;c].values, device=&#039;cuda&#039;)\n\tcol_tensors.append(t)\n\nx_feature_tensor = torch.stack(col_tensors).T\n\n\nfeature_store = cugraph_pyg.data.TensorDictFeatureStore()\nfeature_store&#x5B;&quot;node&quot;, &quot;x&quot;] = x_feature_tensor\nfeature_store&#x5B;&quot;node&quot;, &quot;y&quot;] = y_label_tensor\n</pre></div>\n\n\n<h4 class=\"wp-block-heading\">Step 3: GNN embedding generation</h4>\n\n\n\n<p>Rather than having the GNN produce a classification, the last layer of the GNN is extracted as embeddings. Those GNN embeddings are passed into XGBoost and a model is created. That model is then saved for use in inferencing.&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\ndef extract_embeddings(model, loader):\n\tmodel.eval()\n\tembeddings = &#x5B;]\n\tlabels = &#x5B;]\n\twith torch.no_grad():\n    \tfor batch in loader:\n        \tbatch_size = batch.batch_size\n        \thidden = model(batch.x&#x5B;:,:].to(torch.float32), batch.edge_index, return_hidden=True)&#x5B;:batch_size]\n        \tembeddings.append(hidden)  # Keep embeddings on GPU\n        \tlabels.append(batch.y&#x5B;:batch_size].view(-1).to(torch.long))\n    \n\tembeddings = torch.cat(embeddings, dim=0)  # Concatenate embeddings on GPU\n\tlabels = torch.cat(labels, dim=0)  # Concatenate labels on GPU\n\treturn embeddings, labels\n\n\n... in main code ....\n\n# Define the model\nmodel = GraphSAGE( ....)\n\nfor epoch in range(best_params&#x5B;&#039;num_epochs&#039;]):\n\ttrain_loss = train_gnn(model, train_loader, optimizer, criterion)\n\n...\n# Extract embeddings from the second-to-last layer and keep them on GPU\nembeddings, labels = extract_embeddings(model, train_loader)\n</pre></div>\n\n\n<p>By using GPU-accelerated versions of GNN frameworks\u2014such as cuGraph-pyg and cuGraph-dgl\u2014this workflow can handle large datasets with complex graph structures efficiently.</p>\n\n\n\n<h3 id=\"inference_for_real-time_fraud_detection\"  class=\"wp-block-heading\">Inference for real-time fraud detection<a href=\"#inference_for_real-time_fraud_detection\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Once the model is trained, it can be served for real-time fraud detection using <a href=\"https://developer.nvidia.com/triton-inference-server\">NVIDIA Triton Inference Server</a>, an open-source AI model-serving platform that streamlines and accelerates the deployment of AI inference workloads in production. NVIDIA Triton helps enterprises reduce the complexity of model-serving infrastructure, shorten the time needed to deploy new AI models in production, and increase AI inferencing and prediction capacity.&nbsp;</p>\n\n\n\n<p>The trained model can also be deployed using <a href=\"https://developer.nvidia.com/morpheus-cybersecurity\">NVIDIA Morpheus</a>, an open-source cybersecurity AI framework that enables developers to create optimized applications for filtering, processing, and classifying large volumes of streaming data. The <a href=\"https://github.com/nv-morpheus/MRC\">Morpheus Runtime Core (MRC)</a> orchestrating this workflow accelerates massive data processing and analysis and helps with inferencing by periodically triggering the process to build a new model.&nbsp;</p>\n\n\n\n<p>As shown in Figure 3, the inference process involves:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Transforming the raw input data using the same process used during model building (that is, training).</li>\n\n\n\n<li>Feeding the data into the GNN model to convert the transaction into an embedding. This is needed since the XGBoost model was trained on the embedding.</li>\n\n\n\n<li>Feeding the embeddings into the XGBoost model to predict if the transactions are fraudulent.</li>\n</ol>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"722\" height=\"160\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton.png\" alt=\"Inference workflow diagram; (left to right): data stream, data cleaning and prep, data to GNN embedding, NVIDIA Triton Inference Server.\" class=\"wp-image-90958\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton.png 722w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-300x66.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-625x139.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-179x40.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-645x143.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-500x111.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-160x35.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-362x80.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/workflow-inference-gnn-nvidia-triton-496x110.png 496w\" sizes=\"(max-width: 722px) 100vw, 722px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 3. Inference workflow</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n# Load GNN model for creating node embeddings\ngnn_model = torch.load(gnn_model_path)\ngnn_model.eval()  # Set the model to evaluation mode\n\n# Load xgboost model for node classification\nloaded_bst = xgb.Booster()\nloaded_bst.load_model(xgb_model_path)\n\n# Generate node embedding using the GNN model\ntransaction_embeddings = gnn_model(X.to(device), ....)\n\n# Convert embeddings to cuDF DataFrame\nembeddings_cudf = cudf.DataFrame(cp.from_dlpack(to_dlpack(embeddings)))\n\n# Create DMatrix for the test embeddings\ndtest = xgb.DMatrix(embeddings_cudf)\n\n# Predict using XGBoost on GPU\npreds = bst.predict(dtest)\n</pre></div>\n\n\n<p>By incorporating both GNNs and XGBoost, this AI workflow offers a flexible, high-performance solution for fraud detection. Enterprises can customize the configuration of GNNs and adjust model-building processes based on their unique needs, ensuring the system stays optimized over time.</p>\n\n\n\n<h2 id=\"ecosystem_using_the_ai_workflow_to_enhance_fraud_detection\"  class=\"wp-block-heading\">Ecosystem using the AI workflow to enhance fraud detection<a href=\"#ecosystem_using_the_ai_workflow_to_enhance_fraud_detection\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Amazon Web Services (AWS) is the first cloud service provider to integrate this <a href=\"https://www.youtube.com/watch?v=fZJLfruV-1w\">end-to-end fraud detection workflow</a> with their highly secure accelerated computing capabilities. With this simple workflow integration, developers who build fraud detection models can use NVIDIA RAPIDS within Amazon EMR for data processing, leverage RAPIDS and GNN libraries within Amazon SageMaker and Amazon EC2 services for model training. This integration flexibly scales low latency and high throughput predictions using NVIDIA Morpheus and NVIDIA Triton Inference Server through Amazon SageMaker or Amazon Elastic Kubernetes Service endpoint.</p>\n\n\n\n<p>As these efforts continue to develop, this workflow will be available across the NVIDIA partner ecosystem for enterprises and developers to prototype and take it to production through <a href=\"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/\">NVIDIA AI Enterprise</a>.</p>\n\n\n\n<h2 id=\"get_started\"  class=\"wp-block-heading\">Get started<a href=\"#get_started\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>As fraud tactics evolve, traditional detection methods fall short. Combining XGBoost with GNNs offers a powerful solution\u2014boosting accuracy, reducing false positives, and improving real-time detection. This <a href=\"https://www.nvidia.com/en-us/ai-data-science/ai-workflows/fraud-detection/\">AI workflow</a> is designed to help enterprises stay ahead of sophisticated fraud attempts and adapt quickly to new threats.</p>\n\n\n\n<p>To learn more about using GNNs to transform your approach to fraud detection, check out the <a href=\"https://github.com/nv-morpheus/morpheus-experimental/tree/branch-25.02/ai-credit-fraud-workflow\">AI Credit Card Fraud Workflow</a>. You can also explore the NVIDIA LaunchPad lab <a href=\"https://www.nvidia.com/en-us/launchpad/data-science/deploy-a-fraud-detection-xgboost-model-using-triton/\">Deploy a Fraud Detection XGBoost Model with NVIDIA Triton</a> and the <a href=\"https://www.nvidia.com/en-us/use-cases/ai-for-fraud-detection/\">AI for Fraud Detection Use Case</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Fraud in financial services is a massive problem. According to NASDAQ, in 2023, banks faced $442 billion in projected losses from payments, checks, and credit card fraud. It\u2019s not just about the money, though. Fraud can tarnish a company\u2019s reputation and frustrate customers when legitimate purchases are blocked. This is called a false positive. Unfortunately, &hellip; <a href=\"https://developer.nvidia.com/blog/supercharging-fraud-detection-in-financial-services-with-graph-neural-networks/\">Continued</a></p>\n", "protected": false}, "author": 2033, "featured_media": 90918, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1510171", "discourse_permalink": "https://forums.developer.nvidia.com/t/supercharging-fraud-detection-in-financial-services-with-graph-neural-networks/311401", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1464, 696], "tags": [453, 3550, 2127, 1177], "coauthors": [3738, 2092, 4139], "class_list": ["post-90877", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-cybersecurity", "category-data-science", "tag-featured", "tag-fraud-detection", "tag-morpheus", "tag-triton"], "acf": {"post_industry": ["Financial Services"], "post_products": ["AI Enterprise", "Morpheus", "RAPIDS", "Triton Inference Server"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Tutorial"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/fraud-alert-mobile.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nDL", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Data Science", "link": "https://developer.nvidia.com/blog/category/data-science/", "id": 696}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90877"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2033"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90877"}], "version-history": [{"count": 13, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90877/revisions"}], "predecessor-version": [{"id": 91084, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90877/revisions/91084"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90918"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90877"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90877"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90877"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90877"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90897, "date": "2024-10-28T08:00:00", "date_gmt": "2024-10-28T15:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90897"}, "modified": "2024-11-05T18:24:56", "modified_gmt": "2024-11-06T02:24:56", "slug": "nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models/", "title": {"rendered": "NVIDIA GH200 Superchip Accelerates Inference by 2x in Multiturn Interactions with Llama Models"}, "content": {"rendered": "\n<p>Deploying <a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\">large language models (LLMs)</a> in production environments often requires making hard trade-offs between enhancing user interactivity and increasing system throughput. While enhancing user interactivity requires minimizing time to first token (TTFT), increasing throughput requires increasing tokens per second. Improving one aspect often results in the decline of the other, making it difficult for data centers, cloud service providers (CSPs), and AI application providers to find the right balance.&nbsp;</p>\n\n\n\n<p>Leveraging the <a href=\"https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/\">NVIDIA GH200 Grace Hopper Superchip</a> can minimize these tradeoffs. This post explores how IT leaders and infrastructure decision makers can harness the converged memory architecture of NVIDIA GH200 Grace Hopper Superchip to boost TTFT in multiturn user interactions by up to 2x on the popular Llama 3 70B model, compared to x86-based <a href=\"https://www.nvidia.com/en-us/data-center/h100/\">NVIDIA H100 servers</a>, without any tradeoffs to system throughput.</p>\n\n\n\n<h2 id=\"key-value_cache_offloading\"  class=\"wp-block-heading\">Key-value cache offloading<a href=\"#key-value_cache_offloading\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>LLM models are rapidly gaining adoption across various use cases, including question answering, summarization, and code generation. Before responding to a user\u2019s prompt, these models must build a contextual understanding of the input sequence and any additional information retrieved during the inference request, such as in the case of <a href=\"https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/\">retrieval-augmented generation (RAG)</a>.&nbsp;</p>\n\n\n\n<p>This process involves converting the user\u2019s prompt to tokens, and then to highly dense vectors, followed by extensive dot product operations to build a mathematical representation of the relationship between all the token\u2019s in the prompt. The operations are repeated across the different layers of the model. The amount of compute required to generate the contextual understanding of the prompt scales quadratically with the size of the input sequence length.</p>\n\n\n\n<p>This compute-intensive process, which generates the key-value cache, or <a href=\"https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/\">KV cache</a>, is only required during the generation of the first token of the output sequence. Those values are then stored for later reuse when subsequent output tokens are generated, with new values appended as required. This dramatically reduces the amount of compute required to generate new tokens and, ultimately, the time it takes for the LLM to generate an output, improving the user experience.&nbsp;</p>\n\n\n\n<p>Reusing a KV cache avoids the need to recompute it from scratch, reducing inference time and compute resources. However, in situations where user interaction with an LLM-based service is intermittent or if multiple LLM users need to interact with the same KV cache but at different times, storing the KV cache in GPU memory for long periods can waste valuable resources that could be better allocated to handle new incoming user requests, reducing overall system throughput.&nbsp;</p>\n\n\n\n<p>To address this challenge, the KV cache can be offloaded from GPU memory to higher capacity and lower cost CPU memory, and then reloaded back to GPU memory once idle users resume their activity or new users interact with the same piece of content. This method, known as <em>KV cache offloading</em>, eliminates the need to recompute the KV cache without holding up valuable GPU memory.&nbsp;</p>\n\n\n\n<h2 id=\"addressing_challenges_of_multiturn_user_interactions\"  class=\"wp-block-heading\">Addressing challenges of multiturn user interactions<a href=\"#addressing_challenges_of_multiturn_user_interactions\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>KV cache offloading benefits content providers integrating generative AI capabilities into their platforms by enabling multiple users to interact with the same content\u2014like summarizing a news article\u2014without recalculating the KV cache for each new user. By computing the KV cache for the news article once, caching it in CPU memory, and then reusing it across multiple users, significant cost and user experience optimizations can be achieved.&nbsp;</p>\n\n\n\n<p>This technique is also useful during code generation use cases, particularly in integrated development environments (IDEs) that have incorporated LLM capabilities. In this scenario, one or more developers can submit multiple prompts interacting with a single code script over extended periods of time. Offloading the initial KV cache calculations onto CPU memory and then reloading it for subsequent interactions avoids repeated recalculations and saves valuable GPU and infrastructure resources. Check out the <a href=\"https://nvidia.github.io/TensorRT-LLM/kv_cache_reuse.html#offloading-to-host-memory\">NVIDIA TensorRT-LLM documentation</a> for a detailed how-to guide on offloading and reusing the KV cache.</p>\n\n\n\n<p>For the Llama 3<em> </em>70B model running on a server with NVIDIA H100 Tensor Core GPUs connected through PCIe to an x86 host processor, KV cache offloading can accelerate TTFT by up to 14x. This makes it a compelling deployment strategy for data centers, CSPs, and application providers seeking to serve LLMs cost effectively while maintaining positive user experiences.</p>\n\n\n\n<div><figure class=\"wp-block-image aligncenter size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"625\" height=\"598\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-625x598.png\" alt=\"Chart showing performance comparisons of running Llama 3 70B with and without KV cache on an x86-H100 server for different input sequence lengths (ISLs). The x-factor speedups of KV cache offloading start at 5x for 1024 ISLs and go up to 14x for 7168 ISLs.\" class=\"wp-image-90930\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-625x598.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-300x287.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-120x115.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-768x734.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-645x617.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-314x300.png 314w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-94x90.png 94w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-32x32.png 32w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-362x346.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-115x110.png 115w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b-1024x979.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/kv-cache-offloading-ttft-llama-3-70b.png 1324w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. In multiturn interactions, KV cache offloading for the Llama 3 70B model running on an NVIDIA H100 x86 GPU accelerates TTFT by up to 14x for large input sequence lengths compared to recalculating it from scratch</em></em></figcaption></figure></div>\n\n\n\n<h2 id=\"accelerating_kv_cache_offloading_with_nvidia_gh200_converged_cpu-gpu_memory\"  class=\"wp-block-heading\">Accelerating KV cache offloading with NVIDIA GH200 converged CPU-GPU memory<a href=\"#accelerating_kv_cache_offloading_with_nvidia_gh200_converged_cpu-gpu_memory\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>In traditional x86-based GPU servers, the KV cache offloading occurs over the 128 GB/s PCIe connection. For large batch sizes that include multiple multiturn user prompts, the slow PCIe interface can hamper performance, pushing TTFT above the 300 ms &#8211; 500 ms threshold typically associated with a realtime user experience.&nbsp;</p>\n\n\n\n<p>The NVIDIA GH200 Grace Hopper Superchip overcomes the challenges of low speed PCIe interfaces. NVIDIA GH200 is a new class of superchip that brings together the Arm-based<a href=\"https://www.nvidia.com/en-us/data-center/grace-cpu/\"> NVIDIA Grace CPU</a> and<a href=\"https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/\"> NVIDIA Hopper GPU</a> architectures using<a href=\"https://www.nvidia.com/en-us/data-center/nvlink-c2c/\"> NVLink-C2C</a> interconnect technology. NVLink-C2C delivers up to 900 GB/s total bandwidth between the CPU and the GPU. This is 7x higher bandwidth than the standard PCIe Gen5 lanes found in traditional x86-based GPU servers. Additionally, with GH200, the CPU and GPU share a single per-process page table, enabling all CPU and GPU threads to access all system-allocated memory that can reside on physical CPU or GPU memory.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1999\" height=\"718\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture.png\" alt=\"Comparison of legacy PCIe architecture that has CPU and GPU memory connected with a low bandwidth PCIe versus the Grace Hopper architecture that has a single unified virtual memory pool with a high bandwidth NVLINK-C2C connection. \n\" class=\"wp-image-90931\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-300x108.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-625x224.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-179x64.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-768x276.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-1536x552.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-645x232.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-500x180.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-160x57.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-362x130.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-306x110.png 306w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/comparison-legacy-pcle-architecture-nvidia-grace-hopper-architecture-1024x368.png 1024w\" sizes=\"(max-width: 1999px) 100vw, 1999px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 2. NVIDIA Grace Hopper architecture that leverages the 900 GB/s NVLink-C2C overcomes PCIe bottlenecks</em></em></figcaption></figure>\n\n\n\n<p>Offloading KV cache for the Llama 3 70B model on GH200 delivers up to 2x more speedup for TTFT compared to offloading on x86-H100 in multiturn scenarios. This enables organizations deploying LLMs for where multiturn user interactions are frequent to increase user interactivity without any tradeoffs to overall system throughput.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1555\" height=\"1417\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200.png\" alt=\"Chart showing performance comparisons of running Llama 3 70B with KV cache on an NVIDIA GH200 Superchip compared to an x86-H100 GPU. Chart shows that for different input sequence lengths (ISLs) the x-factor speedups of KV cache offloading on the NVIDIA GH200 Superchip increases from 1.2x for 1024 ISLs to up to 2x for 7168 ISLs.\n\" class=\"wp-image-91042\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200.png 1555w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-300x273.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-625x570.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-126x115.png 126w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-768x700.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-1536x1400.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-645x588.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-329x300.png 329w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-99x90.png 99w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-362x330.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-121x110.png 121w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/performance-comparison-llama-3-kv-cache-nvidia-gh200-1024x933.png 1024w\" sizes=\"(max-width: 1555px) 100vw, 1555px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 3. As a result of the 900 GB/s NVLink-C2C that connects the NVIDIA Grace CPU with the NVIDIA H200 GPU, offloading the KV cache for the Llama 3 70B model on a GH200 Superchip accelerates TTFT by up to 2x compared to on an x86-H100 GPU&nbsp;</em></em></figcaption></figure>\n\n\n\n<h2 id=\"superior_inference_on_llama_3_with_nvidia_grace_hopper_and_nvlink-c2c&nbsp;\"  class=\"wp-block-heading\">Superior inference on Llama 3 with NVIDIA Grace Hopper and NVLink-C2C&nbsp;<a href=\"#superior_inference_on_llama_3_with_nvidia_grace_hopper_and_nvlink-c2c&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>KV cache offloading is gaining traction among CSPs, data centers, and AI application providers due to its ability to improve TTFT in multiturn user interactions without degrading overall system throughput. By leveraging the 900 GB/s NVLink-C2C on the NVIDIA GH200 Superchip, inference on the popular Llama 3 model can be accelerated by up to 2x without any degradation to the system throughput. This enables organizations to improve user experience without additional infrastructure investments.</p>\n\n\n\n<p>Today, <a href=\"https://nvidianews.nvidia.com/news/nvidia-grace-hopper-ignites-new-era-of-ai-supercomputing\">NVIDIA GH200 powers nine supercomputers</a> around the world, is offered by a <a href=\"https://blogs.nvidia.com/blog/mgx-accelerated-systems-gtc/\">wide array of system makers</a>, and can be accessed on demand at cloud providers such as Vultr, Lambda, and CoreWeave. You can <a href=\"https://www.nvidia.com/en-us/launchpad/development-frameworks/one-grace-hopper/\">test NVIDIA GH200 for free</a> through NVIDIA LaunchPad.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Deploying large language models (LLMs) in production environments often requires making hard trade-offs between enhancing user interactivity and increasing system throughput. While enhancing user interactivity requires minimizing time to first token (TTFT), increasing throughput requires increasing tokens per second. Improving one aspect often results in the decline of the other, making it difficult for data &hellip; <a href=\"https://developer.nvidia.com/blog/nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models/\">Continued</a></p>\n", "protected": false}, "author": 2008, "featured_media": 90903, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1510158", "discourse_permalink": "https://forums.developer.nvidia.com/t/nvidia-gh200-superchip-accelerates-inference-by-2x-in-multiturn-interactions-with-llama-models/311398", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 3110, 1903], "tags": [453, 4159, 2932, 3613], "coauthors": [3708, 2732, 4049, 2940, 4137, 4138, 4140], "class_list": ["post-90897", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-center-cloud", "category-generative-ai", "category-features", "tag-featured", "tag-inference-performance", "tag-large-language-models", "tag-retrieval-augmented-generation-rag"], "acf": {"post_industry": ["Cloud Services"], "post_products": ["GB200", "NVLink"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Benchmark"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/grace-superchip.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nE5", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90897"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2008"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90897"}], "version-history": [{"count": 12, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90897/revisions"}], "predecessor-version": [{"id": 91045, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90897/revisions/91045"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90903"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90897"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90897"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90897"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90897"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90863, "date": "2024-10-25T13:39:38", "date_gmt": "2024-10-25T20:39:38", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90863"}, "modified": "2024-10-31T11:36:43", "modified_gmt": "2024-10-31T18:36:43", "slug": "advancing-performance-with-nvidia-sharp-in-network-computing", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/advancing-performance-with-nvidia-sharp-in-network-computing/", "title": {"rendered": "Advancing Performance with NVIDIA SHARP In-Network Computing"}, "content": {"rendered": "\n<p>AI and scientific computing applications are great examples of distributed computing problems. The problems are too large and the computations too intensive to run on a single machine. These computations are broken down into parallel tasks that are distributed across thousands of compute engines, such as CPUs and GPUs.&nbsp;</p>\n\n\n\n<p>To achieve scalable performance, the system relies on dividing workloads like training data, model parameters, or both, across multiple nodes. These nodes must then frequently exchange information, such as gradients of newly-processed model computations during backpropagation in model training, requiring efficient collective communications like all-reduce, broadcast, and gather and scatter operations.&nbsp;</p>\n\n\n\n<p>These collective communication patterns ensure the synchronization and convergence of model parameters across the distributed system. The efficiency of these operations is crucial for minimizing communication overhead and maximizing parallel computation, as poorly optimized collective communications can lead to bottlenecks, limiting scalability.</p>\n\n\n\n<p>The bottlenecks arise from several factors:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Latency and bandwidth limitations:</strong> Collective operations rely on high-speed data transfers across nodes, which are constrained by the physical network&#8217;s latency and bandwidth. As the scale of the system increases, the amount of data to be exchanged grows, and the time taken for communication becomes a dominant factor over computation.</li>\n\n\n\n<li><strong>Synchronization overhead:</strong> Many collective operations require synchronization points where all participating nodes must reach the same state before proceeding. If certain nodes are slower, the entire system experiences delays, causing inefficiencies known as <em>stragglers</em>.</li>\n\n\n\n<li><strong>Network contention:</strong> As the network becomes more congested with larger numbers of nodes trying to communicate simultaneously, contention for bandwidth and network resources increases, further slowing down collective operations.</li>\n\n\n\n<li><strong>Non-optimal communication patterns:</strong> Some collective communication algorithms (e.g., tree-based reductions or ring-based all-reduce) are not always well-optimized for large-scale systems, leading to inefficient use of available resources and increased latency.</li>\n</ul>\n\n\n\n<p>Overcoming this bottleneck requires advancements in network technologies (for example, InfiniBand or RDMA) and algorithmic optimizations (for example, hierarchical all-reduce or pipelining techniques) to minimize synchronization delays, reduce contention, and optimize data flow across distributed systems.</p>\n\n\n\n<h2 id=\"creation_of_nvidia_sharp\"  class=\"wp-block-heading\">Creation of NVIDIA SHARP<a href=\"#creation_of_nvidia_sharp\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The key collective communications enable all compute engines to exchange data between themselves. Managing such communication on a NIC or server requires exchanging massive amounts of data, and is exposed to the variance of latency or collective performance, also known as <em>server jitter</em>.&nbsp;</p>\n\n\n\n<p>Migrating the responsibility to manage and execute these collective communications on the switch fabric reduces the amount of transferred data by half and minimizes jitter. NVIDIA Scalable Hierarchical Aggregation and Reduction Protocol (SHARP) is the technology implementing that concept and introduced the concept of <em>in-network computing</em>. It is incorporated in the switch ASIC and designed to accelerate collective communication in distributed computing systems.&nbsp;</p>\n\n\n\n<p>Introduced with <a href=\"https://www.nvidia.com/en-gb/networking/products/infiniband/\">NVIDIA InfiniBand networks</a>, SHARP offloads collective communication operations\u2014like all-reduce, reduce, and broadcast\u2014from the server\u2019s compute engines to the network switches. By performing reductions (summing, averaging, and so on) directly within the network fabric, SHARP improves these operations and the overall application performance.&nbsp;</p>\n\n\n\n<h2 id=\"generational_advancements_with_nvidia_sharp\"  class=\"wp-block-heading\">Generational advancements with NVIDIA SHARP<a href=\"#generational_advancements_with_nvidia_sharp\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The first generation of SHARP was specifically designed for scientific computing applications, with a focus on small-message reduction operations. It was introduced with NVIDIA EDR 100Gb/s switch generation, and was quickly supported by leading Message Passing Interface (MPI) libraries. SHARPv1 small message reduction supported multiple scientific computing applications in parallel.&nbsp;</p>\n\n\n\n<p>MVAPICH2 is an open-source implementation of the MPI standard, specifically designed for high-performance computing (HPC) environments. The Ohio State University team responsible for the MVAPICH MPI library has demonstrated the performance achievement of SHARP on the Texas Advanced Computing Center Frontera supercomputer. From 5x higher performance for MPI AllReduce and up to 9x for MPI Barrier collective communications. For more information, see <a href=\"https://par.nsf.gov/servlets/purl/10249393\">Scalable MPI Collectives using SHARP: Large Scale Performance Evaluation on the TACC Frontera System</a>.</p>\n\n\n\n<p>The second generation of SHARP was introduced with the NVIDIA HDR 200Gb/s Quantum InfiniBand switch generation and added support for AI workloads. SHARPv2 includes support for large message reduction operations, supporting a single workload at a time. This version further improved the scalability and flexibility of the technology by supporting more complex data types and aggregation operations.&nbsp;</p>\n\n\n\n<p>SHARPv2 performance advantage was demonstrated with NVIDIA MLPerf submission and results in June 2021, demonstrating 17% higher BERT training performance. For more information, see <a href=\"https://developer.nvidia.com/blog/mlperf-v1-0-training-benchmarks-insights-into-a-record-setting-performance/\">MLPerf v1.0 Training Benchmarks: Insights into a Record-Setting NVIDIA Performance</a><strong>.</strong></p>\n\n\n\n<p>Michael Houston, vice president and chief architect of AI systems at NVIDIA, presented the <a href=\"https://ucbrise.github.io/cs294-ai-sys-sp22/\">AllReduce performance benefits of SHARPv2</a>, in a UC Berkeley&#8217;s Machine Learning Systems course.</p>\n\n\n\n<p>The 2x performance benefit of the AllReduce bandwidth translated into 17% higher BERT training performance.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"398\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-1024x398.png\" alt=\"Two graphs. A line chart shows performance at various scales with and without SHARP. A bar chart shows SHARP performance across the most commonly used message sizes.\n\" class=\"wp-image-90868\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-1024x398.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-300x116.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-625x243.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-179x69.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-768x298.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-1536x596.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-645x250.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-500x194.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-160x62.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-362x141.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results-283x110.png 283w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/hdr200-selene-results.png 1999w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Example from UC Berkeley&#8217;s Machine Learning Systems course </em><br><em>(source:</em> <a href=\"https://ucbrise.github.io/cs294-ai-sys-sp22/\">Distributed deep learning, Part II: Scaling Constraints</a><em>)</em></figcaption></figure>\n\n\n\n<p>Most recently, the third generation of SHARP was introduced with the <a href=\"https://www.nvidia.com/en-gb/networking/quantum2/\">NVIDIA Quantum-2 NDR 400G InfiniBand</a> platform. SHARPv3 supports multi-tenant in-network computing for AI workloads, meaning that multiple AI workloads are supported in parallel compared to the single workload with SHARPv2.</p>\n\n\n\n<p>SHARPv3 performance was presented by Jithin Jose, principal software engineer at Microsoft Azure in the session, <a href=\"https://www.nvidia.com/en-us/on-demand/session/gtcspring23-s51204/?playlistId=playList-dcc84447-8c5e-4708-a21f-8429a4ac2abf\">Transforming Clouds to Cloud-Native Supercomputing: Best Practices with Microsoft Azure</a>. Jithin covered InfiniBand\u2019s in-network computing technologies at Azure and showcased nearly an order of magnitude performance benefits for AllReduce latency.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"717\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-1024x717.png\" alt=\"Line chart shows latency benefits of SHARPv3 compared to no SHARP across a range of message sizes. \" class=\"wp-image-90870\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-1024x717.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-300x210.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-625x438.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-164x115.png 164w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-768x538.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-645x452.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-429x300.png 429w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-129x90.png 129w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-362x253.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements-157x110.png 157w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/allreduce-latency-improvements.png 1430w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. AllReduce latency performance benefits for SHARPv3</em></figcaption></figure></div>\n\n\n<h2 id=\"end-to-end_ai_system_optimization\"  class=\"wp-block-heading\">End-to-end AI system optimization<a href=\"#end-to-end_ai_system_optimization\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>A powerful example of SHARP can be seen with the all-reduce operation. Gradients are summed across multiple GPUs or nodes during model training, and SHARP aggregates the gradients in-network, avoiding the need to send full data sets between GPUs or across nodes. This reduces the communication time, leading to faster iteration times and higher throughput for AI workloads.</p>\n\n\n\n<p>Before the era of in-network computing and SHARP, NVIDIA Collective Communication Library (NCCL) communication software would copy all the model weights from the graph, perform an all-reduce operation to sum the weights, and then write the updated weights back to the graph, resulting in multiple data copies.&nbsp;</p>\n\n\n\n<p>In 2021, the NCCL team began integrating SHARP, introducing user buffer registration. This enabled NCCL collectives to use pointers directly, eliminating the need to copy data back and forth during the process and improving efficiency.</p>\n\n\n\n<p>Today, SHARP is tightly integrated with NCCL, which is widely used in distributed AI training frameworks. NCCL is optimized to take advantage of SHARP by offloading key collective communication operations to the network, significantly improving both the scalability and performance of distributed deep learning workloads.</p>\n\n\n\n<p>SHARP technology helps to increase the performance of distributed computing applications. SHARP is being used by HPC supercomputing centers for their scientific computing workloads, and also by AI supercomputers for the AI applications. SHARP is the \u201csecret sauce\u201d that is enabling a competitive advantage. A large service provider uses SHARP to improve its performance across in-house AI workloads from 10\u201320%.&nbsp;&nbsp;</p>\n\n\n\n<h2 id=\"sharpv4\"  class=\"wp-block-heading\">SHARPv4<a href=\"#sharpv4\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>SHARPv4 introduces new algorithms to support a larger variety of collective communications that are now used in leading AI training applications. It will be released with the <a href=\"https://www.nvidia.com/en-us/networking/products/infiniband/quantum-x800/\">NVIDIA Quantum-X800 XDR InfiniBand switch platforms</a>, delivering the next level of in-network computing.</p>\n\n\n\n<h2 id=\"summary\"  class=\"wp-block-heading\">Summary<a href=\"#summary\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>For more information, see the following resources:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Technical Blog posts:\n<ul class=\"wp-block-list\">\n<li><a href=\"https://developer.nvidia.com/blog/nvidia-slashes-bert-training-and-inference-times/\">NVIDIA Slashes BERT Training and Inference Times</a></li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/blog/boosting-mlperf-training-v1-1-performance-with-full-stack-optimization/\">Boosting NVIDIA MLPerf Training v1.1 Performance with Full Stack Optimization</a></li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/blog/setting-new-records-at-data-center-scale-using-nvidia-h100-gpus-and-quantum-2-infiniband/\">Setting New Records at Data Center Scale Using NVIDIA H100 GPUs and NVIDIA Quantum-2 InfiniBand</a></li>\n</ul>\n</li>\n\n\n\n<li>Videos:\n<ul class=\"wp-block-list\">\n<li><a href=\"https://www.youtube.com/watch?v=XfwqoJEXGNM&amp;t=1993s\">Tutorial: SHARP: In-Network Scalable Hierarchical Aggregation and Reduction Protocol</a></li>\n\n\n\n<li><a href=\"https://youtu.be/is7aBZ1_Op0\">In-Network Computing with NVIDIA SHARP</a></li>\n\n\n\n<li><a href=\"https://www.nvidia.com/en-us/on-demand/session/gtc24-s63276/\">Behind the Scenes with Azure AI Infrastructure (Presented by Microsoft) | GTC 24 2024 | NVIDIA On-Demand</a></li>\n</ul>\n</li>\n\n\n\n<li><a href=\"https://par.nsf.gov/servlets/purl/10249393\">Scalable MPI Collectives using SHARP: Large Scale Performance Evaluation on the TACC Frontera System</a></li>\n\n\n\n<li><a href=\"https://learn.microsoft.com/en-us/samples/azure/azureml-examples/run-nccl-tests-on-gpu-to-check-performance-and-configuration/\">Run NCCL tests on GPU to check performance and configuration</a></li>\n\n\n\n<li><a href=\"https://network.nvidia.com/pdf/solutions/hpc/paperieee_copyright.pdf\">Scalable Hierarchical Aggregation Protocol : A Hardware Architecture for Efficient Data Reduction</a></li>\n</ul>\n", "protected": false}, "excerpt": {"rendered": "<p>AI and scientific computing applications are great examples of distributed computing problems. The problems are too large and the computations too intensive to run on a single machine. These computations are broken down into parallel tasks that are distributed across thousands of compute engines, such as CPUs and GPUs.&nbsp; To achieve scalable performance, the system &hellip; <a href=\"https://developer.nvidia.com/blog/advancing-performance-with-nvidia-sharp-in-network-computing/\">Continued</a></p>\n", "protected": false}, "author": 1112, "featured_media": 90867, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1509195", "discourse_permalink": "https://forums.developer.nvidia.com/t/advancing-performance-with-nvidia-sharp-in-network-computing/311180", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1205], "tags": [453, 658], "coauthors": [2310], "class_list": ["post-90863", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-networking-communications", "tag-featured", "tag-infiniband"], "acf": {"post_industry": ["Hardware / Semiconductor"], "post_products": ["NCCL"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-sharp-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nDx", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Networking / Communications", "link": "https://developer.nvidia.com/blog/category/networking-communications/", "id": 1205}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90863"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1112"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90863"}], "version-history": [{"count": 4, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90863/revisions"}], "predecessor-version": [{"id": 90951, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90863/revisions/90951"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90867"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90863"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90863"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90863"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90863"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90907, "date": "2024-10-25T08:00:00", "date_gmt": "2024-10-25T15:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90907"}, "modified": "2024-10-31T11:37:06", "modified_gmt": "2024-10-31T18:37:06", "slug": "nvidia-showcases-the-future-of-intelligent-robots-at-corl-2024", "status": "publish", "type": "post", "link": "https://nvda.ws/3NFp6Cu", "title": {"rendered": "NVIDIA Showcases the Future of Intelligent Robots at CoRL 2024"}, "content": {"rendered": "\n<p>From humanoids to policy, explore the work NVIDIA is bringing to the robotics community.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>From humanoids to policy, explore the work NVIDIA is bringing to the robotics community.</p>\n", "protected": false}, "author": 1304, "featured_media": 90908, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1509044", "discourse_permalink": "https://forums.developer.nvidia.com/t/nvidia-showcases-the-future-of-intelligent-robots-at-corl-2024/311163", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/3NFp6Cu", "_links_to_target": "_blank"}, "categories": [63], "tags": [453, 4145, 1958, 1962, 282, 3424, 3584], "coauthors": [2668], "class_list": ["post-90907", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-robotics", "tag-featured", "tag-humanoid-robots", "tag-news", "tag-nvidia-research", "tag-reinforcement-learning", "tag-robot-manipulation", "tag-robotics-simulation"], "acf": {"post_industry": ["Academia / Education", "Healthcare & Life Sciences", "Manufacturing", "Public Sector", "Restaurant / Quick-Service", "Smart Cities / Spaces"], "post_products": ["Isaac ROS", "Isaac SDK", "Isaac Sim"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["News"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/isaac-robotics-blog-3249864-1920x1080-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nEf", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Robotics", "link": "https://developer.nvidia.com/blog/category/robotics/", "id": 63}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90907"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1304"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90907"}], "version-history": [{"count": 1, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90907/revisions"}], "predecessor-version": [{"id": 90928, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90907/revisions/90928"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90908"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90907"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90907"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90907"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90907"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90884, "date": "2024-10-24T12:21:33", "date_gmt": "2024-10-24T19:21:33", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90884"}, "modified": "2024-10-31T11:37:24", "modified_gmt": "2024-10-31T18:37:24", "slug": "powering-the-next-wave-of-ai-robotics-with-three-computers", "status": "publish", "type": "post", "link": "https://nvda.ws/48j1ixK", "title": {"rendered": "Powering the Next Wave of AI Robotics with Three Computers\u00a0"}, "content": {"rendered": "\n<p>NVIDIA has built three computers and accelerated development platforms to enable developers to create physical AI.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>NVIDIA has built three computers and accelerated development platforms to enable developers to create physical AI.</p>\n", "protected": false}, "author": 2400, "featured_media": 90899, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1508407", "discourse_permalink": "https://forums.developer.nvidia.com/t/powering-the-next-wave-of-ai-robotics-with-three-computers/311052", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/48j1ixK", "_links_to_target": "_blank"}, "categories": [2758, 63], "tags": [453, 4145, 2375, 1958], "coauthors": [4136], "class_list": ["post-90884", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-edge-computing", "category-robotics", "tag-featured", "tag-humanoid-robots", "tag-industrial-digitalization-digital-twin", "tag-news"], "acf": {"post_industry": ["Agriculture", "Architecture / Engineering / Construction", "Automotive / Transportation", "Manufacturing", "Public Sector", "Restaurant / Quick-Service", "Retail / Consumer Packaged Goods", "Smart Cities / Spaces"], "post_products": ["DGX", "Isaac Sim", "Jetson", "Omniverse"], "post_learning_levels": ["Beginner Technical"], "post_content_types": ["News"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/NVIDIA-3-Computers-image.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nDS", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Robotics", "link": "https://developer.nvidia.com/blog/category/robotics/", "id": 63}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90884"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2400"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90884"}], "version-history": [{"count": 2, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90884/revisions"}], "predecessor-version": [{"id": 90895, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90884/revisions/90895"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90899"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90884"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90884"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90884"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90884"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 89875, "date": "2024-10-24T11:02:16", "date_gmt": "2024-10-24T18:02:16", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=89875"}, "modified": "2024-10-31T11:37:51", "modified_gmt": "2024-10-31T18:37:51", "slug": "augmenting-security-operations-centers-with-accelerated-alert-triage-and-llm-agents-using-nvidia-morpheus", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/augmenting-security-operations-centers-with-accelerated-alert-triage-and-llm-agents-using-nvidia-morpheus/", "title": {"rendered": "Augmenting Security Operations Centers with Accelerated Alert Triage and LLM Agents Using NVIDIA Morpheus"}, "content": {"rendered": "\n<p>Every day, security operation center (SOC) analysts receive an overwhelming amount of incoming security alerts. To ensure the continued safety of their organization, they are tasked with wading through the incoming noise, triaging out false positives, and sniffing out what could be indicators of a true security breach. However, the sheer quantity of alerts may mean that important early indicators of a breach get buried. Not to mention the process itself, which is often repetitive, time-consuming, and costly.</p>\n\n\n\n<p>Can we build a workflow to alleviate these issues while still maintaining a good or even better level of security?</p>\n\n\n\n<p>We begin this attempt by looking at <a href=\"https://www.nvidia.com/en-us/ai-data-science/products/morpheus/\">NVIDIA Morpheus</a>, a GPU-accelerated cybersecurity AI framework for processing and analyzing high-velocity data streams. In particular, we focus on the <a href=\"https://www.nvidia.com/en-us/ai-data-science/ai-workflows/digital-fingerprinting/\">digital fingerprinting</a> AI workflow, which enables large-scale anomaly detection on networks.&nbsp;</p>\n\n\n\n<p>The digital fingerprinting workflow learns the normal behavior profile of any given entity, representing it in an autoencoder model. When behavior deviates, such as if a user displays several new geolocations, a z-score is generated with a magnitude corresponding to the degree of abnormality.&nbsp;</p>\n\n\n\n<h2 id=\"incorporating_generative_ai_with_nvidia_nim_to_enhance_security_operations&nbsp;\"  class=\"wp-block-heading\">Incorporating generative AI with NVIDIA NIM to enhance security operations&nbsp;<a href=\"#incorporating_generative_ai_with_nvidia_nim_to_enhance_security_operations&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Traditionally, outputs of AI-based cyber-anomaly detection pipelines, such as digital fingerprinting, are tabular data structures with anomaly scores and additional metadata regarding which parts of a security event were anomalous.&nbsp;</p>\n\n\n\n<p>While this feed is highly informative, it can be time-consuming to interpret. In this post, we describe how we augmented the digital fingerprinting workflow with generative AI to demonstrate how you can instead transform these outputs into actionable insights that are easy to interpret and interact with.&nbsp;</p>\n\n\n\n<p>Using a default Llama 3.1 model, we synthesized these scattered insights into readable reports, producing one report per user. The goal of this synthesis process is to catch, group, and place alerts that would otherwise have been categorized as too low-priority to receive a manual look-over. Automating this triage work also decreases the overall time to respond to an alert.</p>\n\n\n\n<p>Having finished generating and preprocessing alerts, you can use the user summary reports to inform a security co-pilot. The co-pilot receives verbal queries from a human SOC analyst and produces spoken responses.&nbsp;</p>\n\n\n\n<p>Here are the steps for the co-pilot process:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Transcribe the query into text.&nbsp;</li>\n\n\n\n<li>Deploy an LLM agent and give this agent access to the user summary reports. You also give read access to databases and tools that a human SOC analyst would traditionally use, including a user directory and a network traffic database.&nbsp;</li>\n\n\n\n<li>The agent performs iterative reasoning through retrieval-augmented generation (RAG).&nbsp;</li>\n\n\n\n<li>The LLM agent\u2019s final response is turned back into audio.</li>\n\n\n\n<li>The audio instructs the animations on the face of an avatar.</li>\n</ul>\n\n\n\n<p><a href=\"https://developer.nvidia.com/nim\">NVIDIA NIM</a> <em>microservices</em> (containerized standalone models that emphasize ease of deployment) are the heart of this agentic process.&nbsp;</p>\n\n\n\n<p>For speech services:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://build.nvidia.com/nvidia/parakeet-ctc-1_1b-asr\">Parakeet-CTC-1.1B</a> NIM microservice for automatic speech recognition (ASR) to transcribe voice queries to text.</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/nvidia/fastpitch-hifigan-tts\">FastPitch-HifiGAN</a> NIM microservice for text-to-speech (TTS) from NVIDIA Riva, to convert the LLM response back to audio.&nbsp;</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/meta/llama-3_1-405b-instruct\">Llama 3.1</a> NIM microservice powers the LLM agent.&nbsp;</li>\n</ul>\n\n\n\n<p>For the embedding and retrieval process of RAG:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://build.nvidia.com/nvidia/embed-qa-4\">embed-qa-4 model</a> NIM microservice for embedding, from <a href=\"https://www.nvidia.com/en-us/ai-data-science/products/nemo/\">NVIDIA NeMo Retriever</a>.&nbsp;</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/nvidia/rerank-qa-mistral-4b\">rerank-qa-mistral-4b model</a> for reranking, also from NeMo Retriever.&nbsp;</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/nvidia/audio2face\">NVIDIA Audio2Face NIM</a> animates the digital face mesh, which in this project is a default Metahuman face rendered in Unreal Engine 5.4.&nbsp;</li>\n</ul>\n\n\n\n<p>Inference calls powered by self-hosted NIM microservices can easily be swapped out for cloud-based endpoints hosted at <a href=\"https://build.nvidia.com/explore/discover\">build.nvidia.com</a> because of the common API standard, providing a lightweight way of testing different model API endpoints.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"437\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-1024x437.png\" alt=\"A diagram shows modules for data ingestion, processing, and output, with connections between components labeled.\" class=\"wp-image-89883\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-1024x437.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-300x128.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-625x267.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-179x76.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-768x328.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-645x276.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-500x214.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-160x68.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-362x155.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture-257x110.png 257w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/security-co-pilot-ref-architecture.png 1271w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Security analyst co-pilot full reference architecture</em></figcaption></figure></div>\n\n\n<p>The result of integrating this full architecture is a smart security co-pilot for streamlining SOC analyst tasks. Next, we discuss a complete scenario that shows just how much time and repetitive labor this workflow saves.</p>\n\n\n\n<h2 id=\"co-pilot_on\"  class=\"wp-block-heading\">Co-pilot: On<a href=\"#co-pilot_on\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Imagine that you are a Level 1 SOC analyst encountering an alert that claims the endpoint user june@domain.com has been displaying unusual volumes of outbound network traffic.&nbsp;</p>\n\n\n\n<p>First, you check your internal database of network traffic. You must write some strict query language rules to specify the parameters you\u2019re searching in, such as time frame.&nbsp;</p>\n\n\n\n<p>Upon constructing and running the query, you see one recurring destination URL. You enter this URL into a malware detection tool, such as <a href=\"https://www.virustotal.com/gui/home/upload\">VirusTotal</a>. The URL historically belongs to a known malicious actor, so you conclude that this alert is a true positive.&nbsp;</p>\n\n\n\n<p>As you can see, SOC analyst is one of many occupations that involves juggling numerous dashboards and data modalities, leading to repetitive tasks that could benefit from automation.</p>\n\n\n\n<p>This series of events could be accomplished with a verbal request to the RAG co-pilot: \u201cCan you provide me additional insight about whether the user june@domain.com has been compromised?\u201d</p>\n\n\n\n<p>Because the LLM agent has been given access to all the internal and external data that a human analyst would have, it can reason to itself about the most logical path to perform an investigation and then gather the pieces of evidence needed by such an investigation.&nbsp;</p>\n\n\n\n<p>When it comes to cybersecurity, we want to mitigate risk as far as possible, due to the large impact that cyber threats can have. The LLM does not synthesize any conclusions but presents what it believes to be relevant evidence to the human analyst. The SOC analyst can then give a final verdict, or inquire further. To follow up, you might ask the LLM agent something like, \u201cDid you notice any other users displaying similar indicators of compromise?\u201d</p>\n\n\n\n<p>Our ultimate goal is to increase the productivity of SOC analysts, enabling you to focus on detecting and mitigating cyber attacks that are more complicated and creative. The freedom afforded by natural language querying means that you no longer have to construct rigid, rule-based searches, or take additional time to interpret granular numerical data.&nbsp;</p>\n\n\n\n<p>Meanwhile, the keyboard-free speech interaction enabled by <a href=\"https://build.nvidia.com/explore/speech\">NVIDIA Riva NIM microservices</a> speeds up every interaction.</p>\n\n\n\n<p>A secondary aim of the co-pilot is to build user trust. Compared to a fully event-driven and automatic execution chain, the end user can control and inquire about each step of the LLM\u2019s reasoning. Adding the NVIDIA ACE <a href=\"https://build.nvidia.com/nvidia/audio2face\">Audio2Face NIM microservice</a> turns interactions into intuitive conversational experiences, adding a layer of communication in facial expression. </p>\n\n\n\n<p>As a display of the art of the possible, we show how a user can engage in a back-and-forth discussion with the digital agent, as if problem-solving together on a team (Video 1). In this way, we are using AI to transform the security operations center.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/yrTpS3jF_rs?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. NVIDIA Morpheus Security Alert Triage LLM Agent</em></figcaption></figure>\n\n\n\n<p>In the future, we hope to work on easier integration of specific data sources, turning the currently asynchronous data pools into live event-driven ingests that can handle real-world volumes.&nbsp;</p>\n\n\n\n<p>In collaboration with the NVIDIA internal Threat Operations team, we\u2019re striving to pinpoint where tools such as this workflow can be most beneficial and intuitive for users.&nbsp;</p>\n\n\n\n<h2 id=\"getting_started_with_nvidia_morpheus&nbsp;\"  class=\"wp-block-heading\">Getting started with NVIDIA Morpheus&nbsp;<a href=\"#getting_started_with_nvidia_morpheus&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Morpheus <a href=\"https://www.nvidia.com/en-us/ai-data-science/ai-workflows/digital-fingerprinting/\">digital fingerprinting</a>, as seen in this project, uniquely provides 100% data visibility for zero-trust anomaly detection on end users and devices.</p>\n\n\n\n<p>This checklist and multi-step agentic RAG workflow is based on the architecture provided by the Morpheus <a href=\"https://build.nvidia.com/nvidia/vulnerability-analysis-for-container-security\">security vulnerability analysis AI workflow</a>. The workflow was originally created to automate the screening for common vulnerabilities and exposures in code releases.&nbsp;</p>\n\n\n\n<p>At its core, it provides a reference architecture for iterative complex reasoning with parallelized inference, easily adaptable to multiple industries and use cases from a SOC co-pilot to a vision-accessibility tool that can navigate a dynamic open-world environment.</p>\n\n\n\n<p>Build powerful cybersecurity pipelines and complex agentic workflows using NVIDIA Morpheus with other NVIDIA NIM microservices.</p>\n\n\n\n<p>For more information, see the following resources:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><a href=\"https://developer.nvidia.com/morpheus-cybersecurity\">Morpheus Cybersecurity</a></li>\n\n\n\n<li><a href=\"https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-DS-03+V1\">Building AI-Based Cybersecurity Pipelines</a> (plus more <a href=\"https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+C-DS-03+V1\">instructor-led training</a> and <a href=\"https://learn.nvidia.com/courses/course-detail?course_id=course-v1:DLI+T-DS-02+V2\">self-paced courses</a>)</li>\n\n\n\n<li><a href=\"https://build.nvidia.com/explore/discover\">NVIDIA API Catalog</a> (NVIDIA NIM microservices for testing and self-hosted deployment)</li>\n\n\n\n<li><a href=\"https://github.com/NVIDIA/GenerativeAIExamples/tree/main/community/digital-human-security-analyst\" target=\"_blank\" rel=\"noreferrer noopener\">Digital Human Security Analyst</a> GitHub repo</li>\n</ul>\n", "protected": false}, "excerpt": {"rendered": "<p>Every day, security operation center (SOC) analysts receive an overwhelming amount of incoming security alerts. To ensure the continued safety of their organization, they are tasked with wading through the incoming noise, triaging out false positives, and sniffing out what could be indicators of a true security breach. However, the sheer quantity of alerts may &hellip; <a href=\"https://developer.nvidia.com/blog/augmenting-security-operations-centers-with-accelerated-alert-triage-and-llm-agents-using-nvidia-morpheus/\">Continued</a></p>\n", "protected": false}, "author": 2348, "featured_media": 90552, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1508375", "discourse_permalink": "https://forums.developer.nvidia.com/t/augmenting-security-operations-centers-with-accelerated-alert-triage-and-llm-agents-using-nvidia-morpheus/311041", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1464], "tags": [453, 3650, 1511], "coauthors": [4081, 4082], "class_list": ["post-89875", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-cybersecurity", "tag-featured", "tag-llm-techniques", "tag-security-ai"], "acf": {"post_industry": ["Financial Services"], "post_products": ["Morpheus", "NeMo Retriever"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cybersecurity-digital-fingerprint-human-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nnB", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Cybersecurity", "link": "https://developer.nvidia.com/blog/category/cybersecurity/", "id": 1464}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/89875"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2348"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=89875"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/89875/revisions"}], "predecessor-version": [{"id": 90881, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/89875/revisions/90881"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90552"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=89875"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=89875"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=89875"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=89875"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90086, "date": "2024-10-24T09:30:00", "date_gmt": "2024-10-24T16:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90086"}, "modified": "2024-10-31T09:26:15", "modified_gmt": "2024-10-31T16:26:15", "slug": "bridging-the-cuda-c-ecosystem-and-python-developers-with-numbast", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/bridging-the-cuda-c-ecosystem-and-python-developers-with-numbast/", "title": {"rendered": "Bridging the CUDA C++ Ecosystem and Python Developers with Numbast"}, "content": {"rendered": "\n<p>By enabling CUDA kernels to be written in Python similar to how they can be implemented within C++, Numba bridges the gap between the Python ecosystem and the performance of CUDA.&nbsp;</p>\n\n\n\n<p>However, CUDA C++ developers have access to many libraries that presently have no exposure in Python. These include the CUDA Core Compute Libraries (CCCL), cuRAND, and header-based implementations of numeric types like bfloat16, to name a few.</p>\n\n\n\n<p>While each CUDA C++ library can introduce itself to Python in its own way, manually making bindings for each library is laborious, repetitive, and prone to inconsistency. For example, the float16 and bfloat16 data types define over 60 similar standalone functions and similar bindings would be needed multiple times for both types.&nbsp;</p>\n\n\n\n<p>In addition, manually created bindings often fall out of sync when the underlying CUDA C++ library introduces new features.</p>\n\n\n\n<h2 id=\"solution_numbast\"  class=\"wp-block-heading\">Solution: Numbast<a href=\"#solution_numbast\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Numbast establishes an automated pipeline that converts CUDA C/C++ APIs into Numba bindings.</p>\n\n\n\n<p>At a high level, top-level declarations are read from CUDA C++ header files, serialized, and passed to Python APIs. Numba binding generators then iterate through these declarations and generate Numba extensions for each of the APIs.</p>\n\n\n\n<h2 id=\"demo_c++_declaration_of_a_simple_struct\"  class=\"wp-block-heading\">Demo: C++ declaration of a simple struct<a href=\"#demo_c++_declaration_of_a_simple_struct\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>To show Numbast in action, the following example shows how Numba bindings are created for a demo <code>myfloat16</code> type. These C++ declarations are inspired by those in the CUDA <code>float16</code> header, giving a simplified version to demonstrate the binding generation in practice.</p>\n\n\n\n<h3 id=\"c++_declaration\"  class=\"wp-block-heading\">C++ declaration<a href=\"#c++_declaration\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>This demo shows the following elements in C++ syntax:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n// demo.cuh\nstruct __attribute__((aligned(2))) myfloat16\n{\npublic:\n half data;\n\n __host__ __device__ myfloat16();\n\n __host__ __device__ myfloat16(double val);\n\n __host__ __device__ operator float() const;\n};\n__host__ __device__ myfloat16 operator+(const myfloat16 &amp;lh, const myfloat16 &amp;rh);\n\n__host__ __device__ myfloat16 hsqrt(const myfloat16 a);\n</pre></div>\n\n\n<ul class=\"wp-block-list\">\n<li>A struct declaration, which has\n<ul class=\"wp-block-list\">\n<li>Device constructors</li>\n\n\n\n<li>A few device methods, including conversion and arithmetic operators</li>\n</ul>\n</li>\n\n\n\n<li>Two function declarations: arithmetic operator overload and a square root function.</li>\n</ul>\n\n\n\n<p>For more information about the language features supported in Numbast, see <a href=\"https://github.com/NVIDIA/numbast/tree/main/numbast#supported-cuda-c-declarations\">Supported CUDA C++ declarations</a>.</p>\n\n\n\n<h3 id=\"setup_script_with_numbast\"  class=\"wp-block-heading\">Setup script with Numbast<a href=\"#setup_script_with_numbast\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Numbast usage normally involves two steps:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Parsing header files with <code>AST_Canopy</code>.</li>\n\n\n\n<li>Generating Numba bindings from parsed headers.</li>\n</ol>\n\n\n\n<p>The following code example sets up the Numba bindings by implementing these two steps:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nimport os\nfrom ast_canopy import parse_declarations_from_source\nfrom numbast import bind_cxx_struct, bind_cxx_function, MemoryShimWriter\n\nfrom numba import types, cuda\nfrom numba.core.datamodel.models import PrimitiveModel\n\nimport numpy as np\n# Step 1:\n# Use `AST_Canopy` to parse demo.cuh as AST, read all declarations from it.\nsource = os.path.join(os.path.dirname(__file__), &quot;demo.cuh&quot;)\n# Assume that you want to generate bindings for a machine with &quot;sm_80&quot;\n# capability.\nstructs, functions, *_ = parse_declarations_from_source(source, &#x5B;source], &quot;sm_80&quot;)\n\nshim_writer = MemoryShimWriter(f&#039;#include &quot;{source}&quot;&#039;)\n# Step 2:\n# Make Numba bindings from the declarations.\n# New type &quot;myfloat16&quot; is a Number type, data model is `PrimitiveModel`.\nmyfloat16 = bind_cxx_struct(shim_writer, structs&#x5B;0], types.Number, PrimitiveModel)# bind_cxx_function returns the generated bindings to the C++ declaration.# The first function binds to an operator, and it\u2019s bound to `operator.add`. You can directly use `myfloat16 + myfloat16` in kernels.\nbind_cxx_function(shim_writer, functions&#x5B;0])# The second function is `hsqrt`, with which Numbast creates a new Python handle and returns it in the return value.\nhsqrt = bind_cxx_function(shim_writer, functions&#x5B;1])\n</pre></div>\n\n\n<p><em>Data models</em> are the different ways that Numba represents the underlying data. The <code>PrimitiveModel</code> model that is used for <code>myfloat16</code> is well-suited for scalars. A <code>StructModel</code> model (not used here) is useful for classes and structs. Other data models are less commonly used.</p>\n\n\n\n<h3 id=\"usage_in_the_most_natural_way\"  class=\"wp-block-heading\">Usage in the most natural way<a href=\"#usage_in_the_most_natural_way\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>In CUDA C++, you can construct a myfloat16<em> </em>object and use it as follows:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n__global__ void kernel()\n{\n\u00a0 auto one = myfloat16(1.0);\n\u00a0 auto two = myfloat16(2.0);\n\u00a0 auto three = one + two;\n\u00a0 auto sqrt3 = hsqrt(three);\n}\n</pre></div>\n\n\n<p>In Numba kernels, you use them as-is:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n@cuda.jit(link=shim_writer.links())\ndef kernel():\n\u00a0 one = myfloat16(1.0)\n\u00a0 two = myfloat16(2.0)\n\u00a0 three = one + two\n\u00a0 sqrt3 = hsqrt(three)\n</pre></div>\n\n\n<p>Thanks to type inference in Numba, the code is even cleaner than the original C++.</p>\n\n\n\n<h3 id=\"first_supported_bindings_bfloat16_data_type\"  class=\"wp-block-heading\">First supported bindings: bfloat16 data type<a href=\"#first_supported_bindings_bfloat16_data_type\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The first Numba binding supported through Numbast is a new <code>bfloat16</code> data type. The <code>bfloat16</code> data type can interoperate with PyTorch\u2019s <code>torch.bfloat16</code> data type, so that you can efficiently develop custom compute kernels with this new data type.&nbsp;</p>\n\n\n\n<p>The following code example shows how to use the new <code>bfloat16</code> data type to develop a Numba kernel that performs computation on torch tensors. It passes a PyTorch array of <code>torch.bfloat16</code> type into a Numba compute kernel and performs math operations using CUDA intrinsics bound through Numbast.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nfrom numba import float32\nimport numba.cuda as cuda\nimport torch\nfrom numbast_extensions.bf16 import get_shims, hsin, nv_bfloat16\n\n\n@cuda.jit(link=get_shims())\ndef torch_add_sin(a, b, out):\n\u00a0 i, j = cuda.grid(2)\n\u00a0 if i &lt; out.shape&#x5B;0] and j &lt; out.shape&#x5B;1]:\n\u00a0 \u00a0 \u00a0 # Arithmetic of bfloat16 type\n\u00a0 \u00a0 \u00a0 sum = a&#x5B;i, j] + b&#x5B;i, j]\n\u00a0 \u00a0 \u00a0 # Bfloat16 native intrinsics\n\u00a0 \u00a0 \u00a0 sin_of_sum = hsin(sum)\n\u00a0 \u00a0 \u00a0 # bf16 to f32 upcast\n\u00a0 \u00a0 \u00a0 f32 = float32(sin_of_sum)\n\u00a0 \u00a0 \u00a0 # f32 to bf16 downcast\n\u00a0 \u00a0 \u00a0 bf16 = nv_bfloat16(f32)\n\u00a0 \u00a0 \u00a0 # Assignment to external array\n\u00a0 \u00a0 \u00a0 out&#x5B;i, j] = bf16\n\n\na = torch.ones(&#x5B;2, 2], device=torch.device(&quot;cuda:0&quot;), dtype=torch.bfloat16)\nb = torch.ones(&#x5B;2, 2], device=torch.device(&quot;cuda:0&quot;), dtype=torch.bfloat16)\nexpected = torch.sin(a + b)\n\nout = torch.zeros(&#x5B;2, 2], device=torch.device(&quot;cuda:0&quot;), dtype=torch.bfloat16)\n\nthreadsperblock = (16, 16)\nblockspergrid = (1, 1)\ntorch_add_sin&#x5B;blockspergrid, threadsperblock](a, b, out)\nassert torch.equal(expected, out)\n</pre></div>\n\n\n<p>You can download Numbast and the <code>bfloat16</code> Numba bindings from <code>conda-forge</code>:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nconda install -c nvidia -c rapidsai -c conda-forge ml_dtypes numbast-extensions\n</pre></div>\n\n\n<h2 id=\"architecture\"  class=\"wp-block-heading\">Architecture<a href=\"#architecture\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Numbast consists of two components:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>AST_Canopy</code>: An underlying layer that parses and serializes C++ headers</li>\n\n\n\n<li>Numbast: A user-facing layer that consumes the parsed results and builds Numba bindings dynamically.&nbsp;</li>\n</ul>\n\n\n\n<h3 id=\"ast_canopy_declaration_parser\"  class=\"wp-block-heading\">AST_Canopy: declaration parser<a href=\"#ast_canopy_declaration_parser\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>In forest ecology, a <em>canopy </em>refers to the upper layer of a forest habitat zone. <code>AST_Canopy</code> is the package that inspects the top-level declarations in the forest of abstract syntax trees, extracting information from them and passing them to the Python layer. Here, top level refers to the public, user-facing APIs that a CUDA C++ library exposes to users.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"388\" height=\"143\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers.png\" alt=\"Diagram shows that the C++ core layer is libastcanopy, which depends on ClangTooling, Its functionalities are bridged to AST_Canopy through the binding layer Pylibastcanopy.\" class=\"wp-image-90112\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers.png 388w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers-300x111.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers-179x66.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers-160x59.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers-362x133.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/numbast-layers-298x110.png 298w\" sizes=\"(max-width: 388px) 100vw, 388px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Layered architecture of </em>AST_Canopy</figcaption></figure></div>\n\n\n<p>Figure 1 shows the architecture of <code>AST_Canopy</code>:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><code>clangTooling</code>: a Clang library used to support writing standalone tools, such as Numbast.</li>\n\n\n\n<li><code>libastcanopy</code>: Implements the declaration-parsing logic using <code>clangTooling</code>.</li>\n\n\n\n<li><code>pylibastcanopy</code>: A binding that directly exposes <code>libastcanopy</code> APIs in Python.</li>\n\n\n\n<li><code>AST_Canopy</code>: A layer on top of <code>pylibastcanopy</code> that provides a pleasantly Pythonic user experience.</li>\n</ul>\n\n\n\n<p>In addition to header parsing and serialization, <code>AST_Canopy</code> also provides the following features:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Environment detection at runtime:</strong> Auto-detects the <code>libstdcxx</code> and CUDA headers installed through Conda packages, and sets up the <code>clang</code> compilers accordingly.</li>\n\n\n\n<li><strong>Flexibility in compute capability parsing:</strong> Enables configuring AST parsing based on different compute capabilities. Some headers conditionally expose code based on compute capability, and this feature supports cases where the header serialization and runtime environments are different.</li>\n</ul>\n\n\n\n<h3 id=\"numbast_binding_generator\"  class=\"wp-block-heading\">Numbast: binding generator<a href=\"#numbast_binding_generator\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Numbast is downstream to AST_Canopy, which consumes the declaration information and generates Numba bindings automatically. At a high level, Numbast exists to provide a translation layer between C++ and Python syntax. As the demo suggests, most simple C++ syntax finds its natural counterpart in Python (Table 1). <em> </em></p>\n\n\n\n<figure class=\"wp-block-table aligncenter is-style-stripes\"><table class=\"has-fixed-layout\"><tbody><tr><td><strong>Operation</strong></td><td><strong>CUDA C++</strong></td><td><strong>Numba</strong></td></tr><tr><td>Object construction</td><td><code>auto hpi = myfloat16(3.14)</code></td><td><code>hpi = myfloat16(3.14)</code></td></tr><tr><td>Attribute access</td><td><code>auto data = hpi.data</code></td><td><code>data = hpi.data</code></td></tr><tr><td>Function invocation</td><td><code>auto r = hsqrt(hpi)</code></td><td><code>r = hsqrt(hpi)</code></td></tr><tr><td>Type casts</td><td><code>auto fpi = float(hpi);</code></td><td><code>fpi = types.float32(hpi)</code></td></tr><tr><td>Arithmetic operations</td><td><code>auto pi2 = hpi + hpi</code></td><td><code>pi2 = hpi + hpi</code></td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 1. Mapping of CUDA C++ syntax onto Python syntax</em></figcaption></figure>\n\n\n\n<p>Numba\u2019s type system has much in common with C and C++-like languages. Of course, there are also features not present in Python, such as pointer semantics and template-based meta-programming.&nbsp;</p>\n\n\n\n<p>Numbast is the middle layer that encapsulates the similarities and differences between C++ and Python.</p>\n\n\n\n<h2 id=\"lowering_the_bigger_picture\"  class=\"wp-block-heading\">Lowering: The bigger picture<a href=\"#lowering_the_bigger_picture\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Bindings generated using Numbast are lowered with a feature in Numba called <a href=\"https://numba.readthedocs.io/en/stable/cuda/cuda_ffi.html#declaration-in-python\">foreign function invocation </a>(FFI). Numba ABI-compatible shim functions wrapping over the native CUDA function call are generated and then compiled with NVRTC. Expect the same optimized performance that a CUDA C++ developer enjoys, minus the performance of FFI.&nbsp;</p>\n\n\n\n<p>Future versions of <a href=\"https://github.com/NVIDIA/numba-cuda\">Numba-cuda</a> will introduce <a href=\"https://developer.nvidia.com/blog/cuda-12-0-compiler-support-for-runtime-lto-using-nvjitlink-library/\">link time optimization (LTO)</a> support, further eliminating the performance gap between accelerated Numba kernel and native CUDA C++.</p>\n\n\n\n<h2 id=\"caveats\"  class=\"wp-block-heading\">Caveats<a href=\"#caveats\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Both <code>AST_Canopy</code> and Numbast have caveats worth noting. <code>AST_Canopy</code> depends on <code>clangTooling</code>. Both new CUDA language features that are not yet supported by <code>clangTooling</code> and libraries that depend on the new language feature may not be correctly parsed. However, the majority of libraries and headers make use of features supported by <code>clangTooling</code>.</p>\n\n\n\n<h2 id=\"conclusion\"  class=\"wp-block-heading\">Conclusion<a href=\"#conclusion\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>In this post, we introduced a new Numba binding generation tool, Numbast.&nbsp;We showed that, by using Numbast, you can quickly benefit from the ever-growing feature set of CUDA C++.&nbsp;</p>\n\n\n\n<p>Numbast v0.1.0 provides the new data type <code>bfloat16</code> to Numba. You can&nbsp;expect to see more bindings generated by Numbast, including new data types, NVSHMEM bindings, and CCCL bindings. </p>\n", "protected": false}, "excerpt": {"rendered": "<p>By enabling CUDA kernels to be written in Python similar to how they can be implemented within C++, Numba bridges the gap between the Python ecosystem and the performance of CUDA.&nbsp; However, CUDA C++ developers have access to many libraries that presently have no exposure in Python. These include the CUDA Core Compute Libraries (CCCL), &hellip; <a href=\"https://developer.nvidia.com/blog/bridging-the-cuda-c-ecosystem-and-python-developers-with-numbast/\">Continued</a></p>\n", "protected": false}, "author": 1435, "featured_media": 90859, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1508338", "discourse_permalink": "https://forums.developer.nvidia.com/t/bridging-the-cuda-c-ecosystem-and-python-developers-with-numbast/311035", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 696, 503], "tags": [453, 204, 61], "coauthors": [2885, 4102], "class_list": ["post-90086", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-center-cloud", "category-data-science", "category-simulation-modeling-design", "tag-featured", "tag-numba", "tag-python"], "acf": {"post_industry": ["General"], "post_products": ["CUDA"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Tutorial"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-numba-numbast-featured-a.png", "jetpack_shortlink": "https://wp.me/pcCQAL-nr0", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Simulation / Modeling / Design", "link": "https://developer.nvidia.com/blog/category/simulation-modeling-design/", "id": 503}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90086"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1435"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90086"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90086/revisions"}], "predecessor-version": [{"id": 91297, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90086/revisions/91297"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90859"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90086"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90086"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90086"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90086"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90443, "date": "2024-10-24T09:00:00", "date_gmt": "2024-10-24T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90443"}, "modified": "2024-10-31T11:38:15", "modified_gmt": "2024-10-31T18:38:15", "slug": "federated-learning-in-autonomous-vehicles-using-cross-border-training", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/federated-learning-in-autonomous-vehicles-using-cross-border-training/", "title": {"rendered": "Federated Learning in Autonomous Vehicles Using Cross-Border Training"}, "content": {"rendered": "\n<p>Federated learning is revolutionizing the development of autonomous vehicles (AVs), particularly in cross-country scenarios where diverse data sources and conditions are crucial. Unlike traditional machine learning methods that require centralized data storage, federated learning enables AVs to collaboratively train algorithms using locally collected data while keeping the data decentralized. This approach enhances privacy and security, as sensitive data never leaves the country, and improves the robustness of the models by incorporating a wide range of driving environments and situations.&nbsp;</p>\n\n\n\n<p>Federated learning also helps address regulatory compliance and data movement restrictions, which are significant concerns in the global landscape. Different countries have varying regulations regarding data privacy and cross-border data transfers, making centralized data storage and processing challenging.&nbsp;</p>\n\n\n\n<p>By enabling local data usage and minimizing the need for data movement, federated learning ensures that AVs can adhere to these regulations while still benefiting from a collective learning process. As AVs traverse different terrains, climates, and traffic regulations across countries, federated learning enables them to adapt and optimize their performance, ensuring safer and more reliable autonomous driving experiences</p>\n\n\n\n<p>In this post, we describe our efforts to enable federated learning in AV cross-border training. We have developed an AV federated learning platform by using <a href=\"https://developer.nvidia.com/flare\">NVIDIA FLARE</a>, an open-source federated learning framework. With this platform, we trained a global model with more than a dozen AV models by using data from several different countries. We describe our use cases, integration with existing ML training platforms, and our job UI interfaces, as well as the challenges we went through.</p>\n\n\n\n<h2 id=\"motivation_and_use_cases\"  class=\"wp-block-heading\">Motivation and use cases<a href=\"#motivation_and_use_cases\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The NVIDIA AV team operates globally, collecting data from diverse regions to advance our AV initiatives. To train our models\u2014particularly for tasks such as object detection, parking, and sign detection\u2014we must consider the complexity of handling data from multiple countries.</p>\n\n\n\n<p>To develop separate AV models for each country, the approval processes multiply, increasing both costs and delays. With potentially dozens of distinct models, the burden of navigating regulatory approvals could become significant. Instead, a more efficient approach is to build a unified global model, provided that its performance meets or exceeds the metrics of individual country-specific models.</p>\n\n\n\n<p>Another motivation for incorporating data from multiple countries is the opportunity to address rare use cases that may not be represented in every country. While a globally trained model may not always lead to significant improvements in overall performance metrics, it can enhance the model&#8217;s ability to handle uncommon scenarios effectively</p>\n\n\n\n<p>Training a global model requires using diverse data sources. Traditionally, this would involve centralizing all data in a data lake and conducting training from a single location. However, this approach introduces several challenges. Synchronizing large volumes of multimodal sensor data is not only time-consuming but also expensive.&nbsp;</p>\n\n\n\n<p>Strict data protection laws in various regions\u2014such as China\u2019s Personal Information Protection Law (PIPL), the European Union\u2019s General Data Protection Regulation (GDPR) and AI Act, and similar regulations in Korea and elsewhere\u2014strictly limit cross-border data transfers, further complicating centralized training.</p>\n\n\n\n<p>To address these challenges, we\u2019ve developed a federated learning platform built on NVIDIA FLARE. This platform enables us to train deep learning models on country-specific data without needing direct access to raw datasets, ensuring compliance with local regulations while maintaining data privacy. By federating the data, we can train global AV models effectively, combining insights from diverse regions while adhering to privacy and regulatory requirements.</p>\n\n\n\n<h2 id=\"av_federated_learning_deployment_setup\"  class=\"wp-block-heading\">AV federated learning deployment setup<a href=\"#av_federated_learning_deployment_setup\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The deployment consists of two federated learning clients and a central server. The clients run on different machine learning training systems, while the FL server is hosted on AWS in Japan. In addition, we maintain a development FL server instance in Hong Kong for testing and ongoing development.</p>\n\n\n\n<p>Figure 1 shows the overall architecture.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"704\" height=\"374\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup.png\" alt=\"A map shows the Pacific Ocean, with one client in the USA, another client in China, and the federated learning server located in Japan.\" class=\"wp-image-90448\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup.png 704w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-300x159.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-625x332.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-179x95.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-645x343.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-500x266.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-160x85.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-362x192.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cross-border-federated-learning-setup-207x110.png 207w\" sizes=\"(max-width: 704px) 100vw, 704px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Cross-border federated learning setup</em></figcaption></figure></div>\n\n\n<h2 id=\"av_federated_learning_platform\"  class=\"wp-block-heading\"><strong>AV federated learning platform</strong><a href=\"#av_federated_learning_platform\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Our AV federated learning platform consists of many subsystems:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Integration with existing AV machine learning training system (MegLev: NDAS)&nbsp;</li>\n\n\n\n<li>Job orchestration service&nbsp;</li>\n\n\n\n<li>Federated learning engine with NVIDIA FLARE</li>\n</ul>\n\n\n\n<h3 id=\"integration_with_existing_av_training_platform\"  class=\"wp-block-heading\"><strong>Integration with existing AV Training platform</strong><a href=\"#integration_with_existing_av_training_platform\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>One major challenge in the system setup is effectively integrating two distinct training systems: the local machine learning infrastructure (MAGLEV), which is unaware of NVFLARE, with its training infrastructure, called NDAS.&nbsp;</p>\n\n\n\n<p>NDAS operates independently from the federated learning (FL) system, and because it is used by numerous teams within the NVIDIA AV division, transitioning the entire system to an FL framework is not feasible. We needed a solution to integrate these two systems.</p>\n\n\n\n<p>To address this, we used the NVFLARE third-party integration feature, enabling local training to continue within the MAGLEV framework while transferring model parameters to the NVIDIA FLARE client. We optimized the model transfer process through multiple iterations, using both file-based parameter transfer (FilePipe) and TCP-based parameter transfer (CellPipe) with NVIDIA FLARE.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"625\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-1024x625.png\" alt=\"The system diagram shows MAGLEV training systems located in China and the USA, with the NVIDIA FLARE server hosted on AWS.\" class=\"wp-image-90450\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-1024x625.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-300x183.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-625x381.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-179x109.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-768x469.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-645x393.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-492x300.png 492w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-148x90.png 148w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-362x221.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture-180x110.png 180w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-system-architecture.png 1077w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. System architecture of a AV federated learning platform</em></figcaption></figure></div>\n\n\n<h3 id=\"av_federated_learning_orchestration_service\"  class=\"wp-block-heading\"><strong>AV federated learning orchestration service</strong><a href=\"#av_federated_learning_orchestration_service\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>We developed a suite of front-end and back-end services aimed at streamlining the creation and monitoring of federated learning jobs. This system simplifies the user experience, enabling efficient initiation of jobs and seamless tracking of their progress.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"1391\" height=\"701\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1.jpg\" alt=\"Diagram shows a system composed of a web UI, back-end, and a job auto-recovery/resume mechanism.\" class=\"wp-image-90790\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1.jpg 1391w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-300x151.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-625x315.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-179x90.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-768x387.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-645x325.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-500x252.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-160x81.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-362x182.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-218x110.jpg 218w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/federated-learning-for-ndas-1-1024x516.jpg 1024w\" sizes=\"(max-width: 1391px) 100vw, 1391px\" /><figcaption class=\"wp-element-caption\"><em>Figure 3. AV federated learning job auto-recovery, resume, and orchestration</em></figcaption></figure></div>\n\n\n<p>The system has been in stable production for over a year, with monitoring tools in place to track the performance. Figure 4 shows the monthly training model statistics across two instances, showcasing the consistency and scale of model training efforts.<mark style=\"background-color:#fcb900\" class=\"has-inline-color\"></mark></p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"299\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-1024x299.png\" alt=\"A table shows the number of models trained each month, broken down by architecture and instance.\n\" class=\"wp-image-90452\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-1024x299.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-300x87.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-625x182.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-179x52.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-768x224.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-1536x448.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-645x188.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-500x146.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-160x47.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-362x106.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics-377x110.png 377w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/monthly-training-job-statistics.png 1999w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 4. Monthly training model statistics across two instances</em></figcaption></figure>\n\n\n\n<p><strong>ALT</strong>: A screenshot displays the monthly training model statistics for two training instances.</p>\n\n\n\n<p>Video 1 shows the job training process.\u00a0It shows the AV-FL system web dashboard and how you can launch a training workflow with a few clicks.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/Q0ZpeJkuduM?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. Federated Learning in Autonomous Vehicles: Cross-Border Training</em></figcaption></figure>\n\n\n\n<h3 id=\"federated_learning_workflows\"  class=\"wp-block-heading\">Federated learning workflows<a href=\"#federated_learning_workflows\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>As we are working with AV sensor data for cross-border training, our workflow patterns differ significantly from those used in healthcare or mobile device federated learning:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Healthcare and edge devices</strong>: Numerous clients, each with a limited amount of data.</li>\n\n\n\n<li><strong>AV cross-border training</strong>: Fewer clients, each with a massive volume of data.</li>\n</ul>\n\n\n\n<p>Given these differences, we can use various workflow patterns for model training. Based on our past experience, we chose the round-robin workflow, also known as <em>cyclic weight transfer</em>, as the initial approach. To prevent gradient conflicts, the server collects gradient updates from only one client at a time.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"529\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-1024x529.png\" alt=\"Diagram shows that training is transferred from site to site, with one site active while the other is in a queuing status.\" class=\"wp-image-90453\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-1024x529.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-300x155.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-625x323.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-179x93.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-768x397.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-645x333.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-500x258.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-160x83.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-362x187.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training-213x110.png 213w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/round-robin-training.png 1368w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 5. Round-robin training from different sites</em></figcaption></figure></div>\n\n\n<h2 id=\"challenges_in_cross-border_training&nbsp;\"  class=\"wp-block-heading\">Challenges in cross-border training&nbsp;<a href=\"#challenges_in_cross-border_training&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The development and deployment of global AI models face significant challenges, which can hinder efficient cross-border training:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>IT setup</li>\n\n\n\n<li>Network bandwidth</li>\n\n\n\n<li>Network outages</li>\n</ul>\n\n\n\n<h3 id=\"it_setup\"  class=\"wp-block-heading\">IT setup<a href=\"#it_setup\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>As the training data resides in an externally managed private cloud data center, each configuration change requires multiple approvals, complicating the process of opening ports or making necessary adjustments for NVFLARE.&nbsp;</p>\n\n\n\n<p>To address this issue, we opted to host the FL server on the AWS public cloud. The FL client in the private cloud must communicate through a network path that connects to a community cloud before reaching the public AWS cloud. We used HTTPS port 443 along with a reverse proxy to manage the required ports.</p>\n\n\n\n<h3 id=\"network_bandwidth\"  class=\"wp-block-heading\">Network bandwidth<a href=\"#network_bandwidth\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Training can be slow due to multiple concurrent jobs and the large size of the models being transferred. In addition to expanding bandwidth, we are exploring opportunities to reduce bandwidth usage.&nbsp;</p>\n\n\n\n<p>We identified an issue with model size inflation; for instance, a PyTorch model originally sized at 200 MB became significantly larger after server transfer. This was caused by the model being converted to NumPy and then back to a PyTorch model, resulting in the loss of PyTorch&#8217;s weight compression. To resolve this, we modified the algorithm to eliminate unnecessary conversions.</p>\n\n\n\n<h3 id=\"network_outages\"  class=\"wp-block-heading\">Network outages<a href=\"#network_outages\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Given the large data volumes, training sessions can last for days or weeks. We periodically encountered issues where certain client training jobs would terminate without any apparent reason, causing the server to wait indefinitely for their return. These sporadic occurrences made diagnosis challenging.&nbsp;</p>\n\n\n\n<p>After analyzing logs with the NVFLARE team, we discovered that these failures were due to prolonged network outages lasting 5 to 10 minutes. The NVFLARE team implemented a mechanism to recover from temporary network outages and resume training. After this fix was applied, we experienced no unexplained job failures.</p>\n\n\n\n<h2 id=\"project_status\"  class=\"wp-block-heading\">Project status<a href=\"#project_status\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>We successfully implemented the AV federated learning platform with the deployment of version 2.0, which has been in production for over a year. So far, we have trained and released a dozen AV models, most of which demonstrate equivalent or superior metrics compared to those trained locally.</p>\n\n\n\n<p>The number of data scientists using this platform has increased significantly, growing from just 2 individuals a year ago to approximately 30 today.&nbsp;</p>\n\n\n\n<p>As an example of how well models are performing, while the local model in the US can only predict the overall sign, the federated learning model is capable of identifying both the overall sign as well as the individual labels: 80 and 12 (Figure 6).</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"444\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-1024x444.png\" alt=\"A screenshot compares the road sign detection capabilities of the US local model and the FL global model in predicting speed signs.\" class=\"wp-image-90454\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-1024x444.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-300x130.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-625x271.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-179x78.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-768x333.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-1536x665.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-645x279.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-500x217.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-160x69.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-362x157.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison-254x110.png 254w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/road-sign-model-comparison.png 1999w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 6. Comparison of road sign models</em></figcaption></figure></div>\n\n\n<p>Here are some of the models trained using this platform:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>DoNET</strong>: A model that detects the status of vehicles, such as lamp status (whether the light is on or off) and door status (whether the door is open or closed).</li>\n\n\n\n<li><strong>WaitNet</strong>: A model designed to detect static objects, including traffic lights, traffic signs, road markings, stop lines, and crosswalks.</li>\n\n\n\n<li><strong>PathNet/RoadNet</strong>: A model that identifies the path the AV takes.</li>\n\n\n\n<li><strong>RadarNet</strong>: A model that uses radar sensor data to predict obstacles around the vehicle.</li>\n\n\n\n<li><strong>PredictionNet</strong>: A model for object tracking and trajectory prediction.</li>\n\n\n\n<li><strong>EGM</strong>: A multi-camera input model for detecting barriers in parking lots, such as height limit poles and pillars.</li>\n</ul>\n\n\n\n<h2 id=\"summary\"  class=\"wp-block-heading\"><strong>Summary</strong><a href=\"#summary\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Federated learning is a decentralized AI technology that enables model training without the need to move data. This approach not only ensures regulatory compliance but also helps minimize costs. </p>\n\n\n\n<p>In this post, we discussed an AV-NVIDIA FLARE system that is designed for autonomous vehicles, highlighting its framework and solutions. These strategies can also be effectively applied to other industries.</p>\n\n\n\n<p>For more information about federated learning, see the talks from <a href=\"https://nvidia.github.io/NVFlare/flareDay/\">NVIDIA FLARE Day</a>, with speakers from multiple industries, including healthcare and finance.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Federated learning is revolutionizing the development of autonomous vehicles (AVs), particularly in cross-country scenarios where diverse data sources and conditions are crucial. Unlike traditional machine learning methods that require centralized data storage, federated learning enables AVs to collaboratively train algorithms using locally collected data while keeping the data decentralized. This approach enhances privacy and security, &hellip; <a href=\"https://developer.nvidia.com/blog/federated-learning-in-autonomous-vehicles-using-cross-border-training/\">Continued</a></p>\n", "protected": false}, "author": 2379, "featured_media": 90466, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1508321", "discourse_permalink": "https://forums.developer.nvidia.com/t/federated-learning-in-autonomous-vehicles-using-cross-border-training/311030", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724], "tags": [2892, 453, 2916], "coauthors": [4116, 4117, 4118, 4119], "class_list": ["post-90443", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-computer-vision", "tag-autonomous-vehicles", "tag-featured", "tag-federated-learning"], "acf": {"post_industry": ["Automotive / Transportation"], "post_products": ["NVFLARE"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Deep dive"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvflare-featured.jpeg", "jetpack_shortlink": "https://wp.me/pcCQAL-nwL", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Data Science", "link": "https://developer.nvidia.com/blog/category/data-science/", "id": 696}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90443"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2379"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90443"}], "version-history": [{"count": 6, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90443/revisions"}], "predecessor-version": [{"id": 90826, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90443/revisions/90826"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90466"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90443"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90443"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90443"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90443"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90387, "date": "2024-10-24T09:00:00", "date_gmt": "2024-10-24T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90387"}, "modified": "2024-10-31T09:21:17", "modified_gmt": "2024-10-31T16:21:17", "slug": "building-ai-agents-to-automate-software-test-case-creation", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/building-ai-agents-to-automate-software-test-case-creation/", "title": {"rendered": "Building AI Agents to Automate Software Test Case Creation"}, "content": {"rendered": "\n<p>In software development, testing is crucial for ensuring the quality and reliability of the final product. However, creating test plans and specifications can be time-consuming and labor-intensive, especially when managing multiple requirements and diverse test types in complex systems. Many of these tasks are traditionally performed manually by test engineers.</p>\n\n\n\n<div class='stb-container stb-style-info stb-no-caption'><div class='stb-caption'><div class='stb-logo'><img class='stb-logo__image' src='data:image/png;base64,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' alt='img'/></div><div class='stb-caption-content'></div><div class='stb-tool'></div></div><div class='stb-content'>This post is part of the <a style=\"color: #0000ff;\" href=\"https://developer.nvidia.com/blog/tag/chat-labs/\">NVIDIA Chat Labs series</a>, which shares insights and best practices developed from the internal generative AI projects that we create to help others navigate AI adoption.</div></div>\n\n\n\n<p>To streamline this process, the <a href=\"https://developer.nvidia.com/drive/os\">DriveOS</a> team at NVIDIA developed Hephaestus (HEPH), an internal <a href=\"https://www.nvidia.com/en-us/glossary/generative-ai/\">generative AI</a> framework for automatic test generation. HEPH automates design and implementation for various tests, including integration and unit tests. It uses <a href=\"https://www.nvidia.com/en-us/glossary/large-language-models/\">large language models</a> (LLMs) for input analysis and code generation, significantly reducing the time spent on creating test cases. By generating context-aware tests based on input documentation, code samples, and feedback loops, HEPH makes testing faster and more efficient.</p>\n\n\n\n<p>This post provides an overview of how an agent framework was built to generate various types of software tests. It covers how an LLM agent is used to ensure document traceability and create executable tests based on software requirements. You also get ideas for improving the agent\u2019s test-generation capabilities.</p>\n\n\n\n<h2 id=\"an_agentic_framework_for_automatic_test_case_creation\"  class=\"wp-block-heading\">An agentic framework for automatic test case creation<a href=\"#an_agentic_framework_for_automatic_test_case_creation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Development, security, and QA teams often face the labor-intensive task of manual test case creation during the software development process.&nbsp;</p>\n\n\n\n<p>The test creation process involves time-intensive steps, including retrieving requirement information, tracing those requirements to relevant documentation, and ultimately generating tests based on the aligned requirements and documentation.</p>\n\n\n\n<p>To simplify this workflow, the DriveOS team designed HEPH, a custom, internal framework for automating the entire testing process, significantly reducing the time spent on creating test specifications and implementations. HEPH uses LLMs to analyze input documentation and code samples, generating tests that are tailored to the provided requirements.</p>\n\n\n\n<h2 id=\"value_of_test_automation\"  class=\"wp-block-heading\">Value of test automation<a href=\"#value_of_test_automation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>HEPH uses an LLM agent for every step in the test generation process\u2014from document traceability to code generation. This enables the automation of the entire testing workflow and saves engineering teams many hours.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Time savings: </strong>HEPH dramatically accelerates the test creation process. In trials with multiple pilot teams at NVIDIA, teams reported saving up to 10 weeks of development time.</li>\n\n\n\n<li><strong>Context-aware test generation:</strong> HEPH uses project documentation and interface specifications to generate test specifications and implementations. Each test is compiled, executed, and verified for correctness. Test coverage data is fed back into the model to further refine test generation.</li>\n\n\n\n<li><strong>Multi-format support and modularity:</strong> HEPH supports various input formats, including PDF, RST, RSTI, and HTML, and integrates with internal tools like Confluence and JIRA. </li>\n</ul>\n\n\n\n<h2 id=\"how_does_heph_work\"  class=\"wp-block-heading\">How does HEPH work?<a href=\"#how_does_heph_work\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>HEPH takes in software requirements, software architecture documents (SWADs), interface control documents (ICDs), and test examples as input. The output is a set of test specifications and implementations for the given requirements (Figure 1).</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"361\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-1024x361.png\" alt=\"The diagram shows various inputs for analysis that undergo a feedback loop, resulting in relevant outputs for test generation.\" class=\"wp-image-90407\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-1024x361.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-300x106.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-625x221.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-179x63.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-768x271.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-1536x542.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-645x228.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-500x176.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-160x56.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-362x128.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture-312x110.png 312w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/heph-architecture.png 1921w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. HEPH technical architecture</em></figcaption></figure></div>\n\n\n<p>The test generation process includes the following main steps:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li><strong>Data preparation: </strong>Input documents like SWADs and ICDs are indexed and stored in an embedding database, which is later used to query relevant information.</li>\n\n\n\n<li><strong>Requirements extraction:</strong> Requirement details are retrieved from the requirement storage system (for example, <a href=\"https://www.jamasoftware.com/\">Jama</a>). If the input requirements lack the necessary details for test generation, HEPH automatically connects to the storage service, locates the requirement, and downloads the missing information.</li>\n\n\n\n<li><strong>Data traceability:</strong> HEPH searches the embedding database to trace information related to the input requirements. The output is a mapped connection between the requirement and the relevant SWAD and ICD fragments.</li>\n\n\n\n<li><strong>Test specification generation:</strong> Based on the verification steps from requirements and the identified SWAD and ICD fragments (traceability), HEPH generates both positive and negative test specifications to cover all aspects of the requirement.</li>\n\n\n\n<li><strong>Test implementation generation</strong>: HEPH uses the ICD fragments (traceability) and the generated test specifications to create the tests in C/C++. The ICD provides context such as function names, data types, enumerations, and return codes, which the LLM uses during code generation. This step results in executable tests.</li>\n\n\n\n<li><strong>Test execution:</strong> The generated tests are compiled and executed and coverage data is collected. The HEPH agent analyzes test coverage results and repeats the generation of test specifications and implementation for the missing cases.</li>\n</ul>\n\n\n\n<h2 id=\"a_real-world_scenario&nbsp;\"  class=\"wp-block-heading\">A real-world scenario&nbsp;<a href=\"#a_real-world_scenario&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Here\u2019s a real-world example to understand how HEPH works.&nbsp;</p>\n\n\n\n<p><a href=\"https://developer.nvidia.com/drive/os\">NVIDIA DriveOS </a>uses the QNX operating system. To demonstrate the capabilities of HEPH, I use one of the <a href=\"https://blackberry.qnx.com/en/developers/board-support-packages\">QNX BSP</a> drivers as an example and a requirement for the thermal functionality in QNX BSP. Given the input requirements and driver documentation, HEPH extracts requirement information from Jama, traces it to the corresponding documentation fragments, and generates test specifications and implementations.</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Requirement extraction</li>\n\n\n\n<li>SWAD data traceability</li>\n\n\n\n<li>ICD data traceability</li>\n\n\n\n<li>Test specification generation</li>\n\n\n\n<li>Test implementation generation</li>\n</ul>\n\n\n\n<h3 id=\"requirement_extraction\"  class=\"wp-block-heading\">Requirement extraction<a href=\"#requirement_extraction\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>HEPH extracts details from requirements storage (Jama) using a requirement identifier. The resulting requirement is formatted as JSON:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: jscript; title: ; notranslate\" title=\"\">\n{\n\u00a0 &quot;requirement_id&quot;: &quot;DOSBSP60-REQ-3874&quot;,\n\u00a0 &quot;name&quot;: &quot;Get Temperature for Thermal Zones in the SOC_THERM Domain&quot;,\n\u00a0 \u00a0 &quot;description&quot;: &quot;When a request to retrieve the temperature of a thermal zone in the SOC_THERM domain is made via TMON_GUEST_LIF#GetTempSocTherm, QNX_BSP shall retrieve and return two consecutive temperature values for the thermal zone via TEGRA_CTRL_LIF#GetTemp, preserving the temperature resolution, along with two corresponding timestamps via DRIVE_OS::QNX_System::OS_LIBC_LIF#ReadClockCycles.&quot;\n}\n</pre></div>\n\n\n<h3 id=\"swad_data_traceability\"  class=\"wp-block-heading\">SWAD data traceability<a href=\"#swad_data_traceability\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>HEPH searches through all architecture documentation (SWAD) to locate information relevant to the requirement. The output is a collection of architectural details, including unit requirements, methods, error handling, and verification criteria.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n### Extracted Information for Requirement: DOSBSP60-REQ-3874\n\n#### Unit Requirements and Functional Blocks\n- **UREQ_NvThermmon_Library_0601**:\n\u00a0 \u00a0 \u00a0 If the thermal zone bound to **Handle** is in the SOC_THERM domain, Thermal_API#GetTempSocTherm shall retrieve the bound zone ID, pass it to BPMP_Comm_API#GetZoneTemp to get the zone temperature, populate **TempVal1** with the zone temperature, use libc_api#QnxLibcReadClockCycles to populate **Timestamp1**, call BPMP_Comm_API#GetZoneTemp to get the zone temperature again, populate **TempVal2** with the zone temperature, use libc_api#QnxLibcReadClockCycles to populate **Timestamp2**, and return success as per Thermal_API ICD.\n\u00a0 \u00a0\n- **UREQ_NvThermmon_Library_0602**:\n\u00a0 \u00a0 \u00a0 If BPMP_Comm_API#GetZoneTemp fails, Thermal_API#GetTempSocTherm shall return error as per Thermal_API ICD and perform no other action.\n\n#### Methods and Functions\n- **Functional Block FUNC_NvThermmon_01**:\n\u00a0 FUNC_NvThermmon_01\n\u00a0 \u00a0 \u00a0 Thermal_API provides the Thermal_API#GetTempSmTmon and Thermal_API#GetTempSocTherm interface to query the temperature of the thermal zone bound to **Handle** and return the result in **zone_temp**.\n\n#### Error Handling\n- **UREQ_NvThermmon_Resmgr_1201**:\n\u00a0 \u00a0 \u00a0 If NvThermmon_Resmgr encounters a SW diagnostic error, the NvThermmon_Resmgr returns error as per Thermal_devctl_API ICD for all current and future Thermal_devctl_API requests and performs no other action.\n\n- **UREQ_NvThermmon_Resmgr_1202**:\n\u00a0 \u00a0 \u00a0 If libc_api#QnxLibcIoctl is called on ``/dev/&lt;ZoneName&gt;`` and the command is not Thermal_devctl_API#GetTemp or Thermal_devctl_API#SetAlert, NvThermmon_Resmgr shall return error as per Thermal_devctl_API ICD.\n\n#### Verification Criteria (Verification Environment: AV+Q Safety prod-debug)\nVerification Environment: AV+Q Safety prod-debug\nPre-Condition: N/A\nConstraints: N/A\nVerification Steps:\n- Run interface tests on API\n- Pass invalid thermal zones and verify the API fails\n- Pass valid thermal zones from a process with required privileges and permissions and verify that the temperature can be read.\n- Inject error such that I2C_API#SendReceive returns error and verify that Thermal_API#GetTempSmTmon fails as expected.\n- Inject error such that BPMP_Comm_API#GetZoneTemp returns error and verify that Thermal_API#GetTempSocTherm fails as expected.\n</pre></div>\n\n\n<h3 id=\"icd_data_traceability\"  class=\"wp-block-heading\">ICD data traceability<a href=\"#icd_data_traceability\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>After searching SWADs, HEPH looks for information in the ICDs. The result includes details on methods, functions, data structures, error codes, and function dependencies.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n### Extracted Information from ICDs\n\n#### Methods and Functions:\n\n1. **NvThermmonOpen**\n\u00a0 \u00a0 **Description**: Opens a connection to the nvthermmon driver for the thermal sensor/zone user is interested in.\n\n\u00a0 \u00a0 **Parameters**:\n\u00a0 \u00a0 - `const char *const ZoneName`: Thermal sensor/zone name\n\u00a0 \u00a0 - `NvThermmonHandle *const Handle`: User handle for further API calls\n\n\u00a0 \u00a0 **Returns**:\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_NO_ERROR`: Success\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_INVALID_PARAM`: Invalid parameters\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_DT_FAILED`: Device tree failure\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_INVALID_PERM`: Permission error\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_INVALID_STATE`: Invalid system state\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_ERROR`: BPMP Comm error\n\n\u00a0 \u00a0 **Precondition**: None\n\n\u00a0 \u00a0 **Usage Considerations**:\n\u00a0 \u00a0 - Allowed context for the API call\n\u00a0 \u00a0 - Sync, not re-entrant\n2. **NvThermmonGetZoneTemp**\n\u00a0 \u00a0 **Description**: Read temperature from selected thermal zone. Populates memory pointed to by `temp` with temperature of thermal zone in millidegrees Celsius and returns status.\n\n\u00a0 \u00a0 **Parameters**:\n\u00a0 \u00a0 - `const NvThermmonHandle Handle`: Handle for execution context bound in `NvThermmonOpen`\n\u00a0 \u00a0 - `int32_t * const TempVal`: Pointer to save temperature value in millidegrees Celsius.\n\n\u00a0 \u00a0 **Returns**:\n\u00a0 \u00a0 - `NvThermmonErrCode`: Error Code (e.g., `NV_THERMMON_ERR_CODE_NO_ERROR`, `NV_THERMMON_ERR_CODE_INVALID_PARAM`)\n\n#### Data Structures and Fields:\n\n1. **zone_temp_t Structure**\n\u00a0 \u00a0 **Fields**:\n\u00a0 \u00a0 - `int32_t temp_1`: First temperature reading\n\u00a0 \u00a0 - `int32_t temp_2`: Second temperature reading\n\u00a0 \u00a0 - `uint64_t ts_1`: Timestamp for first temp reading\n\u00a0 \u00a0 - `uint64_t ts_2`: Timestamp for second temp reading\n\n#### Enumerations:\n1. **NvThermmonErrCode**\n\n\u00a0 \u00a0 **Error Codes**:\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_NO_ERROR`\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_INVALID_PARAM`\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_DT_FAILED`\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_INVALID_PERM`\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_INVALID_STATE`\n\u00a0 \u00a0 - `NV_THERMMON_ERR_CODE_ERROR`\n\n### Integration of Information for Testing:\n\n1. **NvThermmonOpen()**:\n\u00a0 \u00a0 **Precondition**: Ensure that `NvThermmonOpen` returns success for the thermal zone.\n\u00a0 \u00a0 **Dependencies**:\n\u00a0 \u00a0 - Handle for execution context\n\n2. **NvThermmonGetZoneTemp()**:\n\u00a0 \u00a0 **Dependencies**:\n\u00a0 \u00a0 - `zone_temp_t` structure to store temperature readings and timestamps.\n\u00a0 \u00a0 - Error codes to handle different edge cases and validation steps.\n</pre></div>\n\n\n<h3 id=\"test_specification_generation\"  class=\"wp-block-heading\">Test specification generation<a href=\"#test_specification_generation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Based on the verification steps from requirements and the traced SWAD and ICD fragments, HEPH generates test specifications. The following code blocks are examples of generated test cases.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n######\nTest Case ID: TC_DOSBSP60-REQ-3874_001\nTest Case Name: Verify successful temperature query for a supported thermal zone\nTest Type: Positive\nTest Design: Ensure the temperature for a thermal zone in the SOC_THERM domain can be queried successfully.\nPre-condition: Thermal zone is supported and NvThermmonOpen() returns success for the thermal zone.\nTest Procedure:\n1. Open a connection to the thermal zone using NvThermmonOpen().\n2. Query the temperature for the thermal zone using NvThermmonGetZoneTemp().\n3. Retrieve two consecutive temperature values.\nExpected Result: The API should return success with two temperature values that differ by no more than the delta determined by the thermal characteristics of the board.\n\n######\nTest Case ID: TC_DOSBSP60-REQ-3874_002\nTest Case Name: Verify accompanying timestamp for temperature queries\nTest Type: Positive\nTest Design: Ensure that two timestamp values are returned with temperature queries.\nPre-condition: Thermal zone is supported and NvThermmonOpen() returns success for the thermal zone.\nTest Procedure:\n1. Open a connection to the thermal zone using NvThermmonOpen().\n2. Query the temperature for the thermal zone using NvThermmonGetZoneTemp().\n3. Retrieve two consecutive temperature values along with two corresponding timestamps.\nExpected Result: The API should return success with two timestamp values that do not exceed T microseconds between them.\n\n######\nTest Case ID: TC_DOSBSP60-REQ-3874_003\nTest Case Name: Verify temperature variation over successive calls\nTest Type: Positive\nTest Design: Ensure that the temperature for the thermal zone varies over successive queries.\nPre-condition: Thermal zone is supported and NvThermmonOpen() returns success for the thermal zone.\nTest Procedure:\n1. Open a connection to the thermal zone using NvThermmonOpen().\n2. Query the temperature for the thermal zone using NvThermmonGetZoneTemp() multiple times.\n3. Compare temperature values over successive calls.\nExpected Result: The temperature values should show a difference of &gt;0 and should vary with the resolution supported by the temperature sensor.\n</pre></div>\n\n\n<h3 id=\"test_implementation_generation\"  class=\"wp-block-heading\">Test implementation generation<a href=\"#test_implementation_generation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Based on the test specifications and ICD details, HEPH generates the tests in C.&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n#include &lt;stdio.h&gt;\n#include &lt;stdint.h&gt;\n#include &quot;NvThermmonAPI.h&quot;\n\n// Test Case TC_DOSBSP60-REQ-3874_001\n// Verify successful temperature query for a supported thermal zone\nvoid TC_DOSBSP60_REQ_3874_001(void) {\n\u00a0 \u00a0 NvThermmonHandle handle;\n\u00a0 \u00a0 zone_temp_t zoneTemp;\n\n\u00a0 \u00a0 // Step 1: Open a connection to the thermal zone using NvThermmonOpen()\n\u00a0 \u00a0 NvThermmonErrCode status = NvThermmonOpen(&quot;CPU-therm&quot;, &amp;handle);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_001: NvThermmonOpen failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 // Step 2: Query the temperature for the thermal zone using NvThermmonGetZoneTemp()\n\u00a0 \u00a0 status = NvThermmonGetZoneTemp(handle, &amp;zoneTemp);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_001: NvThermmonGetZoneTemp failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 // Step 3: Retrieve two consecutive temperature values\n\u00a0 \u00a0 int32_t delta = zoneTemp.temp_2 - zoneTemp.temp_1;\n\u00a0 \u00a0 if (delta &gt; 100) { // Assume 100 is the delta determined by the thermal characteristics of the board\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_001: Temperature delta is too large\\n&quot;);\n\u00a0 \u00a0 } else {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_001: Passed\\n&quot;);\n\u00a0 \u00a0 }\n}\n\n// Test Case TC_DOSBSP60-REQ-3874_002\n// Verify accompanying timestamp for temperature queries\nvoid TC_DOSBSP60_REQ_3874_002(void) {\n\u00a0 \u00a0 NvThermmonHandle handle;\n\u00a0 \u00a0 zone_temp_t zoneTemp;\n\n\u00a0 \u00a0 // Step 1: Open a connection to the thermal zone using NvThermmonOpen()\n\u00a0 \u00a0 NvThermmonErrCode status = NvThermmonOpen(&quot;CPU-therm&quot;, &amp;handle);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_002: NvThermmonOpen failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 // Step 2: Query the temperature for the thermal zone using NvThermmonGetZoneTemp()\n\u00a0 \u00a0 status = NvThermmonGetZoneTemp(handle, &amp;zoneTemp);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_002: NvThermmonGetZoneTemp failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 // Step 3: Retrieve two consecutive temperature values along with two corresponding timestamps\n\u00a0 \u00a0 uint64_t deltaTs = zoneTemp.ts_2 - zoneTemp.ts_1;\n\u00a0 \u00a0 if (deltaTs &gt; 1000) { // Assume 1000 microseconds is the maximum allowed delta\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_002: Timestamp delta is too large\\n&quot;);\n\u00a0 \u00a0 } else {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_002: Passed\\n&quot;);\n\u00a0 \u00a0 }\n}\n\n// Test Case TC_DOSBSP60-REQ-3874_003\n// Verify temperature variation over successive calls\nvoid TC_DOSBSP60_REQ_3874_003(void) {\n\u00a0 \u00a0 NvThermmonHandle handle;\n\u00a0 \u00a0 zone_temp_t zoneTemp1, zoneTemp2;\n\n\u00a0 \u00a0 // Step 1: Open a connection to the thermal zone using NvThermmonOpen()\n\u00a0 \u00a0 NvThermmonErrCode status = NvThermmonOpen(&quot;CPU-therm&quot;, &amp;handle);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_003: NvThermmonOpen failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 // Step 2: Query the temperature for the thermal zone using NvThermmonGetZoneTemp() multiple times\n\u00a0 \u00a0 status = NvThermmonGetZoneTemp(handle, &amp;zoneTemp1);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_003: NvThermmonGetZoneTemp (1st call) failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 status = NvThermmonGetZoneTemp(handle, &amp;zoneTemp2);\n\u00a0 \u00a0 if (status != NV_THERMMON_ERR_CODE_NO_ERROR) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_003: NvThermmonGetZoneTemp (2nd call) failed\\n&quot;);\n\u00a0 \u00a0 \u00a0 \u00a0 return;\n\u00a0 \u00a0 }\n\n\u00a0 \u00a0 // Step 3: Compare temperature values over successive calls\n\u00a0 \u00a0 int32_t temperatureDifference = zoneTemp2.temp_1 - zoneTemp1.temp_1;\n\u00a0 \u00a0 if (temperatureDifference &lt;= 0) {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_003: Temperature did not vary as expected\\n&quot;);\n\u00a0 \u00a0 } else {\n\u00a0 \u00a0 \u00a0 \u00a0 printf(&quot;TC_DOSBSP60-REQ-3874_003: Passed\\n&quot;);\n\u00a0 \u00a0 }\n}\n</pre></div>\n\n\n<h2 id=\"future_enhancements\"  class=\"wp-block-heading\">Future enhancements<a href=\"#future_enhancements\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>There are a few core things to focus on when designing a test generation framework:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Supporting different test workflows</li>\n\n\n\n<li>Integrating real-time human feedback</li>\n</ul>\n\n\n\n<h3 id=\"supporting_different_test_workflows\"  class=\"wp-block-heading\">Supporting different test workflows<a href=\"#supporting_different_test_workflows\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>HEPH is designed to support most test-generation use cases for software teams. Still, there are instances when teams require a custom test framework or an unsupported test creation workflow.&nbsp;</p>\n\n\n\n<p>To address these challenges, potential future improvements to HEPH could include a modular design, enabling software teams to define custom modules for non-standard workflows. For example, teams might benefit from the ability to generate tests directly from the input code rather than documentation or extend LLM prompts. This modular approach could help tackle the complexities of custom and non-standard test generation scenarios.</p>\n\n\n\n<h3 id=\"integrating_real-time_human_feedback&nbsp;\"  class=\"wp-block-heading\">Integrating real-time human feedback&nbsp;<a href=\"#integrating_real-time_human_feedback&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>While the latest LLMs perform well in understanding the development context and generating high-quality code, there are cases where generated test sets may require improvement.&nbsp;</p>\n\n\n\n<p>Possible future enhancements to HEPH could include the introduction of an interactive mode alongside the current automatic mode. In this interactive mode, you&#8217;d interact with the HEPH agent at each step of the test generation process, reviewing results, providing feedback, and refining outputs before proceeding. For instance, if the generated test specifications lacked details about register mapping, you could add this context, and HEPH would regenerate more accurate test specifications.</p>\n\n\n\n<h2 id=\"start_hephing_your_automatic_test_generation\"  class=\"wp-block-heading\">Start HEPHing your automatic test generation<a href=\"#start_hephing_your_automatic_test_generation\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Hephaestus (HEPH) automates test generation in software development by using LLMs to create comprehensive and context-aware tests. This automation reduces manual effort, accelerates development, and improves the quality and reliability of the final product.&nbsp;</p>\n\n\n\n<p>Upcoming enhancements include modularity, allowing for custom modules to support non-standard testing workflows, and an interactive mode enabling you to provide feedback and refine the test generation process for higher accuracy and relevance.</p>\n\n\n\n<h2 id=\"build_your_ai_agent_application\"  class=\"wp-block-heading\">Build your AI agent application<a href=\"#build_your_ai_agent_application\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>For more information about using NVIDIA <a href=\"https://www.nvidia.com/en-us/glossary/generative-ai/\">generative AI</a> technologies and tools to create your own AI agents and applications, see <a href=\"http://ai.nvidia.com\">ai.nvidia.com</a> or try out <a href=\"https://build.nvidia.com/\">NVIDIA NIM APIs</a>.&nbsp;</p>\n\n\n\n<p>If you\u2019re new to this area, explore our beginner-friendly series, <a href=\"https://developer.nvidia.com/blog/building-your-first-llm-agent-application/\">Building Your First LLM Agent Application</a>.</p>\n\n\n\n<h3 id=\"acknowledgments\"  class=\"wp-block-heading\">Acknowledgments<a href=\"#acknowledgments\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p><em>Thanks to the DriveOS QNX BSP team for piloting HEPH.</em></p>\n", "protected": false}, "excerpt": {"rendered": "<p>In software development, testing is crucial for ensuring the quality and reliability of the final product. However, creating test plans and specifications can be time-consuming and labor-intensive, especially when managing multiple requirements and diverse test types in complex systems. Many of these tasks are traditionally performed manually by test engineers. To streamline this process, the &hellip; <a href=\"https://developer.nvidia.com/blog/building-ai-agents-to-automate-software-test-case-creation/\">Continued</a></p>\n", "protected": false}, "author": 2378, "featured_media": 90362, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1508322", "discourse_permalink": "https://forums.developer.nvidia.com/t/building-ai-agents-to-automate-software-test-case-creation/311031", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 3110], "tags": [4113, 453, 2932], "coauthors": [4112], "class_list": ["post-90387", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-center-cloud", "category-generative-ai", "tag-chat-labs", "tag-featured", "tag-large-language-models"], "acf": {"post_industry": ["Cloud Services", "Hardware / Semiconductor"], "post_products": ["NIM"], "post_learning_levels": ["Intermediate Technical"], "post_content_types": ["Tutorial"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/llm-promo-chat-labs-featured.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nvR", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Generative AI", "link": "https://developer.nvidia.com/blog/category/generative-ai/", "id": 3110}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90387"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2378"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90387"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90387/revisions"}], "predecessor-version": [{"id": 90858, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90387/revisions/90858"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90362"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90387"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90387"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90387"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90387"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 90367, "date": "2024-10-24T09:00:00", "date_gmt": "2024-10-24T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=90367"}, "modified": "2024-10-31T09:21:17", "modified_gmt": "2024-10-31T16:21:17", "slug": "spotlight-accelerating-hpc-in-energy-with-aws-energy-hpc-orchestrator-and-nvidia-energy-samples", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/spotlight-accelerating-hpc-in-energy-with-aws-energy-hpc-orchestrator-and-nvidia-energy-samples/", "title": {"rendered": "Spotlight: Accelerating HPC in Energy with AWS Energy HPC Orchestrator and NVIDIA Energy Samples"}, "content": {"rendered": "\n<p>The energy industry\u2019s digital transformation requires a substantial increase in computational demands for key HPC workloads and applications. This trend is exemplified by advanced seismic imaging methodologies such as reverse time migration (RTM) and full waveform inversion (FWI), where doubling maximum frequency can produce a 16x increase in computational workload. Similarly, in reservoir simulation, a reduction in grid discretization by a factor of two across all three dimensions can amplify computational requirements by a factor of eight.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>These developments highlight an urgent need for flexible and scalable computing resources tailored to meet evolving HPC demands in the energy industry. Cloud computing is a viable solution to accommodate increasing computational requirements. However, achieving optimal performance and cost for cloud computing requires significant engineering efforts to modernize existing HPC applications.&nbsp;</p>\n\n\n\n<p>The AWS Energy HPC Orchestrator provides an integrated environment to overcome those challenges. This open industry platform and marketplace ecosystem, developed in collaboration with AWS and leading energy companies, and the NVIDIA Energy Samples available directly from NVIDIA focuses on enabling interoperability between processing modules to deliver optimized scalability, flexibility, and economics. It also provides a series of pre-optimized, cloud-native HPC templates to ease modernization engineering efforts and create an open HPC marketplace where every participant can focus on their differentiating technology.\u00a0</p>\n\n\n\n<p>In this post, we detail how to integrate the NVIDIA Energy Samples, used to build derivative solutions on top of the AWS Energy HPC Orchestrator. This platform uses an AWS Cloud-optimized template to quickly build a cloud-native seismic application,\u202fand scale it with hundreds of NVIDIA-powered instances.\u00a0</p>\n\n\n\n<h2 id=\"designing_the_aws_energy_hpc_orchestrator&nbsp;\"  class=\"wp-block-heading\">Designing the AWS Energy HPC Orchestrator&nbsp;<a href=\"#designing_the_aws_energy_hpc_orchestrator&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The AWS Energy HPC Orchestrator reference architecture contains the following essential components:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>A system that enables the following:&nbsp;\n<ul class=\"wp-block-list\">\n<li>Orchestration of HPC applications of different kinds that use a common storage system.</li>\n\n\n\n<li>Enterprise functionalities, such as user, project, and data management.</li>\n</ul>\n</li>\n\n\n\n<li>An ecosystem of HPC applications that are compatible with the AWS Energy HPC Orchestrator and distributed through a marketplace.</li>\n\n\n\n<li>A set of data standards to allow the interoperability (data exchange) between HPC applications.&nbsp;</li>\n</ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"470\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-1024x470.jpg\" alt=\"Workflow diagram shows blocks representing RTM applications linked by process arrows.\" class=\"wp-image-90369\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-1024x470.jpg 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-300x138.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-625x287.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-179x82.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-768x352.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-1536x705.jpg 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-645x296.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-500x229.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-160x73.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-362x166.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator-240x110.jpg 240w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/aws-energy-hpc-orchestrator.jpg 1600w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Coordinating multiple HPC applications in the AWS Energy HPC Orchestrator</em></figcaption></figure></div>\n\n\n<h3 id=\"extensions&nbsp;\"  class=\"wp-block-heading\">Extensions&nbsp;<a href=\"#extensions&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Extensions are plug-ins to the system that provide domain-specific capabilities. For example, you can have different extensions providing implementations of algorithms, such as RTM or FWI. Extensions are required to implement the event-based protocols defined by the core.&nbsp;</p>\n\n\n\n<h3 id=\"rtm_template&nbsp;\"  class=\"wp-block-heading\">RTM template&nbsp;<a href=\"#rtm_template&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Templates are reusable for a class of algorithms and encapsulate best practices for running these algorithms on AWS.</p>\n\n\n\n<p>The RTM template is designed to transform a traditional RTM application for seismic processing into a modernized, cloud-native application. This design capitalizes on robust AWS services to boost scalability, resilience, and operational efficiency of high-end seismic imaging algorithms.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full-page-width\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"467\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-1024x467.jpg\" alt=\"Workflow diagram template for RTM applications deployed on AWS including permanent and job infrastructure.\" class=\"wp-image-90370\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-1024x467.jpg 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-300x137.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-625x285.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-179x82.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-768x350.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-645x294.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-500x228.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-160x73.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-362x165.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging-241x110.jpg 241w, https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/cloud-native-rtm-template-seismic-imaging.jpg 1216w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. A cloud-native RTM template from AWS used in seismic imaging</em></figcaption></figure></div>\n\n\n<p>The execution of the RTM algorithm unfolds within the dynamic backend, segmented into four distinct, decoupled microservices, each one specialized for a task of the RTM algorithm:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Analysis</li>\n\n\n\n<li>Migration</li>\n\n\n\n<li>Reduction</li>\n\n\n\n<li>Converter</li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\">Analysis Service</h4>\n\n\n\n<p>This microservice starts the workflow by procuring a work item, usually a pointer to a seismic file&#8217;s location (object store URI), from the input data queue. It then scans the file&#8217;s header or its metadata to ascertain the number of shots it contains.&nbsp;</p>\n\n\n\n<p>Subsequently, for every shot detected, the Analysis Service formulates individual work item details and dispatches this metadata into the migration queue, fragmenting the task into smaller, independent processing units.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">Migration Service</h4>\n\n\n\n<p>The Migration Service pulls work item details from the migration queue. It loads models and reads data from the input seismic data file. Then, it solves the forward wave equation and the adjoint wave equation, yields a 3D image, and uploads to the object store. Afterward, a corresponding reduction work item is pushed into the reduction queue for subsequent stacking.&nbsp;\u202f&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">Reduction Service</h4>\n\n\n\n<p>This service activates by retrieving two work items from the reduction queue. It retrieves two corresponding images from the object store and stacks them into a single image. This stacked image is re-uploaded to the object store, and a work item is re-enqueued to the reduction queue.&nbsp;</p>\n\n\n\n<p>This cycle persists until the reduction queue is left with a singular, composite work item, denoting the completion of the RTM process for the entire dataset.&nbsp;</p>\n\n\n\n<h4 class=\"wp-block-heading\">Converter Service</h4>\n\n\n\n<p>This service converts the final stacked image into the appropriate final format.&nbsp;</p>\n\n\n\n<h3 id=\"queuing_and_scaling\"  class=\"wp-block-heading\">Queuing and scaling<a href=\"#queuing_and_scaling\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The indirect interaction between microservices through a queuing system not only enforces the system&#8217;s resilience and fault tolerance but also enables autonomous scaling of each service. Through an auto-scaling group, services dynamically adjust in scale, driven by the number of work items or seismic shots queued, ensuring optimal resource allocation.&nbsp;\u202f&nbsp;</p>\n\n\n\n<p>By using cloud-native services, such as serverless compute for real-time monitoring and event-driven operations, the architecture eschews traditional HPC orchestration methods such as MPI or Slurm, instead offering a more agile and robust method for implementing RTM in the cloud.&nbsp;\u202f&nbsp;</p>\n\n\n\n<p>The workflow of each service is asynchronous, preventing any single point of failure or single operation from causing a bottleneck. The queue-based communication decouples services for enhanced fault tolerance and promotes a highly asynchronous shot processing system. The asynchronicity ensures scalability and further strengthens the fault tolerance of the system.&nbsp;</p>\n\n\n\n<p>Each microservice operates autonomously and scales up or down, according to the queued workload. This design guarantees resilience against individual component failures and provides flexibility to efficiently manage various loads.&nbsp;&nbsp;</p>\n\n\n\n<p>\u202fThe asynchronous and resilient nature of this architecture also offers a significant edge in both performance and cost optimization using AWS Spot Instances.&nbsp;</p>\n\n\n\n<p>Different instance types can be allocated to various services, striking an optimal balance between cost and performance. For example, Analysis Service can use general-purpose instances. Migration Service can use HPC instances, while Reduction Service may opt for network-optimized instances to suit its workload.&nbsp;</p>\n\n\n\n<h2 id=\"integrating_nvidia_energy_samples\"  class=\"wp-block-heading\">Integrating NVIDIA Energy Samples<a href=\"#integrating_nvidia_energy_samples\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>RTM is an advanced seismic imaging technique widely used in the field of geophysics, particularly in oil and gas exploration. RTM plays a crucial role in creating accurate subsurface images. The technique involves solving the seismic waves propagating through a computational model of the Earth&#8217;s subsurface, allowing geophysicists to generate high-resolution images of geological structures.&nbsp;</p>\n\n\n\n<p>Unlike traditional migration methods, RTM can handle complex velocity models and sharp contrasts in the subsurface, making it invaluable for imaging beneath areas with complex geology, such as salt bodies or steeply dipping layers.&nbsp;</p>\n\n\n\n<p>NVIDIA Energy Samples is a collection of reference implementations of key algorithms in seismic processing such as RTM, Kirchoff, and FWI, all of which have been written in CUDA and tuned for maximum gain on NVIDIA GPUs. The algorithms are ready to run on cloud platforms, but cannot be considered production-grade implementations. The samples, available directly from NVIDIA, make it easy for geophysicists to produce full-featured and highly performant implementations by including their own customizations unique to each geophysics group.</p>\n\n\n\n<p>RTM is a computationally intensive process that benefits significantly from accelerated computing powered by NVIDIA. NVIDIA Energy Samples is a set of sample codes that demonstrate how to harness the full power of NVIDIA GPUs for key seismic processing algorithms. Even though they do not provide a full production solution, the samples enable geophysicists to turn their unique RTM algorithms into high-performing GPU code.&nbsp;&nbsp;</p>\n\n\n\n<p>AWS provides a cloud-native, optimized RTM template as Python code. It is decoupled into four microservices: Analysis, Migration, Reduction, and SegyConverter.&nbsp;\u202f\u202f&nbsp;</p>\n\n\n\n<p>With the help of the AWS RTM template, you use the standard Analysis Service, Reduction Service, and SegyConverter Service without any code modification. These services are written to work with Amazon S3 natively and pre-optimized to achieve optimal performance.&nbsp;</p>\n\n\n\n<p>There are a few modifications to the Migration Service to enable NVIDIA Energy Samples to integrate with AWS Energy HPC Orchestrator (EHO):</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Parameter conversion</li>\n\n\n\n<li>Model handling</li>\n\n\n\n<li>Data handling</li>\n</ul>\n\n\n\n<h3 id=\"parameter_conversion\"  class=\"wp-block-heading\">Parameter conversion<a href=\"#parameter_conversion\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>EHO has a web interface to pass parameters to the HPC application in a JSON format. However, the RTM sample from NVIDIA Energy Samples is taking the parameter as plain ASCII format. You must write a custom Python function to convert the parameter JSON into ASCII format:&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n#!/usr/bin/python3\nimport json\nfrom sys import *\n\ndef json2par(data, local_shot_file, local_modelfiles, local_img_fname, dt, nt, ntr):\n    strpar=&quot;&quot;\n\n    # hardcode part\n    strpar+=f&quot;storageFileName=/scr\\n&quot;\n    strpar+=f&quot;imagingData= {local_img_fname}\\n&quot;\n    strpar+=f&quot;InputData= {local_shot_file}\\n&quot;\n    strpar+=f&quot;InputHeaders= {local_shot_file}.hdr\\n&quot;\n    strpar+=f&quot;NTraces= {ntr}\\n&quot;\n    strpar+=f&quot;Nsamples= {nt}\\n&quot;\n    strpar+=f&quot;SRate= {dt}\\n&quot;\n    strpar+=f&quot;FirstShotSelect= 0\\n&quot;\n    strpar+=f&quot;LastShotSelect= 0\\n&quot;\n    strpar+=f&quot;velocityData= {local_modelfiles&#x5B;&#039;vp&#039;]}\\n&quot;\n    strpar+=f&quot;epsilonData= {local_modelfiles&#x5B;&#039;epsilon&#039;]}\\n&quot;\n    strpar+=f&quot;deltaData= {local_modelfiles&#x5B;&#039;delta&#039;]}\\n&quot;\n    strpar+=f&quot;thetaData= {local_modelfiles&#x5B;&#039;dip&#039;]}\\n&quot;\n    strpar+=f&quot;phiData= {local_modelfiles&#x5B;&#039;azimuth&#039;]}\\n&quot;\n\n    # jobrelated part\n    sdgp = data&#x5B;&quot;Standardized Geophysical Parameters&quot;]\n    rp = data&#x5B;&quot;Runtime Parameters&quot;]\n    spgp = data&#x5B;&quot;Specialized Geophysical Parameters&quot;]\n    srp = data&#x5B;&quot;Specialized Runtime Parameters&quot;]\n    gp = data&#x5B;&quot;Grid Parameters&quot;]\n\n    strpar+=f&quot;ngpus={srp&#x5B;&#039;nGPUs&#039;]}\\n&quot;\n    strpar+=f&quot;storage={srp&#x5B;&#039;LocalComputeStorage&#039;]}\\n&quot;\n    strpar+=f&quot;nb_quants_bitcomp={srp&#x5B;&#039;nb_quants_compression&#039;]}\\n&quot;\n\n    strpar+=f&quot;cyclesSkip4Imaging={spgp&#x5B;&#039;imagingStep&#039;]}\\n&quot;\n    strpar+=f&quot;noperator={spgp&#x5B;&#039;fdOperator&#039;]}\\n&quot;\n    strpar+=f&quot;weightPower={spgp&#x5B;&#039;weightPower&#039;]}\\n&quot;\n    strpar+=f&quot;inputDataMultiply={spgp&#x5B;&#039;inputDataMultiply&#039;]}\\n&quot;\n    strpar+=f&quot;dtPropagation={spgp&#x5B;&#039;dtPropagation&#039;]}\\n&quot;\n    strpar+=f&quot;minValueOfVelocity={spgp&#x5B;&#039;minVelocity&#039;]}\\n&quot;\n    strpar+=f&quot;maxValueOfVelocity={spgp&#x5B;&#039;maxVelocity&#039;]}\\n&quot;\n\n    strpar+=f&quot;aperture_inline={sdgp&#x5B;&#039;aperture&#039;]&#x5B;&#039;inlineAperture&#039;]}\\n&quot;\n    strpar+=f&quot;aperture_xline={sdgp&#x5B;&#039;aperture&#039;]&#x5B;&#039;xlineAperture&#039;]}\\n&quot;\n</pre></div>\n\n\n<h3 id=\"model_handling\"  class=\"wp-block-heading\">Model handling<a href=\"#model_handling\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>The next step involves modifying the <code>download_and_cache_models</code> function. This function is responsible for downloading the seismic velocity models and caching them on an NVIDIA GPU instance until the RTM process is complete. Because the RTM sample from NVIDIA Energy Samples requires models in a raw float binary format, it is necessary to convert the downloaded SEGY format models.&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n# Overwrite this method to post-process the model files after download\ndef download_and_cache_models(self, job_info, tmpdirname) -&gt; dict&#x5B;str, str]:\n   \u2018\u2019\u2019\n   See base class for more details\n   \u2018\u2019\u2019\n    # result = super().download_and_cache_models(job_info, tmpdirname)\n    local_model = {}\n    for input_model in job_info&#x5B;&quot;module_configuration&quot;]&#x5B;&quot;Input&quot;]&#x5B;&quot;InputModelFiles&quot;]:\n    url = urlparse(input_model&#x5B;\u2018modelFile\u2019])\n    local_segy_file = f&quot;{tmpdirname}/{os.path.split(url.path)&#x5B;1]}&quot;\n    local_file = f&quot;{local_segy_file}.bin&quot;\n    local_file_hdr = f&quot;{local_segy_file}.bin.hdr&quot;\n    local_file_att = f&quot;{local_segy_file}.bin.attributes.txt&quot;\n    local_model&#x5B;input_model&#x5B;&#039;property&#039;]]=local_file\n    if not os.path.exists(local_file):\n\tobject_path = url.path.lstrip(&#039;/&#039;)\n\tself.download_file(url.hostname, object_path, local_segy_file)\n\ttrace_batch=1000\n\tprocess_segy.process_segy_file(local_segy_file, trace_batch, local_file, local_file_hdr, local_file_att)\n\tos.remove(local_segy_file)\n\n    return local_model\n</pre></div>\n\n\n<h3 id=\"data_handling\"  class=\"wp-block-heading\">Data handling<a href=\"#data_handling\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h3>\n\n\n\n<p>Next, modify the <code>download_shot_file</code> function provided by the AWS RTM template to enable partial downloads of seismic shot data from an S3 object. The RTM sample from NVIDIA Energy Samples requires seismic data to be in a specific format, consisting of raw binary data accompanied by a raw binary header. The raw binary data contains only the seismic measurements, while the binary header includes seven floating-point values per trace:&nbsp;</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Source x, y, and z (elevation) coordinates</li>\n\n\n\n<li>Receiver x, y, and z (elevation) coordinates</li>\n\n\n\n<li>An additional float to indicate trace validity (1 indicates invalid and 0 indicates valid)</li>\n</ul>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n# Overwrite this method to customize the download of shot file\ndef download_shot_file(self, data_bucket_name:str, data_object_key:str,\n\t\t\tstart_offset:int, end_offset:int, local_shot_file:str):\n\n\t&#039;&#039;&#039;\n\tSee base class for more details\n\t&#039;&#039;&#039;\n\n\tlocal_shot_segy_file=f&quot;{local_shot_file}.segy&quot;\n\tranges=&#x5B;&#x5B;0,3599], &#x5B;start_offset, end_offset-1]]\n\tt = S3CRTFileTransfer(18)\n\tt.download_parts2file(data_bucket_name, data_object_key,\n\t\t\t\tlocal_shot_segy_file, ranges)\n\ttrace_batch=1000\n\tlocal_shot_file_hdr = f&quot;{local_shot_file}.hdr&quot;\n\tlocal_shot_file_att = f&quot;{local_shot_file}.attributes.txt&quot;\n\tprocess_segy.process_segy_file(local_shot_segy_file, trace_batch,\n\t\t\t\t\tlocal_shot_file, local_shot_file_hdr,\n\t\t\t\t\tlocal_shot_file_att)\n\tos.remove(local_shot_segy_file)\n\n\treturn\n</pre></div>\n\n\n<p>Next, modify the <code>migration_single_shot</code> function to execute the RTM sample from NVIDIA Energy Samples by invoking it with the generated ASCII parameter file using a Python sub-process.&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n# Overwrite this method to customize the download of shot file\ndef migrate_shot_local(self, job_info, working_dir:str, local_shot_file:str,\n\t\t\tshot_id:int, local_model_files:dict&#x5B;str,str],\n\t\t\tlocal_img_fname:str) -&gt; bool:\n\tdatattfile = open(f&quot;{local_shot_file}.attributes.txt&quot;, &quot;r&quot;)\n\tlines = datattfile.readlines()\n\tdatattfile.close()\n\n\tt,dt=lines&#x5B;0].split(&quot;:&quot;)\n\tdt=str(float(dt.lstrip().rstrip()/1000.0)\n\tt,nt=lines&#x5B;1].split(&quot;:&quot;)\n\tnt = nt.lstrip().rstrip()\n\n\tlssize = os.stat(local_shot_file).st_size\n\tntr=str(int(lssize/int(nt)/4))\n\t\n\t&#039;&#039;&#039;\n\tSee base class for more details\n\t&#039;&#039;&#039;\n\tjsondata = job_info&#x5B;&#039;module_configuration&#039;]\n\tstrpar = json2par.json2par(jsondata, local_shot_file, local_model_files,\n\t\t\t\t\tlocal_img_fname, dt, nt, ntr)\n\tparfname = &quot;/scr/parfile/singleshot&quot;\n\tparfile = open(parfname, &quot;w&quot;)\n\tparfile.write(strpar)\n\tparfile.close()\n\n\tcmd = f&quot;LD_LIBRARY_PATH=/usr/local/cuda-12.5/targets/x86_64-linux/lib:/work/nvcomp_3.0.4/lib /work/rtm parfile= {parfname}  &gt;&amp; /scr/run.log&quot;\n\tlogging.info(&quot;running RTM cmd: %s&quot;, cmd)\n\t\n\tlogging.info(&quot;Starting Nvidia RTM migration...&quot;)\n\tsubprocess.run(cmd, cwd=working_dir, shell=True, text=True, check=True)\n\tlogging.info(&quot;Migration ended.&quot;)\n\n\treturn True \n</pre></div>\n\n\n<p>Then, package the migration service code, along with RTM sample from NVIDIA Energy Samples and required libraries, into a Docker image, which is subsequently pushed to Amazon Elastic Container Registry (ECR). This enables the AWS RTM template to automatically scale the RTM sample from NVIDIA Energy Samples across hundreds of NVIDIA GPU instances.&nbsp;</p>\n\n\n\n<h2 id=\"building_nvidia_energy_samples\"  class=\"wp-block-heading\">Building NVIDIA Energy Samples<a href=\"#building_nvidia_energy_samples\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>Here\u2019s how to build the RTM sample from NVIDIA Energy Samples and AWS image used for the NVIDIA GPU instance.&nbsp;</p>\n\n\n\n<p>There are a few prerequisites:</p>\n\n\n\n<ul class=\"wp-block-list\">\n<li>Download and install <a href=\"https://developer.nvidia.com/nvcomp-download\">nv_comp library</a> from the NVIDIA Developer web portal.&nbsp;</li>\n\n\n\n<li>Use the AWS deep learning AMI, which is preinstalled with all necessary NVIDIA CUDA libraries and the NVIDIA CUDA GPU Driver.</li>\n</ul>\n\n\n\n<p>Here&#8217;s the homescreen for Amazon Linux 2, supported on multiple NVIDIA CUDA versions, drivers, and Amazon EC2 instances.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: plain; title: ; notranslate\" title=\"\">\n      ,        #_\n      ~\\_  ####_          Amazon Linux 2\n     ~~ \\######\\\n    ~~   \\#######|        AL2 End of Life is 2025-06-30.\n   ~~     ####/ ---\n  ~~      V~&#039; &#039;~-&gt;\n  ~~~           /\n   ~~._.       _/\n     _/_/_/\n    _/m/&#039;\nA newer version of Amazon Linux is available!\n\n         Amazon Linux 2023, GA and supported until 2028-03-15.\n         https://aws.amazon.com/linux/amazon-linux-2023/\n\n27 package(s) needed for security, out of 37 available\nRun &quot;sudo yum update&quot; to apply all updates.\n\n=================================================================\nAMI Name: Deep Learning Base OSS Nvidia Driver AMI (Amazon Linux 2) Version 65\nSupported EC2 instances: G4dn, G5, G6, Gr6, P4d, P4de, P5\nNVIDIA driver version: 535.183.01\nCUDA versions available: cuda-11.8 cuda-12.1 cuda-12.2 cuda-12.3\nDefault CUDA version is 12.1\n</pre></div>\n\n\n<p>Modify the CMakelists.txt to set the arch correctly according to the NVIDIA GPU instance.&nbsp;</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nset(CMAKE_CUDA_FLAGS \u201c${CMAKE_CUDA_FLAGS} -gencode arch=compute_75,code=sm_75 \u201d)\n</pre></div>\n\n\n<p>Then, use CMake to build the RTM sample from NVIDIA Energy Samples and generate an RTM executable binary, which can be integrated to EHO.\u00a0</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\n\t0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info\t: Used 14 registers, 496 bytes cmem&#x5B;0]\nptxas info\t: Compiling entry function &#039;_Z13add_receiversPfPN6common16SeismicHeaderStrES_NS0_5grid4Ejjjf&#039; for &#039;sm_75&#039;\nptxas info\t: Function properties for _Z13add_receiversPfPN6common16SeismicHeaderStrES_NS0_5grid4Ejjjf\n\t0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info\t: Used 30 registers, 496 bytes cmem&#x5B;0], 16 bytes cmem&#x5B;2]\nptxas info\t: Compiling entry function &#039;_Z19add_source_withsincPf6float4N6common5gridEf&#039; for &#039;sm_75&#039;\nptxas info\t: Function properties for _Z19add_source_withsincPf6float4N6common5gridEf\n\t0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info\t: Used 38 registers, 484 bytes cmem&#x5B;0]\nptxas info\t: Compiling entry function &#039;_Z10add_sourceP6float26float4N6common5grid4Ef&#039; for &#039;sm_75&#039;\nptxas info\t: Function properties for _Z10add_sourceP6float26float4N6common5grid4Ef\n\t0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info\t: Used 11 registers, 484 bytes cmem&#x5B;0]\nptxas info\t: Compiling entry function &#039;_Z1-add_sourcePf6float4N6common5grid4Ef&#039; for &#039;sm_75&#039;\nptxas info\t: Function properties for _Z1-add_sourcePf6float4N6common5grid4Ef\n\t0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\nptxas info\t: Used 11 registers, 484 bytes cmem&#x5B;0]\n&#x5B;100%] Linking CUDA executable ../bin/rtm\n&#x5B;100%] Built target rtm\n</pre></div>\n\n\n<h2 id=\"future_of_hpc_in_energy&nbsp;\"  class=\"wp-block-heading\">Future of HPC in energy&nbsp;<a href=\"#future_of_hpc_in_energy&nbsp;\" class=\"heading-anchor-link\"><i class=\"fas fa-link\"></i></a></h2>\n\n\n\n<p>The integration of the NVIDIA Energy Samples application with the AWS Energy HPC Orchestrator demonstrates the potential of cloud-native solutions to meet the growing computational demands of the energy industry. The use of pre-optimized cloud-native templates streamlines the process, enabling faster deployment and efficient resource management.\u00a0</p>\n\n\n\n<p>As the energy sector continues to embrace digital transformation, the adoption of such integrated cloud-based systems will be crucial in addressing the increasingly complex computational challenges. </p>\n\n\n\n<p>For more information, see <a href=\"https://imageevent.aapg.org/portals/26/abstracts/2024/4099604.pdf\">AWS Energy HPC Orchestrator</a> and get access to the <a href=\"https://github.com/NVIDIA/energy-sdk\">NVIDIA Energy Samples</a>. Explore <a href=\"https://www.nvidia.com/en-us/industries/energy/oil-gas-operations/\">AI and HPC for subsurface operations</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>The energy industry\u2019s digital transformation requires a substantial increase in computational demands for key HPC workloads and applications. This trend is exemplified by advanced seismic imaging methodologies such as reverse time migration (RTM) and full waveform inversion (FWI), where doubling maximum frequency can produce a 16x increase in computational workload. Similarly, in reservoir simulation, a &hellip; <a href=\"https://developer.nvidia.com/blog/spotlight-accelerating-hpc-in-energy-with-aws-energy-hpc-orchestrator-and-nvidia-energy-samples/\">Continued</a></p>\n", "protected": false}, "author": 2372, "featured_media": 90372, "comment_status": "closed", "ping_status": "closed", "sticky": false, "template": "", "format": "standard", "meta": {"_acf_changed": false, "publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1508320", "discourse_permalink": "https://forums.developer.nvidia.com/t/spotlight-accelerating-hpc-in-energy-with-aws-energy-hpc-orchestrator-and-nvidia-energy-samples/311029", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 503], "tags": [3941, 453, 1945], "coauthors": [4106, 4107, 4108, 4109, 4110], "class_list": ["post-90367", "post", "type-post", "status-publish", "format-standard", "has-post-thumbnail", "hentry", "category-data-center-cloud", "category-simulation-modeling-design", "tag-ai-impact", "tag-featured", "tag-geoscience"], "acf": {"post_industry": ["Energy"], "post_products": ["General"], "post_learning_levels": ["General Interest"], "post_content_types": ["Spotlight"], "post_collections": ""}, "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2024/10/nvidia-energy-samples-featured.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-nvx", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "primary_category": {"category": "Simulation / Modeling / Design", "link": "https://developer.nvidia.com/blog/category/simulation-modeling-design/", "id": 503}, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90367"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/2372"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=90367"}], "version-history": [{"count": 4, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90367/revisions"}], "predecessor-version": [{"id": 90805, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/90367/revisions/90805"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/90372"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=90367"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=90367"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=90367"}, {"taxonomy": "author", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/coauthors?post=90367"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}]